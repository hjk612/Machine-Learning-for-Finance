{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pandas_datareader import data as pdr\n",
    "import datetime\n",
    "import warnings\n",
    "import fix_yahoo_finance as yf\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import functools as ft\n",
    "import pandas_talib as TA\n",
    "import operator\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "os.chdir(\"/Users/Hatim/Downloads\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded"
     ]
    }
   ],
   "source": [
    "#Downloading the Data for S&P500 Index directly from Yahoo!\n",
    "start = \"1995-01-01\" \n",
    "end = \"2017-12-17\"\n",
    "SPData = pdr.get_data_yahoo(\"^GSPC\",start,end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SP500 may be highly influenced by other major financial major indexes across the world. So we can include them as features and need to get data for them. Indexes considered are FTSE100, NIKKEI225,DJIA, Frankfurt DAX, Paris CAC,Hong Kong Hang Seng, Australia AXJO and NASDAQ. Exchange rates may also influence SP500 so we can also take USD/CNY, USD/JPY,USD/EUR and USD/GBP. We also use VIX data since it incorporates information about the market volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to download the data from Yahoo! and fred so that anyone is able to run the whole code without worrying about the datsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded"
     ]
    }
   ],
   "source": [
    "#getting all the necessary data\n",
    "FTSE = pdr.get_data_yahoo(\"^FTSE\",start,end)\n",
    "NIKKEI = pdr.get_data_yahoo(\"^N225\",start,end)\n",
    "DJI = pdr.get_data_yahoo(\"^DJI\",start,end)\n",
    "NASDAQ = pdr.get_data_yahoo(\"^IXIC\",start,end)\n",
    "CAC = pdr.get_data_yahoo(\"^FCHI\",start,end)\n",
    "HSI = pdr.get_data_yahoo(\"^HSI\",start,end)\n",
    "AXJO = pdr.get_data_yahoo(\"^AXJO\",start,end)\n",
    "SSE = pdr.get_data_yahoo(\"^SSEC\",start,end)\n",
    "VIX = pdr.get_data_yahoo(\"^VIX\",start,end)\n",
    "USDJPY = pdr.get_data_fred(\"DEXJPUS\",start,end)\n",
    "USDCNY = pdr.get_data_fred(\"DEXCHUS\",start,end)\n",
    "USDGBP = pdr.get_data_fred(\"DEXUSUK\",start,end)\n",
    "USDEUR = pdr.get_data_fred(\"DEXUSEU\",start,end)\n",
    "Gold = pdr.get_data_fred(\"GOLDPMGBD228NLBM\",start,end)\n",
    "#crude oil price - West Texas Intermediate\n",
    "Oil = pdr.get_data_fred(\"DCOILWTICO\",start,end)\n",
    "Oil.columns = ['Price']\n",
    "#It has null values, so dropping null values.\n",
    "Oil.dropna(axis=0,how=\"all\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Alignment and Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Renaming the columns so that we can identify different Close when we merge the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPData.rename(columns = {'Close':'SP_Close'},inplace=True)\n",
    "FTSE.rename(columns = {'Close':'FTSE_Close'},inplace=True)\n",
    "NIKKEI.rename(columns = {'Close':'NIKKEI_Close'},inplace=True)\n",
    "DJI.rename(columns = {'Close':'DJI_Close'},inplace=True)\n",
    "NASDAQ.rename(columns = {'Close':'NASDAQ_Close'},inplace=True)\n",
    "CAC.rename(columns = {'Close':'CAC_Close'},inplace=True)\n",
    "HSI.rename(columns = {'Close':'HSI_Close'},inplace=True)\n",
    "AXJO.rename(columns = {'Close':'AXJO_Close'},inplace=True)\n",
    "SSE.rename(columns = {'Close':'SSE_Close'},inplace=True)\n",
    "VIX.rename(columns = {'Close':'VIX_Close'},inplace=True)\n",
    "USDJPY.columns = [\"USDJPY_Close\"]\n",
    "USDCNY.columns = [\"USDCNY_Close\"]\n",
    "USDGBP.columns = [\"USDGBP_Close\"]\n",
    "USDEUR.columns = [\"USDEUR_Close\"]\n",
    "Gold.columns = [\"Gold_Price\"]\n",
    "Oil.rename(columns = {'Price':'Oil_Price'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tickers = [\"SP\",\"FTSE\",\"NIKKEI\",\"DJI\",\"NASDAQ\",\"CAC\",\"HSI\",\"AXJO\",\"USDJPY\",\"USDCNY\",\"USDGBP\",\"USDEUR\",\"VIX\"]\n",
    "dfs = [SPData,FTSE,NIKKEI,DJI,NASDAQ,CAC,HSI,AXJO,SSE,VIX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the Adjusted Close column since it would be wise to work on the Close instead of Adjusted Close. Also,since we are working on indexes Adjusted Close is equal to the Close. Please refer to this link which explains it nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.priceactionlab.com/Blog/2011/03/chaos-in-technical-analysis-and-backtesting-part-i-close-vs-adjusted-close/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df.drop(axis=1,columns=\"Adj Close\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of data to be merged\n",
    "Temp = [SPData,FTSE[\"FTSE_Close\"],NIKKEI[\"NIKKEI_Close\"],DJI[\"DJI_Close\"],NASDAQ[\"NASDAQ_Close\"],CAC[\"CAC_Close\"],HSI[\"HSI_Close\"],AXJO[\"AXJO_Close\"],\n",
    "USDJPY[\"USDJPY_Close\"],USDCNY[\"USDCNY_Close\"],USDGBP[\"USDGBP_Close\"],USDEUR[\"USDEUR_Close\"],Gold[\"Gold_Price\"],Oil[\"Oil_Price\"],VIX[\"VIX_Close\"],SSE[\"SSE_Close\"]]\n",
    "MergingList = [Temp[i].to_frame() for i in range(1,len(Temp))]\n",
    "MergingList.insert(0,SPData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = ft.reduce(lambda left,right: pd.merge(left,right,left_index=True,right_index=True),MergingList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have enough data points to do 2500 out of sample predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be working with 3 Target variables which will be described shortly as follows. I got this idea from the following paper:\n",
    "\n",
    "Application of machine learning techniques for stock market prediction by Bin Weng, Auburn University, May 6, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target 1: Close(i+1) - Close(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target 2: Open(i+1) - Open(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target 3: if Return > 0.0015 -> +1\n",
    "            else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp = Data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create label 3\n",
    "def target_label(x):\n",
    "    if x>0.0015:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical indicators are used extensively in the industry and they speak quite well about the trend. People have successfully traded using technical indicators so I decided to use several technical indicators in my project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def STOK(close, low, high, n): \n",
    " STOK = ((close - pd.rolling_min(low, n)) / (pd.rolling_max(high, n) - pd.rolling_min(low, n))) * 100\n",
    " return STOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTemp[\"STOK\"] = STOK(DataTemp[\"SP_Close\"],DataTemp[\"Low\"],DataTemp[\"High\"],14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def STOD(close, low, high, n):\n",
    " STOK = ((close - pd.rolling_min(low, n)) / (pd.rolling_max(high, n) - pd.rolling_min(low, n))) * 100\n",
    " STOD = pd.rolling_mean(STOK, 3)\n",
    " return STOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTemp[\"STOD\"] = STOD(DataTemp[\"SP_Close\"],DataTemp[\"Low\"],DataTemp[\"High\"],14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RSI(close, period):\n",
    "    delta = close.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = pd.stats.moments.ewma(u, com=period-1, adjust=False) / \\\n",
    "         pd.stats.moments.ewma(d, com=period-1, adjust=False)\n",
    "    return 100 - 100 / (1 + rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"RSI\"] = RSI(DataTemp[\"SP_Close\"],14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CCI(close, high, low, n, constant): \n",
    " TP = (high + low + close) / 3 \n",
    " CCI = pd.Series((TP - pd.rolling_mean(TP, n)) / (constant * pd.rolling_std(TP, n)), name = 'CCI_' + str(n)) \n",
    " return CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"CCI_20\"] = CCI(DataTemp[\"SP_Close\"],DataTemp[\"High\"],DataTemp[\"Low\"],20,0.015)\n",
    "DataTemp[\"CCI_10\"] = CCI(DataTemp[\"SP_Close\"],DataTemp[\"High\"],DataTemp[\"Low\"],10,0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ACCDIST(Close, High, Low, Volume, n):  \n",
    "    ad = (2 * Close - High - Low) / (High - Low) * Volume  \n",
    "    M = ad.diff(n - 1)  \n",
    "    N = ad.shift(n - 1)  \n",
    "    ROC = M / N  \n",
    "    AD = pd.Series(ROC, name = 'Acc/Dist_ROC_' + str(n))    \n",
    "    return AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"ACCDIST\"] = ACCDIST(DataTemp[\"SP_Close\"],DataTemp[\"High\"],DataTemp[\"Low\"],DataTemp[\"Volume\"],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MOM(Close, n):  \n",
    "    M = pd.Series(Close.diff(n), name = 'Momentum_' + str(n))    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"MOM_3\"] = MOM(DataTemp[\"SP_Close\"],3)\n",
    "DataTemp[\"MOM_5\"] = MOM(DataTemp[\"SP_Close\"],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ROC(close, n):  \n",
    "    M = close.diff(n - 1)  \n",
    "    N = close.shift(n - 1)  \n",
    "    ROC = pd.Series(((M / N) * 100), name = 'ROC_' + str(n))   \n",
    "    return ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"ROC_3\"] = ROC(DataTemp[\"SP_Close\"],3)\n",
    "DataTemp[\"ROC_5\"] = ROC(DataTemp[\"SP_Close\"],5)\n",
    "DataTemp[\"ROC_7\"] = ROC(DataTemp[\"SP_Close\"],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MA(Close,n):\n",
    "    MA = pd.Series(pd.rolling_mean(Close,n),name='MA_'+str(n))\n",
    "    return MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"MA_10\"] = MA(DataTemp[\"SP_Close\"],10)\n",
    "DataTemp[\"MA_5\"] = MA(DataTemp[\"SP_Close\"],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ForceIndex(close, volume, n): \n",
    " FI = pd.Series(close.diff(n) * volume, name = 'ForceIndex')  \n",
    " return FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"FI\"] = ForceIndex(DataTemp[\"SP_Close\"],DataTemp[\"Volume\"],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EMA(close, n):  \n",
    "    EMA = pd.Series(pd.ewma(close, span = n, min_periods = n - 1), name = 'EMA_' + str(n))    \n",
    "    return EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"EMA_10\"] = EMA(DataTemp[\"SP_Close\"],10)\n",
    "DataTemp[\"EMA_7\"] = EMA(DataTemp[\"SP_Close\"],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EOM(High,Low,Volume,n):  \n",
    "    EoM = (High.diff(1) + Low.diff(1)) * (High - Low) / (2 * Volume)  \n",
    "    Eom_ma = pd.Series(pd.rolling_mean(EoM, n), name = 'EoM_' + str(n))  \n",
    "    return Eom_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"EOM\"] = EOM(DataTemp[\"High\"],DataTemp[\"Low\"],DataTemp[\"Volume\"],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def STDDEV(close, n):  \n",
    "    stddev = pd.Series(pd.rolling_std(close, n), name = 'STD_' + str(n)) \n",
    "    return stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"STDDEV_10\"] = STDDEV(DataTemp[\"SP_Close\"],10)\n",
    "DataTemp[\"STDDEV_21\"] = STDDEV(DataTemp[\"SP_Close\"],21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Chaikin(close,high,low,volume):  \n",
    "    ad = (2 * close - high - low) / (high - low) * volume \n",
    "    Chaikin = pd.Series(pd.ewma(ad, span = 3, min_periods = 2) - pd.ewma(ad, span = 10, min_periods = 9), name = 'Chaikin')   \n",
    "    return Chaikin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"Chaikin\"] = Chaikin(DataTemp[\"SP_Close\"],DataTemp[\"High\"],DataTemp[\"Low\"],DataTemp[\"Volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EMA(close, n):  \n",
    "    EMA = pd.Series(pd.ewma(close, span = n, min_periods = n - 1), name = 'EMA_' + str(n))   \n",
    "    return EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"EMA_10\"] = EMA(DataTemp[\"SP_Close\"],10) \n",
    "DataTemp[\"EMA_7\"] = EMA(DataTemp[\"SP_Close\"],7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTemp[\"Target1\"] = np.sign(DataTemp[\"SP_Close\"].diff()).shift(-1)\n",
    "DataTemp[\"Target2\"] = np.sign(DataTemp[\"Open\"].diff()).shift(-1)\n",
    "DataTemp[\"Target3\"] = DataTemp[\"SP_Close\"].pct_change().apply(target_label).shift(-1)\n",
    "DataTemp.ix[DataTemp.Target2==0, 'Target2'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to trade at the open of the market. We cannot use the features such as low,high, volume, etc.\n",
    "but we can definitely use the returns of the other indices since they trade before US market and will affect US market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Features_label2 = [\"HSI_Returns\",\"AXJO_Returns\",\"SSE_Returns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp[\"Open_Change\"] = DataTemp[\"Open\"].pct_change()\n",
    "DataTemp[\"High_Change\"] = DataTemp[\"High\"].pct_change()\n",
    "DataTemp[\"Volume_Change\"] = DataTemp[\"Volume\"].pct_change()\n",
    "DataTemp[\"Low_Change\"] = DataTemp[\"Low\"].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating Returns\n",
    "ReturnsList = [i for i in DataTemp.columns if any(['_Close' in i,'_Price' in i])]\n",
    "for i in ReturnsList:\n",
    "    DataTemp[i.split(\"_\")[0]+\"_Returns\"] = DataTemp[i].pct_change()\n",
    "Drop = [i for i in DataTemp.columns if any([\"_Price\" in i,\"_Close\" in i])]\n",
    "DataTemp.drop(Drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp.dropna(inplace=True)\n",
    "ColsList = list(DataTemp.columns)\n",
    "ColsList.pop(ColsList.index(\"Target1\"))\n",
    "ColsList.pop(ColsList.index(\"Target2\"))\n",
    "ColsList.pop(ColsList.index(\"Target3\"))\n",
    "DataTemp = DataTemp[ColsList+[\"Target1\"]+[\"Target2\"]+[\"Target3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataTemp.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\"n_estimators\":[100,500,1000],\"criterion\":[\"entropy\",\"gini\"],\"max_features\":[\"sqrt\",\"log2\",10,20],\n",
    "              \"max_depth\":[10,15,20,None],\"min_samples_leaf\":[1,5,10,15,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RC = RandomForestClassifier(oob_score=True,n_jobs=-1,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using first 250 points for parameter tuning to just get a rough estimate of the parameters. \n",
    "A better approach would be to do parameter tuning every time we train the model. But GridSearchCV is a costly process\n",
    "I tried using the parameters obtained by using first 250 points and got pretty good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=True, random_state=123, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 500, 1000], 'criterion': ['entropy', 'gini'], 'max_features': ['sqrt', 'log2', 10, 20], 'max_depth': [10, 15, 20, None], 'min_samples_leaf': [1, 5, 10, 15, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv = GridSearchCV(RC,parameters,scoring=\"roc_auc\",n_jobs=-1,cv=10)\n",
    "gscv.fit(DataTemp[DataTemp.columns[:-1]][0:250],DataTemp[DataTemp.columns[-1]][0:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 15,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 5,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Volume', 'STOK', 'STOD', 'RSI', 'CCI_20',\n",
       "       'CCI_10', 'ACCDIST', 'MOM_3', 'MOM_5', 'ROC_3', 'ROC_5', 'ROC_7',\n",
       "       'MA_10', 'MA_5', 'FI', 'EMA_10', 'EMA_7', 'EOM', 'STDDEV_10',\n",
       "       'STDDEV_21', 'Chaikin', 'Open_Change', 'High_Change', 'Volume_Change',\n",
       "       'Low_Change', 'SP_Returns', 'FTSE_Returns', 'NIKKEI_Returns',\n",
       "       'DJI_Returns', 'NASDAQ_Returns', 'CAC_Returns', 'HSI_Returns',\n",
       "       'AXJO_Returns', 'USDJPY_Returns', 'USDCNY_Returns', 'USDGBP_Returns',\n",
       "       'USDEUR_Returns', 'Gold_Returns', 'Oil_Returns', 'VIX_Returns',\n",
       "       'SSE_Returns', 'Target1', 'Target2', 'Target3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataTemp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's consider a Naive classifier where we predict all 1's and we will consider this classifier as our benchmark\n",
    "#Lets see the f1 score and accuracy for this classifier\n",
    "\n",
    "#Only the features (predictors) data\n",
    "Features = DataTemp[DataTemp.columns[:-3]]\n",
    "#Label or target data\n",
    "Label1 = DataTemp[DataTemp.columns[-3]]\n",
    "Label2 = DataTemp[DataTemp.columns[-2]]\n",
    "Label3 = DataTemp[DataTemp.columns[-1]]\n",
    "from sklearn.metrics import f1_score\n",
    "#A function is created so that you pass the test set and it gives you the accuracy, f1 score and roc_auc_score by just predicting \n",
    "#all +1 on the test set.\n",
    "def benchmark_stats(Test):\n",
    "    #Calculating F1 score\n",
    "    print (\"F1 score for predicting all +1 on the test dataset: {:.4f}\".format(\n",
    "        f1_score(Test, [1]*len(Test), pos_label=1, average='binary')))\n",
    "\n",
    "    #Calculating Accuracy score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print (\"Accuracy score for predicting all +1 on the test dataset: {:.4f}\".format(\n",
    "        accuracy_score(Test, [1]*len(Test))))\n",
    "    \n",
    "    #Calculating roc_auc score\n",
    "    print(\"AUC score for predicting all +1 on the test dataset: {:.4f}\".format(roc_auc_score(Test,[1]*len(Test))))\n",
    "    \n",
    "#We will be using the above function to compare the accuracy,f1 score and AUC score of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up some helper functions that may help to train, predict and evaluate our model.\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    print (\"Model Trained!!!!\")\n",
    "\n",
    "def predict_labels_f1(clf, features, target):\n",
    "    \n",
    "    y_pred = clf.predict(features)\n",
    "    return f1_score(target, y_pred, pos_label=1)\n",
    "\n",
    "def predict_labels_accuracy(clf, features, target):\n",
    "    \n",
    "    y_pred = clf.predict(features)\n",
    "    return accuracy_score(target, y_pred)   \n",
    "\n",
    "def predict_labels_auc(clf,features,target):\n",
    "    \n",
    "    y_pred = clf.predict(features)\n",
    "    return roc_auc_score(target,y_pred)\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer'''\n",
    "    \n",
    "    #Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    #Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    #Print the results of prediction for both training and testing\n",
    "    print (\"F1 score for training set: {:.4f}.\".format(predict_labels_f1(clf, X_train, y_train)))\n",
    "    print (\"Accuracy score for training set: {:.4f}.\".format(predict_labels_accuracy(clf, X_train, y_train)))\n",
    "    print(\"AUC score for training set: {:.4f}.\".format(predict_labels_auc(clf,X_train,y_train)))\n",
    "    print (\"F1 score for test set: {:.4f}.\".format(predict_labels_f1(clf, X_test, y_test)))\n",
    "    print (\"Accuracy score for test set: {:.4f}.\".format(predict_labels_accuracy(clf, X_test, y_test)))\n",
    "    print(\"AUC score for the test set: {:.4f}.\".format(predict_labels_auc(clf,X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import  three supervised learning models from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "DT = DecisionTreeClassifier(random_state=42)\n",
    "GNB = GaussianNB()\n",
    "svc = SVC(random_state=42)\n",
    "RF = RandomForestClassifier(n_estimators=3000,criterion=\"gini\",max_depth=25,max_features=\"log2\",min_samples_leaf=5,random_state=42)\n",
    "Logistic = LogisticRegression()"
   ]
  },
  {
   "attachments": {
    "Untitled.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Untitled.png](attachment:Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier: \n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4762.\n",
      "Accuracy score for test set: 0.4500.\n",
      "AUC score for the test set: 0.4536.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4571.\n",
      "Accuracy score for test set: 0.4300.\n",
      "AUC score for the test set: 0.4293.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5614.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4931.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5149.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5124.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5614.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5143.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4927.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6087.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5430.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5614.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5510.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5600.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5455.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4952.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5607.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5375.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6387.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5543.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6393.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5429.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7879\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5812.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.4996.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5593.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4631.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4078.\n",
      "Accuracy score for test set: 0.3900.\n",
      "AUC score for the test set: 0.3932.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5688.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5395.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5439.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4720.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5306.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5618.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5690.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4884.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5263.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5489.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5437.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5337.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6496.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5775.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4444.\n",
      "Accuracy score for test set: 0.4500.\n",
      "AUC score for the test set: 0.4537.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5528.\n",
      "Accuracy score for test set: 0.4500.\n",
      "AUC score for the test set: 0.4241.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6000.\n",
      "Accuracy score for test set: 0.6667.\n",
      "AUC score for the test set: 0.6573.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6286\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4583\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "GaussianNB: \n",
      "\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5510.\n",
      "Accuracy score for training set: 0.5160.\n",
      "AUC score for training set: 0.5162.\n",
      "F1 score for test set: 0.6812.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5123.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5735.\n",
      "Accuracy score for training set: 0.5210.\n",
      "AUC score for training set: 0.5200.\n",
      "F1 score for test set: 0.5306.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5475.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5556.\n",
      "Accuracy score for training set: 0.5280.\n",
      "AUC score for training set: 0.5275.\n",
      "F1 score for test set: 0.4045.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5193.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6002.\n",
      "Accuracy score for training set: 0.5470.\n",
      "AUC score for training set: 0.5433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test set: 0.5766.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5385.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5979.\n",
      "Accuracy score for training set: 0.5440.\n",
      "AUC score for training set: 0.5395.\n",
      "F1 score for test set: 0.5149.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5503.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6233.\n",
      "Accuracy score for training set: 0.5480.\n",
      "AUC score for training set: 0.5357.\n",
      "F1 score for test set: 0.6933.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.4794.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6606.\n",
      "Accuracy score for training set: 0.5530.\n",
      "AUC score for training set: 0.5283.\n",
      "F1 score for test set: 0.6928.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5804.\n",
      "Accuracy score for training set: 0.5330.\n",
      "AUC score for training set: 0.5269.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6676.\n",
      "Accuracy score for training set: 0.5490.\n",
      "AUC score for training set: 0.5145.\n",
      "F1 score for test set: 0.6331.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4900.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6876.\n",
      "Accuracy score for training set: 0.5530.\n",
      "AUC score for training set: 0.5124.\n",
      "F1 score for test set: 0.5474.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5777.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6830.\n",
      "Accuracy score for training set: 0.5610.\n",
      "AUC score for training set: 0.5283.\n",
      "F1 score for test set: 0.6333.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5417.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6903.\n",
      "Accuracy score for training set: 0.5710.\n",
      "AUC score for training set: 0.5373.\n",
      "F1 score for test set: 0.6071.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5541.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7071.\n",
      "Accuracy score for training set: 0.5800.\n",
      "AUC score for training set: 0.5401.\n",
      "F1 score for test set: 0.7848.\n",
      "Accuracy score for test set: 0.6600.\n",
      "AUC score for the test set: 0.5341.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7879\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7144.\n",
      "Accuracy score for training set: 0.5730.\n",
      "AUC score for training set: 0.5234.\n",
      "F1 score for test set: 0.7059.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5109.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7189.\n",
      "Accuracy score for training set: 0.5770.\n",
      "AUC score for training set: 0.5209.\n",
      "F1 score for test set: 0.7389.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5119.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7157.\n",
      "Accuracy score for training set: 0.5750.\n",
      "AUC score for training set: 0.5246.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7028.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5213.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.4919.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7113.\n",
      "Accuracy score for training set: 0.5730.\n",
      "AUC score for training set: 0.5252.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7168.\n",
      "Accuracy score for training set: 0.5820.\n",
      "AUC score for training set: 0.5270.\n",
      "F1 score for test set: 0.7421.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7196.\n",
      "Accuracy score for training set: 0.5800.\n",
      "AUC score for training set: 0.5155.\n",
      "F1 score for test set: 0.7226.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.4718.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7374.\n",
      "Accuracy score for training set: 0.5890.\n",
      "AUC score for training set: 0.5084.\n",
      "F1 score for test set: 0.6486.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7227.\n",
      "Accuracy score for training set: 0.5680.\n",
      "AUC score for training set: 0.4980.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7151.\n",
      "Accuracy score for training set: 0.5610.\n",
      "AUC score for training set: 0.5016.\n",
      "F1 score for test set: 0.7226.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5029.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7012.\n",
      "Accuracy score for training set: 0.5610.\n",
      "AUC score for training set: 0.5164.\n",
      "F1 score for test set: 0.6759.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.4972.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7020.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5173.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.4828.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7015.\n",
      "Accuracy score for training set: 0.5600.\n",
      "AUC score for training set: 0.5148.\n",
      "F1 score for test set: 0.6286.\n",
      "Accuracy score for test set: 0.4583.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6286\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4583\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "SVC: \n",
      "\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7097.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7805.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6928.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7500.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7879.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7879\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7342.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7654.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7421.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6486.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7342.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6286.\n",
      "Accuracy score for test set: 0.4583.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6286\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4583\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "RandomForestClassifier: \n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6615.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5255.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5234.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4879.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5347.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5546.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9971.\n",
      "Accuracy score for training set: 0.9970.\n",
      "AUC score for training set: 0.9970.\n",
      "F1 score for test set: 0.5567.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5703.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9990.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9990.\n",
      "F1 score for test set: 0.4270.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5651.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9981.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9978.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.4737.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9991.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9989.\n",
      "F1 score for test set: 0.6379.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5725.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9973.\n",
      "Accuracy score for training set: 0.9970.\n",
      "AUC score for training set: 0.9966.\n",
      "F1 score for test set: 0.6412.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5300.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9991.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9989.\n",
      "F1 score for test set: 0.5405.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4900.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9973.\n",
      "Accuracy score for training set: 0.9970.\n",
      "AUC score for training set: 0.9971.\n",
      "F1 score for test set: 0.5200.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5233.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9982.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9978.\n",
      "F1 score for test set: 0.7121.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5792.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9955.\n",
      "Accuracy score for training set: 0.9950.\n",
      "AUC score for training set: 0.9944.\n",
      "F1 score for test set: 0.5378.\n",
      "Accuracy score for test set: 0.4500.\n",
      "AUC score for the test set: 0.4319.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9964.\n",
      "Accuracy score for training set: 0.9960.\n",
      "AUC score for training set: 0.9955.\n",
      "F1 score for test set: 0.7324.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5429.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7879\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9973.\n",
      "Accuracy score for training set: 0.9970.\n",
      "AUC score for training set: 0.9966.\n",
      "F1 score for test set: 0.5873.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4622.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9991.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9989.\n",
      "F1 score for test set: 0.5937.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4466.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9982.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9977.\n",
      "F1 score for test set: 0.5614.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5102.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9982.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9978.\n",
      "F1 score for test set: 0.5487.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4868.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9982.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9977.\n",
      "F1 score for test set: 0.7625.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5128.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9982.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9977.\n",
      "F1 score for test set: 0.5253.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5496.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9991.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9988.\n",
      "F1 score for test set: 0.7403.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5057.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6383.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5072.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6126.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5787.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9947.\n",
      "Accuracy score for training set: 0.9940.\n",
      "AUC score for training set: 0.9937.\n",
      "F1 score for test set: 0.6393.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5398.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9964.\n",
      "Accuracy score for training set: 0.9960.\n",
      "AUC score for training set: 0.9960.\n",
      "F1 score for test set: 0.0364.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5093.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.3678.\n",
      "Accuracy score for test set: 0.4500.\n",
      "AUC score for the test set: 0.4832.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9991.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9989.\n",
      "F1 score for test set: 0.6897.\n",
      "Accuracy score for test set: 0.6250.\n",
      "AUC score for the test set: 0.6469.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6286\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4583\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "LogisticRegression: \n",
      "\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5249.\n",
      "Accuracy score for training set: 0.5130.\n",
      "AUC score for training set: 0.5131.\n",
      "F1 score for test set: 0.5636.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5172.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5590.\n",
      "Accuracy score for training set: 0.5220.\n",
      "AUC score for training set: 0.5214.\n",
      "F1 score for test set: 0.6429.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5939.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5548.\n",
      "Accuracy score for training set: 0.5250.\n",
      "AUC score for training set: 0.5245.\n",
      "F1 score for test set: 0.6379.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5725.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6101.\n",
      "Accuracy score for training set: 0.5360.\n",
      "AUC score for training set: 0.5305.\n",
      "F1 score for test set: 0.5932.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5327.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5918.\n",
      "Accuracy score for training set: 0.5420.\n",
      "AUC score for training set: 0.5380.\n",
      "F1 score for test set: 0.6613.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5564.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6471.\n",
      "Accuracy score for training set: 0.5550.\n",
      "AUC score for training set: 0.5379.\n",
      "F1 score for test set: 0.5538.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test set: 0.4200.\n",
      "AUC score for the test set: 0.3856.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6861.\n",
      "Accuracy score for training set: 0.5480.\n",
      "AUC score for training set: 0.5119.\n",
      "F1 score for test set: 0.6573.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.4859.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6892.\n",
      "Accuracy score for training set: 0.5500.\n",
      "AUC score for training set: 0.5069.\n",
      "F1 score for test set: 0.6331.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4900.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6856.\n",
      "Accuracy score for training set: 0.5460.\n",
      "AUC score for training set: 0.5012.\n",
      "F1 score for test set: 0.6569.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5300.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6417.\n",
      "Accuracy score for training set: 0.5400.\n",
      "AUC score for training set: 0.5153.\n",
      "F1 score for test set: 0.6508.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5427.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6321.\n",
      "Accuracy score for training set: 0.5460.\n",
      "AUC score for training set: 0.5281.\n",
      "F1 score for test set: 0.6870.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5500.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6423.\n",
      "Accuracy score for training set: 0.5500.\n",
      "AUC score for training set: 0.5292.\n",
      "F1 score for test set: 0.6230.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5194.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6450.\n",
      "Accuracy score for training set: 0.5300.\n",
      "AUC score for training set: 0.5013.\n",
      "F1 score for test set: 0.7568.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5451.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7879\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6608.\n",
      "Accuracy score for training set: 0.5360.\n",
      "AUC score for training set: 0.5006.\n",
      "F1 score for test set: 0.6061.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4573.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6903.\n",
      "Accuracy score for training set: 0.5460.\n",
      "AUC score for training set: 0.4945.\n",
      "F1 score for test set: 0.7333.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5337.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6801.\n",
      "Accuracy score for training set: 0.5410.\n",
      "AUC score for training set: 0.4972.\n",
      "F1 score for test set: 0.6222.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5128.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6780.\n",
      "Accuracy score for training set: 0.5440.\n",
      "AUC score for training set: 0.5088.\n",
      "F1 score for test set: 0.7260.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5195.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6935.\n",
      "Accuracy score for training set: 0.5430.\n",
      "AUC score for training set: 0.4934.\n",
      "F1 score for test set: 0.7613.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5349.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7122.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5003.\n",
      "F1 score for test set: 0.7389.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5037.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7287.\n",
      "Accuracy score for training set: 0.5740.\n",
      "AUC score for training set: 0.4980.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7378.\n",
      "Accuracy score for training set: 0.5850.\n",
      "AUC score for training set: 0.5012.\n",
      "F1 score for test set: 0.6486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7277.\n",
      "Accuracy score for training set: 0.5720.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7196.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7130.\n",
      "Accuracy score for training set: 0.5540.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7130.\n",
      "Accuracy score for training set: 0.5540.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7342.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7130.\n",
      "Accuracy score for training set: 0.5540.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6286.\n",
      "Accuracy score for test set: 0.4583.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6286\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4583\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#working with Label1\n",
    "for clf in [DT, GNB, svc,RF,Logistic]:\n",
    "    print (\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    for i in range(0,3525,100):\n",
    "        if(len(Features[i+1000:i+1100]==100)):\n",
    "            train_predict(clf, Features[i:i+1000], Label1[i:i+1000], Features[i+1000:i+1100], Label1[i+1000:i+1100])\n",
    "            print('#'*40)\n",
    "            print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "            benchmark_stats(Label1[i+1000:i+1100])\n",
    "            print('#'*40)\n",
    "            print('-'*50)\n",
    "        else:\n",
    "            break     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier: \n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5664.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5020.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4854.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.4732.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5636.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5154.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5577.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5410.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5455.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5084.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5455.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4951.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4490.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.4646.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5417.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5596.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4421.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.4690.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5625.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5800.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6019.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5975.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5825.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5703.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6034.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5345.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5766.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5385.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5421.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5089.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5631.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5538.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6066.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.4974.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5234.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4958.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5636.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5154.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5614.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4907.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5455.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5545.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5513.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5926.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5576.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6341.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5307.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7952\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5045.\n",
      "Accuracy score for test set: 0.4500.\n",
      "AUC score for the test set: 0.4549.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6250.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.4792.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "GaussianNB: \n",
      "\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5404.\n",
      "Accuracy score for training set: 0.5730.\n",
      "AUC score for training set: 0.5731.\n",
      "F1 score for test set: 0.4490.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.4667.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5828.\n",
      "Accuracy score for training set: 0.5790.\n",
      "AUC score for training set: 0.5790.\n",
      "F1 score for test set: 0.6847.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.6461.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6386.\n",
      "Accuracy score for training set: 0.5970.\n",
      "AUC score for training set: 0.5951.\n",
      "F1 score for test set: 0.6774.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5795.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6527.\n",
      "Accuracy score for training set: 0.5860.\n",
      "AUC score for training set: 0.5808.\n",
      "F1 score for test set: 0.6016.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5148.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6634.\n",
      "Accuracy score for training set: 0.5840.\n",
      "AUC score for training set: 0.5751.\n",
      "F1 score for test set: 0.7023.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5678.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set: 0.6628.\n",
      "Accuracy score for training set: 0.5940.\n",
      "AUC score for training set: 0.5826.\n",
      "F1 score for test set: 0.6341.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5300.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6597.\n",
      "Accuracy score for training set: 0.5790.\n",
      "AUC score for training set: 0.5628.\n",
      "F1 score for test set: 0.5983.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5197.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6831.\n",
      "Accuracy score for training set: 0.5760.\n",
      "AUC score for training set: 0.5459.\n",
      "F1 score for test set: 0.5055.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5466.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6923.\n",
      "Accuracy score for training set: 0.5840.\n",
      "AUC score for training set: 0.5543.\n",
      "F1 score for test set: 0.3143.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.4992.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6806.\n",
      "Accuracy score for training set: 0.5720.\n",
      "AUC score for training set: 0.5493.\n",
      "F1 score for test set: 0.6372.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5900.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6656.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5444.\n",
      "F1 score for test set: 0.6917.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5547.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6729.\n",
      "Accuracy score for training set: 0.5770.\n",
      "AUC score for training set: 0.5597.\n",
      "F1 score for test set: 0.6815.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5510.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6641.\n",
      "Accuracy score for training set: 0.5700.\n",
      "AUC score for training set: 0.5548.\n",
      "F1 score for test set: 0.7600.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5470.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6718.\n",
      "Accuracy score for training set: 0.5750.\n",
      "AUC score for training set: 0.5558.\n",
      "F1 score for test set: 0.6457.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5682.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6724.\n",
      "Accuracy score for training set: 0.5810.\n",
      "AUC score for training set: 0.5638.\n",
      "F1 score for test set: 0.7445.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.6144.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6677.\n",
      "Accuracy score for training set: 0.5910.\n",
      "AUC score for training set: 0.5796.\n",
      "F1 score for test set: 0.6767.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5919.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6645.\n",
      "Accuracy score for training set: 0.5950.\n",
      "AUC score for training set: 0.5877.\n",
      "F1 score for test set: 0.7712.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.5443.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6844.\n",
      "Accuracy score for training set: 0.6080.\n",
      "AUC score for training set: 0.5956.\n",
      "F1 score for test set: 0.7260.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5292.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6936.\n",
      "Accuracy score for training set: 0.6060.\n",
      "AUC score for training set: 0.5857.\n",
      "F1 score for test set: 0.7092.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5487.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7038.\n",
      "Accuracy score for training set: 0.6170.\n",
      "AUC score for training set: 0.5926.\n",
      "F1 score for test set: 0.6713.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.4678.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7008.\n",
      "Accuracy score for training set: 0.6090.\n",
      "AUC score for training set: 0.5798.\n",
      "F1 score for test set: 0.6299.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5300.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6928.\n",
      "Accuracy score for training set: 0.6000.\n",
      "AUC score for training set: 0.5737.\n",
      "F1 score for test set: 0.6355.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.6138.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6825.\n",
      "Accuracy score for training set: 0.5990.\n",
      "AUC score for training set: 0.5785.\n",
      "F1 score for test set: 0.7049.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.6242.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6759.\n",
      "Accuracy score for training set: 0.6010.\n",
      "AUC score for training set: 0.5857.\n",
      "F1 score for test set: 0.7347.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5120.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for predicting all +1 on the test dataset: 0.6600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7000.\n",
      "Accuracy score for training set: 0.6100.\n",
      "AUC score for training set: 0.5821.\n",
      "F1 score for test set: 0.7183.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5234.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6956.\n",
      "Accuracy score for training set: 0.5860.\n",
      "AUC score for training set: 0.5467.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.4375.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "SVC: \n",
      "\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6676.\n",
      "Accuracy score for training set: 0.5010.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7097.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6702.\n",
      "Accuracy score for training set: 0.5040.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6746.\n",
      "Accuracy score for training set: 0.5090.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6799.\n",
      "Accuracy score for training set: 0.5150.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6577.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6851.\n",
      "Accuracy score for training set: 0.5210.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7730.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6971.\n",
      "Accuracy score for training set: 0.5350.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7038.\n",
      "Accuracy score for training set: 0.5430.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7130.\n",
      "Accuracy score for training set: 0.5540.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7097.\n",
      "Accuracy score for training set: 0.5500.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6301.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6996.\n",
      "Accuracy score for training set: 0.5380.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6945.\n",
      "Accuracy score for training set: 0.5320.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6962.\n",
      "Accuracy score for training set: 0.5340.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6928.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6937.\n",
      "Accuracy score for training set: 0.5310.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7730.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6996.\n",
      "Accuracy score for training set: 0.5380.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6979.\n",
      "Accuracy score for training set: 0.5360.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6920.\n",
      "Accuracy score for training set: 0.5290.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6842.\n",
      "Accuracy score for training set: 0.5200.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7805.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6928.\n",
      "Accuracy score for training set: 0.5300.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7500.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7038.\n",
      "Accuracy score for training set: 0.5430.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7122.\n",
      "Accuracy score for training set: 0.5530.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7421.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7196.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7138.\n",
      "Accuracy score for training set: 0.5550.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6486.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7097.\n",
      "Accuracy score for training set: 0.5500.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7097.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7030.\n",
      "Accuracy score for training set: 0.5420.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7952.\n",
      "Accuracy score for test set: 0.6600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7952\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7188.\n",
      "Accuracy score for training set: 0.5610.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7805.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7253.\n",
      "Accuracy score for training set: 0.5690.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7805.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "RandomForestClassifier: \n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8733.\n",
      "Accuracy score for training set: 0.8720.\n",
      "AUC score for training set: 0.8720.\n",
      "F1 score for test set: 0.5437.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5323.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8687.\n",
      "Accuracy score for training set: 0.8670.\n",
      "AUC score for training set: 0.8670.\n",
      "F1 score for test set: 0.6250.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5739.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8809.\n",
      "Accuracy score for training set: 0.8780.\n",
      "AUC score for training set: 0.8779.\n",
      "F1 score for test set: 0.5660.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5406.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8776.\n",
      "Accuracy score for training set: 0.8720.\n",
      "AUC score for training set: 0.8714.\n",
      "F1 score for test set: 0.5321.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4920.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8828.\n",
      "Accuracy score for training set: 0.8760.\n",
      "AUC score for training set: 0.8751.\n",
      "F1 score for test set: 0.6325.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5639.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8825.\n",
      "Accuracy score for training set: 0.8700.\n",
      "AUC score for training set: 0.8668.\n",
      "F1 score for test set: 0.6308.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.4911.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8814.\n",
      "Accuracy score for training set: 0.8660.\n",
      "AUC score for training set: 0.8612.\n",
      "F1 score for test set: 0.6325.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5600.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8824.\n",
      "Accuracy score for training set: 0.8640.\n",
      "AUC score for training set: 0.8571.\n",
      "F1 score for test set: 0.5745.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5986.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8747.\n",
      "Accuracy score for training set: 0.8550.\n",
      "AUC score for training set: 0.8478.\n",
      "F1 score for test set: 0.5055.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5463.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8875.\n",
      "Accuracy score for training set: 0.8740.\n",
      "AUC score for training set: 0.8699.\n",
      "F1 score for test set: 0.5688.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5300.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9011.\n",
      "Accuracy score for training set: 0.8920.\n",
      "AUC score for training set: 0.8898.\n",
      "F1 score for test set: 0.6486.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.6065.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8821.\n",
      "Accuracy score for training set: 0.8680.\n",
      "AUC score for training set: 0.8638.\n",
      "F1 score for test set: 0.5487.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4839.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8839.\n",
      "Accuracy score for training set: 0.8710.\n",
      "AUC score for training set: 0.8675.\n",
      "F1 score for test set: 0.6774.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5766.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8901.\n",
      "Accuracy score for training set: 0.8760.\n",
      "AUC score for training set: 0.8713.\n",
      "F1 score for test set: 0.6441.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5929.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8732.\n",
      "Accuracy score for training set: 0.8580.\n",
      "AUC score for training set: 0.8538.\n",
      "F1 score for test set: 0.6903.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.6437.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8629.\n",
      "Accuracy score for training set: 0.8490.\n",
      "AUC score for training set: 0.8460.\n",
      "F1 score for test set: 0.5962.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5845.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8558.\n",
      "Accuracy score for training set: 0.8450.\n",
      "AUC score for training set: 0.8433.\n",
      "F1 score for test set: 0.7244.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.6233.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8626.\n",
      "Accuracy score for training set: 0.8490.\n",
      "AUC score for training set: 0.8461.\n",
      "F1 score for test set: 0.5950.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.4875.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8596.\n",
      "Accuracy score for training set: 0.8400.\n",
      "AUC score for training set: 0.8341.\n",
      "F1 score for test set: 0.6552.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5893.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8616.\n",
      "Accuracy score for training set: 0.8400.\n",
      "AUC score for training set: 0.8328.\n",
      "F1 score for test set: 0.5841.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5236.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8646.\n",
      "Accuracy score for training set: 0.8390.\n",
      "AUC score for training set: 0.8283.\n",
      "F1 score for test set: 0.6387.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5700.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8721.\n",
      "Accuracy score for training set: 0.8510.\n",
      "AUC score for training set: 0.8431.\n",
      "F1 score for test set: 0.5825.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5721.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8531.\n",
      "Accuracy score for training set: 0.8320.\n",
      "AUC score for training set: 0.8259.\n",
      "F1 score for test set: 0.6609.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.6010.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8671.\n",
      "Accuracy score for training set: 0.8520.\n",
      "AUC score for training set: 0.8484.\n",
      "F1 score for test set: 0.6615.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5169.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7952\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8834.\n",
      "Accuracy score for training set: 0.8640.\n",
      "AUC score for training set: 0.8565.\n",
      "F1 score for test set: 0.6772.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5582.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8952.\n",
      "Accuracy score for training set: 0.8740.\n",
      "AUC score for training set: 0.8626.\n",
      "F1 score for test set: 0.7273.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5972.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "LogisticRegression: \n",
      "\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6033.\n",
      "Accuracy score for training set: 0.5660.\n",
      "AUC score for training set: 0.5658.\n",
      "F1 score for test set: 0.6612.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5747.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6628.\n",
      "Accuracy score for training set: 0.5380.\n",
      "AUC score for training set: 0.5351.\n",
      "F1 score for test set: 0.7067.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5073.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6716.\n",
      "Accuracy score for training set: 0.5100.\n",
      "AUC score for training set: 0.5013.\n",
      "F1 score for test set: 0.7226.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5114.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6812.\n",
      "Accuracy score for training set: 0.5180.\n",
      "AUC score for training set: 0.5031.\n",
      "F1 score for test set: 0.6577.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6855.\n",
      "Accuracy score for training set: 0.5220.\n",
      "AUC score for training set: 0.5010.\n",
      "F1 score for test set: 0.7730.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6971.\n",
      "Accuracy score for training set: 0.5350.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7038.\n",
      "Accuracy score for training set: 0.5430.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7130.\n",
      "Accuracy score for training set: 0.5540.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7097.\n",
      "Accuracy score for training set: 0.5500.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6301.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7014.\n",
      "Accuracy score for training set: 0.5420.\n",
      "AUC score for training set: 0.5043.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6968.\n",
      "Accuracy score for training set: 0.5370.\n",
      "AUC score for training set: 0.5053.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6990.\n",
      "Accuracy score for training set: 0.5400.\n",
      "AUC score for training set: 0.5064.\n",
      "F1 score for test set: 0.6928.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6982.\n",
      "Accuracy score for training set: 0.5410.\n",
      "AUC score for training set: 0.5107.\n",
      "F1 score for test set: 0.7730.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7014.\n",
      "Accuracy score for training set: 0.5420.\n",
      "AUC score for training set: 0.5043.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7011.\n",
      "Accuracy score for training set: 0.5430.\n",
      "AUC score for training set: 0.5075.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6971.\n",
      "Accuracy score for training set: 0.5420.\n",
      "AUC score for training set: 0.5140.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6868.\n",
      "Accuracy score for training set: 0.5440.\n",
      "AUC score for training set: 0.5266.\n",
      "F1 score for test set: 0.7853.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.5139.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6984.\n",
      "Accuracy score for training set: 0.5440.\n",
      "AUC score for training set: 0.5151.\n",
      "F1 score for test set: 0.7500.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7061.\n",
      "Accuracy score for training set: 0.5480.\n",
      "AUC score for training set: 0.5055.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7122.\n",
      "Accuracy score for training set: 0.5530.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7421.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7196.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7138.\n",
      "Accuracy score for training set: 0.5550.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6486.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7097.\n",
      "Accuracy score for training set: 0.5500.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7097.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7030.\n",
      "Accuracy score for training set: 0.5420.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7952.\n",
      "Accuracy score for test set: 0.6600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7952\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7188.\n",
      "Accuracy score for training set: 0.5610.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7805.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7253.\n",
      "Accuracy score for training set: 0.5690.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7805.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#working with Label2\n",
    "for clf in [DT, GNB, svc,RF,Logistic]:\n",
    "    print (\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    for i in range(0,3525,100):\n",
    "        if(len(Features[i+1000:i+1100]==100)):\n",
    "            train_predict(clf, DataTemp[Features_label2][i:i+1000], Label2[i:i+1000], DataTemp[Features_label2][i+1000:i+1100], Label2[i+1000:i+1100])\n",
    "            print('#'*40)\n",
    "            print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "            benchmark_stats(Label2[i+1000:i+1100])\n",
    "            print('#'*40)\n",
    "            print('-'*50)\n",
    "        else:\n",
    "            break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier: \n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4270.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4838.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6111\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4783.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5169.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4783.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5169.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4545.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5187.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5612\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5200.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5208.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4681.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4984.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5825.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5739.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5301.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5988.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5816\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5714.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5801.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4651.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5504.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5049.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4896.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6842\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5000.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5697.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4719.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5300.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4396.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4864.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5417.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5644.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.2857.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4526.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5401\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5294.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5198.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6755\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5000.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5018.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5657.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5700.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4783.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5169.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4086.\n",
      "Accuracy score for test set: 0.4500.\n",
      "AUC score for the test set: 0.4475.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4318.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4929.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5600.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5609.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5636.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5354.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4828.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5424.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.2667.\n",
      "Accuracy score for test set: 0.5417.\n",
      "AUC score for the test set: 0.4664.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.4516\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.2917\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "GaussianNB: \n",
      "\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2047.\n",
      "Accuracy score for training set: 0.5570.\n",
      "AUC score for training set: 0.5193.\n",
      "F1 score for test set: 0.3729.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5893.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6111\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2762.\n",
      "Accuracy score for training set: 0.5650.\n",
      "AUC score for training set: 0.5281.\n",
      "F1 score for test set: 0.2667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5314.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2496.\n",
      "Accuracy score for training set: 0.5670.\n",
      "AUC score for training set: 0.5244.\n",
      "F1 score for test set: 0.2623.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5221.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2598.\n",
      "Accuracy score for training set: 0.5670.\n",
      "AUC score for training set: 0.5253.\n",
      "F1 score for test set: 0.3200.\n",
      "Accuracy score for test set: 0.6600.\n",
      "AUC score for the test set: 0.5780.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5612\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3542.\n",
      "Accuracy score for training set: 0.5880.\n",
      "AUC score for training set: 0.5521.\n",
      "F1 score for test set: 0.2143.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5433.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3517.\n",
      "Accuracy score for training set: 0.5760.\n",
      "AUC score for training set: 0.5441.\n",
      "F1 score for test set: 0.4337.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5240.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3333.\n",
      "Accuracy score for training set: 0.5680.\n",
      "AUC score for training set: 0.5387.\n",
      "F1 score for test set: 0.6202.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5293.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3005.\n",
      "Accuracy score for training set: 0.5670.\n",
      "AUC score for training set: 0.5371.\n",
      "F1 score for test set: 0.5312.\n",
      "Accuracy score for test set: 0.4000.\n",
      "AUC score for the test set: 0.4655.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5816\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3153.\n",
      "Accuracy score for training set: 0.5700.\n",
      "AUC score for training set: 0.5393.\n",
      "F1 score for test set: 0.5385.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5224.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2576.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5288.\n",
      "F1 score for test set: 0.5347.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5313.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3194.\n",
      "Accuracy score for training set: 0.5610.\n",
      "AUC score for training set: 0.5360.\n",
      "F1 score for test set: 0.4762.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5673.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6842\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3671.\n",
      "Accuracy score for training set: 0.5690.\n",
      "AUC score for training set: 0.5508.\n",
      "F1 score for test set: 0.3951.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.4960.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3528.\n",
      "Accuracy score for training set: 0.5560.\n",
      "AUC score for training set: 0.5376.\n",
      "F1 score for test set: 0.2121.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4800.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3611.\n",
      "Accuracy score for training set: 0.5470.\n",
      "AUC score for training set: 0.5319.\n",
      "F1 score for test set: 0.3014.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4755.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3740.\n",
      "Accuracy score for training set: 0.5380.\n",
      "AUC score for training set: 0.5279.\n",
      "F1 score for test set: 0.3896.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5458.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4259.\n",
      "Accuracy score for training set: 0.5470.\n",
      "AUC score for training set: 0.5408.\n",
      "F1 score for test set: 0.1754.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.4485.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5401\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3644.\n",
      "Accuracy score for training set: 0.5430.\n",
      "AUC score for training set: 0.5294.\n",
      "F1 score for test set: 0.1333.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4882.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6755\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3710.\n",
      "Accuracy score for training set: 0.5320.\n",
      "AUC score for training set: 0.5213.\n",
      "F1 score for test set: 0.2727.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5424.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4149.\n",
      "Accuracy score for training set: 0.5290.\n",
      "AUC score for training set: 0.5250.\n",
      "F1 score for test set: 0.3125.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5530.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4406.\n",
      "Accuracy score for training set: 0.5200.\n",
      "AUC score for training set: 0.5174.\n",
      "F1 score for test set: 0.4156.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5350.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3980.\n",
      "Accuracy score for training set: 0.5280.\n",
      "AUC score for training set: 0.5213.\n",
      "F1 score for test set: 0.4267.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5505.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2921.\n",
      "Accuracy score for training set: 0.5250.\n",
      "AUC score for training set: 0.5104.\n",
      "F1 score for test set: 0.4722.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5924.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2973.\n",
      "Accuracy score for training set: 0.5320.\n",
      "AUC score for training set: 0.5160.\n",
      "F1 score for test set: 0.3467.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5008.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2741.\n",
      "Accuracy score for training set: 0.5340.\n",
      "AUC score for training set: 0.5156.\n",
      "F1 score for test set: 0.2143.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5212.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2919.\n",
      "Accuracy score for training set: 0.5440.\n",
      "AUC score for training set: 0.5245.\n",
      "F1 score for test set: 0.2400.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5610.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GaussianNB using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2449.\n",
      "Accuracy score for training set: 0.5560.\n",
      "AUC score for training set: 0.5264.\n",
      "F1 score for test set: 0.2000.\n",
      "Accuracy score for test set: 0.6667.\n",
      "AUC score for the test set: 0.5126.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.4516\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.2917\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "SVC: \n",
      "\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6111\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5612\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5816\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6842\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5401\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6755\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.7083.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.4516\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.2917\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "RandomForestClassifier: \n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.3438.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5446.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6111\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9989.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9989.\n",
      "F1 score for test set: 0.2295.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5020.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9977.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9980.\n",
      "F1 score for test set: 0.3333.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5717.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.1818.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5431.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5612\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9977.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9977.\n",
      "F1 score for test set: 0.1132.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5120.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9966.\n",
      "Accuracy score for training set: 0.9970.\n",
      "AUC score for training set: 0.9966.\n",
      "F1 score for test set: 0.5393.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5865.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9978.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9980.\n",
      "F1 score for test set: 0.5176.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5831.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9967.\n",
      "Accuracy score for training set: 0.9970.\n",
      "AUC score for training set: 0.9969.\n",
      "F1 score for test set: 0.4889.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5395.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5816\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9956.\n",
      "Accuracy score for training set: 0.9960.\n",
      "AUC score for training set: 0.9956.\n",
      "F1 score for test set: 0.4884.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5553.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9922.\n",
      "Accuracy score for training set: 0.9930.\n",
      "AUC score for training set: 0.9923.\n",
      "F1 score for test set: 0.4524.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5516.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9956.\n",
      "Accuracy score for training set: 0.9960.\n",
      "AUC score for training set: 0.9958.\n",
      "F1 score for test set: 0.5000.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5657.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6842\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9925.\n",
      "Accuracy score for training set: 0.9930.\n",
      "AUC score for training set: 0.9928.\n",
      "F1 score for test set: 0.4186.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4909.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9957.\n",
      "Accuracy score for training set: 0.9960.\n",
      "AUC score for training set: 0.9958.\n",
      "F1 score for test set: 0.4156.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5500.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9979.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9980.\n",
      "F1 score for test set: 0.3000.\n",
      "Accuracy score for test set: 0.4400.\n",
      "AUC score for the test set: 0.4295.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9979.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9980.\n",
      "F1 score for test set: 0.3544.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5044.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9969.\n",
      "Accuracy score for training set: 0.9970.\n",
      "AUC score for training set: 0.9970.\n",
      "F1 score for test set: 0.2609.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4391.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5401\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9979.\n",
      "Accuracy score for training set: 0.9980.\n",
      "AUC score for training set: 0.9980.\n",
      "F1 score for test set: 0.1613.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4878.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6755\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9990.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9990.\n",
      "F1 score for test set: 0.5920.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4767.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9990.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9990.\n",
      "F1 score for test set: 0.4096.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5068.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.4835.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5262.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9990.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9990.\n",
      "F1 score for test set: 0.2222.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.4778.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.5263.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.6185.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9947.\n",
      "Accuracy score for training set: 0.9950.\n",
      "AUC score for training set: 0.9947.\n",
      "F1 score for test set: 0.4944.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5465.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9947.\n",
      "Accuracy score for training set: 0.9950.\n",
      "AUC score for training set: 0.9947.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0426.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.4853.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a RandomForestClassifier using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.9989.\n",
      "Accuracy score for training set: 0.9990.\n",
      "AUC score for training set: 0.9989.\n",
      "F1 score for test set: 0.5000.\n",
      "Accuracy score for test set: 0.7500.\n",
      "AUC score for the test set: 0.6555.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.4516\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.2917\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "\n",
      "LogisticRegression: \n",
      "\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.1067.\n",
      "Accuracy score for training set: 0.5480.\n",
      "AUC score for training set: 0.5052.\n",
      "F1 score for test set: 0.0851.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5138.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6111\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2036.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5195.\n",
      "F1 score for test set: 0.2456.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5390.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2186.\n",
      "Accuracy score for training set: 0.5640.\n",
      "AUC score for training set: 0.5191.\n",
      "F1 score for test set: 0.1818.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5173.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2555.\n",
      "Accuracy score for training set: 0.5630.\n",
      "AUC score for training set: 0.5215.\n",
      "F1 score for test set: 0.2222.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.5559.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5612\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3307.\n",
      "Accuracy score for training set: 0.5790.\n",
      "AUC score for training set: 0.5418.\n",
      "F1 score for test set: 0.2414.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5441.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3785.\n",
      "Accuracy score for training set: 0.5730.\n",
      "AUC score for training set: 0.5448.\n",
      "F1 score for test set: 0.3768.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5585.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3954.\n",
      "Accuracy score for training set: 0.5750.\n",
      "AUC score for training set: 0.5512.\n",
      "F1 score for test set: 0.3947.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5275.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4034.\n",
      "Accuracy score for training set: 0.5770.\n",
      "AUC score for training set: 0.5553.\n",
      "F1 score for test set: 0.4938.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5744.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5816\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3983.\n",
      "Accuracy score for training set: 0.5860.\n",
      "AUC score for training set: 0.5612.\n",
      "F1 score for test set: 0.5060.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5841.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4073.\n",
      "Accuracy score for training set: 0.5780.\n",
      "AUC score for training set: 0.5562.\n",
      "F1 score for test set: 0.3514.\n",
      "Accuracy score for test set: 0.5200.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for the test set: 0.5375.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4690.\n",
      "Accuracy score for training set: 0.5720.\n",
      "AUC score for training set: 0.5601.\n",
      "F1 score for test set: 0.4390.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5481.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6842\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4864.\n",
      "Accuracy score for training set: 0.5670.\n",
      "AUC score for training set: 0.5592.\n",
      "F1 score for test set: 0.4235.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4649.\n",
      "Accuracy score for training set: 0.5580.\n",
      "AUC score for training set: 0.5489.\n",
      "F1 score for test set: 0.4819.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5700.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4848.\n",
      "Accuracy score for training set: 0.5600.\n",
      "AUC score for training set: 0.5534.\n",
      "F1 score for test set: 0.3864.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.4544.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4667.\n",
      "Accuracy score for training set: 0.5430.\n",
      "AUC score for training set: 0.5379.\n",
      "F1 score for test set: 0.4719.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5385.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4808.\n",
      "Accuracy score for training set: 0.5400.\n",
      "AUC score for training set: 0.5369.\n",
      "F1 score for test set: 0.3636.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.4828.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5401\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4358.\n",
      "Accuracy score for training set: 0.5340.\n",
      "AUC score for training set: 0.5261.\n",
      "F1 score for test set: 0.4000.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5242.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6755\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4418.\n",
      "Accuracy score for training set: 0.5300.\n",
      "AUC score for training set: 0.5238.\n",
      "F1 score for test set: 0.3415.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.4725.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4672.\n",
      "Accuracy score for training set: 0.5210.\n",
      "AUC score for training set: 0.5190.\n",
      "F1 score for test set: 0.5393.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5880.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4665.\n",
      "Accuracy score for training set: 0.5220.\n",
      "AUC score for training set: 0.5201.\n",
      "F1 score for test set: 0.4706.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5415.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4080.\n",
      "Accuracy score for training set: 0.5270.\n",
      "AUC score for training set: 0.5208.\n",
      "F1 score for test set: 0.4557.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5545.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3170.\n",
      "Accuracy score for training set: 0.5260.\n",
      "AUC score for training set: 0.5125.\n",
      "F1 score for test set: 0.3529.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5255.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3575.\n",
      "Accuracy score for training set: 0.5400.\n",
      "AUC score for training set: 0.5267.\n",
      "F1 score for test set: 0.3636.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5016.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3230.\n",
      "Accuracy score for training set: 0.5430.\n",
      "AUC score for training set: 0.5265.\n",
      "F1 score for test set: 0.3226.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5475.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3353.\n",
      "Accuracy score for training set: 0.5480.\n",
      "AUC score for training set: 0.5307.\n",
      "F1 score for test set: 0.3607.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5665.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2314.\n",
      "Accuracy score for training set: 0.5550.\n",
      "AUC score for training set: 0.5247.\n",
      "F1 score for test set: 0.2000.\n",
      "Accuracy score for test set: 0.6667.\n",
      "AUC score for the test set: 0.5126.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.4516\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.2917\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#working with Label3\n",
    "for clf in [DT, GNB, svc,RF,Logistic]:\n",
    "    print (\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    for i in range(0,3525,100):\n",
    "        if(len(Features[i+1000:i+1100]==100)):\n",
    "            train_predict(clf, Features[i:i+1000], Label3[i:i+1000], Features[i+1000:i+1100], Label3[i+1000:i+1100])\n",
    "            print('#'*40)\n",
    "            print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "            benchmark_stats(Label3[i+1000:i+1100])\n",
    "            print('#'*40)\n",
    "            print('-'*50)\n",
    "        else:\n",
    "            break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for predicting the open of the market is quite good. Seems that the algorithms are able to capture the pattern for the open quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that Decision trees, GNB and SVC perform slightly better than the naive classifier which predicts all +1.Hence we haven't gained any advantage. So we will have to tune the parameters of the classifiers to achieve better results. Random forest performs quite well beating the naive classifier most of the time. We get respectable results for label 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests on the other hand (although not all the time, but most of the time) perform much better than the Naive classifier. At times achieving accuracy of 62%. So indicating that ML could be used in certain period to have significant gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pick individual classifiers and do the parameter tuning using gridsearchcv for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6386.\n",
      "Accuracy score for training set: 0.6220.\n",
      "AUC score for training set: 0.6221.\n",
      "F1 score for test set: 0.5000.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.4589.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6720.\n",
      "Accuracy score for training set: 0.5080.\n",
      "AUC score for training set: 0.5040.\n",
      "F1 score for test set: 0.7097.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6712.\n",
      "Accuracy score for training set: 0.5210.\n",
      "AUC score for training set: 0.5174.\n",
      "F1 score for test set: 0.6615.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5191.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6856.\n",
      "Accuracy score for training set: 0.5360.\n",
      "AUC score for training set: 0.5213.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7205.\n",
      "Accuracy score for training set: 0.6990.\n",
      "AUC score for training set: 0.6970.\n",
      "F1 score for test set: 0.4468.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5391.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7115.\n",
      "Accuracy score for training set: 0.6480.\n",
      "AUC score for training set: 0.6347.\n",
      "F1 score for test set: 0.6767.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5343.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6613.\n",
      "Accuracy score for training set: 0.5810.\n",
      "AUC score for training set: 0.5640.\n",
      "F1 score for test set: 0.5217.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5668.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6832.\n",
      "Accuracy score for training set: 0.6040.\n",
      "AUC score for training set: 0.5836.\n",
      "F1 score for test set: 0.5913.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5300.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6896.\n",
      "Accuracy score for training set: 0.6660.\n",
      "AUC score for training set: 0.6661.\n",
      "F1 score for test set: 0.4301.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.4700.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7267.\n",
      "Accuracy score for training set: 0.5870.\n",
      "AUC score for training set: 0.5381.\n",
      "F1 score for test set: 0.5902.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.4855.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7044.\n",
      "Accuracy score for training set: 0.5670.\n",
      "AUC score for training set: 0.5265.\n",
      "F1 score for test set: 0.7285.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5083.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6499.\n",
      "Accuracy score for training set: 0.6100.\n",
      "AUC score for training set: 0.6047.\n",
      "F1 score for test set: 0.5185.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.4782.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6906.\n",
      "Accuracy score for training set: 0.5780.\n",
      "AUC score for training set: 0.5455.\n",
      "F1 score for test set: 0.6857.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.4835.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7879\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7155.\n",
      "Accuracy score for training set: 0.5570.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7197.\n",
      "Accuracy score for training set: 0.5740.\n",
      "AUC score for training set: 0.5159.\n",
      "F1 score for test set: 0.7368.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5304.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7148.\n",
      "Accuracy score for training set: 0.5690.\n",
      "AUC score for training set: 0.5167.\n",
      "F1 score for test set: 0.5857.\n",
      "Accuracy score for test set: 0.4200.\n",
      "AUC score for the test set: 0.4456.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7080.\n",
      "Accuracy score for training set: 0.5480.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7654.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7158.\n",
      "Accuracy score for training set: 0.5680.\n",
      "AUC score for training set: 0.5154.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7289.\n",
      "Accuracy score for training set: 0.5820.\n",
      "AUC score for training set: 0.5179.\n",
      "F1 score for test set: 0.7421.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7318.\n",
      "Accuracy score for training set: 0.5770.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7458.\n",
      "Accuracy score for training set: 0.6100.\n",
      "AUC score for training set: 0.5354.\n",
      "F1 score for test set: 0.6074.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.4848.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7332.\n",
      "Accuracy score for training set: 0.6470.\n",
      "AUC score for training set: 0.6132.\n",
      "F1 score for test set: 0.5102.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5207.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7257.\n",
      "Accuracy score for training set: 0.5910.\n",
      "AUC score for training set: 0.5384.\n",
      "F1 score for test set: 0.6986.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5055.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7160.\n",
      "Accuracy score for training set: 0.5820.\n",
      "AUC score for training set: 0.5373.\n",
      "F1 score for test set: 0.0357.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.4984.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6514.\n",
      "Accuracy score for training set: 0.5590.\n",
      "AUC score for training set: 0.5366.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7130.\n",
      "Accuracy score for training set: 0.5540.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.6286.\n",
      "Accuracy score for test set: 0.4583.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6286\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4583\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Decision tree paramter tuning for label 1\n",
    "\n",
    "parameters = {'max_depth': [1,2,3,4,5,6,7,8,9],'criterion':('gini','entropy'),'splitter':('best','random')}\n",
    "DT = DecisionTreeClassifier(random_state=42)\n",
    "gscv = GridSearchCV(DT, parameters,cv=10,n_jobs=-1)\n",
    "for i in range(0,3525,100):\n",
    "    if(len(Features[i+1000:i+1100]==100)):\n",
    "        train_predict(gscv, Features[i:i+1000], Label1[i:i+1000], Features[i+1000:i+1100], Label1[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "        benchmark_stats(Label1[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print('-'*50)\n",
    "    else:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6963.\n",
      "Accuracy score for training set: 0.6990.\n",
      "AUC score for training set: 0.6990.\n",
      "F1 score for test set: 0.5714.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5131.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5142.\n",
      "Accuracy score for training set: 0.5900.\n",
      "AUC score for training set: 0.5913.\n",
      "F1 score for test set: 0.5532.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5958.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5933.\n",
      "Accuracy score for training set: 0.5900.\n",
      "AUC score for training set: 0.5900.\n",
      "F1 score for test set: 0.5818.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5357.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6709.\n",
      "Accuracy score for training set: 0.6410.\n",
      "AUC score for training set: 0.6388.\n",
      "F1 score for test set: 0.5487.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4928.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5508.\n",
      "Accuracy score for training set: 0.5840.\n",
      "AUC score for training set: 0.5881.\n",
      "F1 score for test set: 0.5818.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5513.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6546.\n",
      "Accuracy score for training set: 0.6370.\n",
      "AUC score for training set: 0.6365.\n",
      "F1 score for test set: 0.6308.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.4911.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5634.\n",
      "Accuracy score for training set: 0.5830.\n",
      "AUC score for training set: 0.5912.\n",
      "F1 score for test set: 0.5474.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5777.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6815.\n",
      "Accuracy score for training set: 0.5850.\n",
      "AUC score for training set: 0.5588.\n",
      "F1 score for test set: 0.6111.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5869.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.7183.\n",
      "Accuracy score for training set: 0.5930.\n",
      "AUC score for training set: 0.5540.\n",
      "F1 score for test set: 0.5849.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5684.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5301.\n",
      "Accuracy score for training set: 0.5780.\n",
      "AUC score for training set: 0.5892.\n",
      "F1 score for test set: 0.5263.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5500.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6550.\n",
      "Accuracy score for training set: 0.6070.\n",
      "AUC score for training set: 0.6006.\n",
      "F1 score for test set: 0.6777.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5922.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6775.\n",
      "Accuracy score for training set: 0.5850.\n",
      "AUC score for training set: 0.5681.\n",
      "F1 score for test set: 0.6815.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5510.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6457.\n",
      "Accuracy score for training set: 0.5950.\n",
      "AUC score for training set: 0.5884.\n",
      "F1 score for test set: 0.7317.\n",
      "Accuracy score for test set: 0.6700.\n",
      "AUC score for the test set: 0.6544.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6480.\n",
      "Accuracy score for training set: 0.5860.\n",
      "AUC score for training set: 0.5760.\n",
      "F1 score for test set: 0.6000.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.6022.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6619.\n",
      "Accuracy score for training set: 0.6180.\n",
      "AUC score for training set: 0.6118.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.6700.\n",
      "AUC score for the test set: 0.6591.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6673.\n",
      "Accuracy score for training set: 0.6280.\n",
      "AUC score for training set: 0.6233.\n",
      "F1 score for test set: 0.6286.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.6152.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Decision tree paramter tuning for label 2\n",
    "parameters = {'max_depth': [1,2,3,4,5,6,7,8,9],'criterion':('gini','entropy'),'splitter':('best','random')}\n",
    "DT = DecisionTreeClassifier(random_state=42)\n",
    "gscv = GridSearchCV(DT, parameters,cv=10,n_jobs=-1)\n",
    "for i in range(0,3525,100):\n",
    "    if(len(Features[i+2000:i+2100]==100)):\n",
    "        train_predict(gscv, DataTemp[Features_label2][i:i+1000], Label2[i:i+1000], DataTemp[Features_label2][i+1000:i+1100], Label2[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "        benchmark_stats(Label2[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print('-'*50)\n",
    "    else:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it can be seen that the predictive power for open is really good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.0000.\n",
      "Accuracy score for training set: 0.5480.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6111\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.2478.\n",
      "Accuracy score for training set: 0.5690.\n",
      "AUC score for training set: 0.5297.\n",
      "F1 score for test set: 0.3582.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5471.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.0223.\n",
      "Accuracy score for training set: 0.5620.\n",
      "AUC score for training set: 0.5048.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.0000.\n",
      "Accuracy score for training set: 0.5600.\n",
      "AUC score for training set: 0.5000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5714\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4099.\n",
      "Accuracy score for training set: 0.5710.\n",
      "AUC score for training set: 0.5461.\n",
      "F1 score for test set: 0.4500.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5500.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4447.\n",
      "Accuracy score for training set: 0.5730.\n",
      "AUC score for training set: 0.5539.\n",
      "F1 score for test set: 0.3478.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5440.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.4422.\n",
      "Accuracy score for training set: 0.6190.\n",
      "AUC score for training set: 0.5940.\n",
      "F1 score for test set: 0.5545.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5543.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.3952.\n",
      "Accuracy score for training set: 0.5960.\n",
      "AUC score for training set: 0.5707.\n",
      "F1 score for test set: 0.3377.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.4651.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5915\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5173.\n",
      "Accuracy score for training set: 0.6100.\n",
      "AUC score for training set: 0.5972.\n",
      "F1 score for test set: 0.5435.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5777.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5516.\n",
      "Accuracy score for training set: 0.5920.\n",
      "AUC score for training set: 0.5887.\n",
      "F1 score for test set: 0.5149.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5112.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5079.\n",
      "Accuracy score for training set: 0.5930.\n",
      "AUC score for training set: 0.5829.\n",
      "F1 score for test set: 0.5060.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5978.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6842\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5381.\n",
      "Accuracy score for training set: 0.5640.\n",
      "AUC score for training set: 0.5627.\n",
      "F1 score for test set: 0.5000.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5535.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5126.\n",
      "Accuracy score for training set: 0.5930.\n",
      "AUC score for training set: 0.5847.\n",
      "F1 score for test set: 0.4524.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5370.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "F1 score for training set: 0.5646.\n",
      "Accuracy score for training set: 0.5820.\n",
      "AUC score for training set: 0.5816.\n",
      "F1 score for test set: 0.4330.\n",
      "Accuracy score for test set: 0.4500.\n",
      "AUC score for the test set: 0.4498.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.6157.\n",
      "Accuracy score for training set: 0.5830.\n",
      "AUC score for training set: 0.5879.\n",
      "F1 score for test set: 0.5849.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5584.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a GridSearchCV using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 0.8096.\n",
      "Accuracy score for training set: 0.8250.\n",
      "AUC score for training set: 0.8233.\n",
      "F1 score for test set: 0.3467.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.4773.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5401\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Decision tree paramter tuning for label 3\n",
    "parameters = {'max_depth': [1,2,3,4,5,6,7,8,9],'criterion':('gini','entropy'),'splitter':('best','random')}\n",
    "DT = DecisionTreeClassifier(random_state=42)\n",
    "gscv = GridSearchCV(DT, parameters,cv=10,n_jobs=-1)\n",
    "for i in range(0,3525,100):\n",
    "    if(len(Features[i+2000:i+2100]==100)):\n",
    "        train_predict(gscv, Features[i:i+1000], Label3[i:i+1000], Features[i+1000:i+1100], Label3[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "        benchmark_stats(Label3[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print('-'*50)\n",
    "    else:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the model is more adaptive and dynamic in nature. The accuracy scores have improved drastically and are almost equal and greater than the naive classifier accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7097.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7500.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7879\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6486.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7730.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6928.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6755.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7500.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7879.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7342.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7654.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.0000\n",
      "Accuracy score for predicting all +1 on the test dataset: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-518181ee5844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BENCHMARK STATS - NAIVE CLASSIFIER\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mbenchmark_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabel1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-169-3021ec86e8db>\u001b[0m in \u001b[0;36mbenchmark_stats\u001b[0;34m(Test)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#Calculating roc_auc score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC score for predicting all +1 on the test dataset: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#We will be using the above function to compare the accuracy,f1 score and AUC score of our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    269\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "#Tuning SVC with train size of 1000 and test size of 100. Label 1\n",
    "parameters = {'kernel':('linear', 'rbf','sigmoid'), 'C':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "              'gamma':[.000001,.000005,.00005,.0005,.001,.005,.01,.02,.04,.05,.1,.3,.5]}\n",
    "svc = SVC(random_state=3)\n",
    "gscv = GridSearchCV(svc, parameters,cv=10,n_jobs=-1)\n",
    "for i in range(0,3525,100):\n",
    "    if(len(Features[i+1000:i+1100]==100)):\n",
    "        train_predict(svc, Features[i:i+1000], Label1[i:i+1000], Features[i+1000:i+1100], Label1[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "        benchmark_stats(Label1[i+2000:i+2100])\n",
    "        print('#'*40)\n",
    "        print('-'*50)\n",
    "    else:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7097.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7730\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6577.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7730.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6301.\n",
      "Accuracy score for test set: 0.4600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7179\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6667.\n",
      "Accuracy score for test set: 0.5000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6667\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5000\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6928.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7730.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7097\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7952\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7179.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7805\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.7805.\n",
      "Accuracy score for test set: 0.6400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.0000\n",
      "Accuracy score for predicting all +1 on the test dataset: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-e6ad4ddefbc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BENCHMARK STATS - NAIVE CLASSIFIER\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mbenchmark_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabel2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-169-3021ec86e8db>\u001b[0m in \u001b[0;36mbenchmark_stats\u001b[0;34m(Test)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#Calculating roc_auc score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC score for predicting all +1 on the test dataset: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#We will be using the above function to compare the accuracy,f1 score and AUC score of our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    269\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "#Tuning SVC with train size of 1000 and test size of 100. Label 2\n",
    "parameters = {'kernel':('linear', 'rbf','sigmoid'), 'C':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "              'gamma':[.000001,.000005,.00005,.0005,.001,.005,.01,.02,.04,.05,.1,.3,.5]}\n",
    "svc = SVC(random_state=3)\n",
    "gscv = GridSearchCV(svc, parameters,cv=10,n_jobs=-1)\n",
    "for i in range(0,3525,100):\n",
    "    if(len(Features[i+1000:i+1100]==100)):\n",
    "        train_predict(svc, Features[i:i+1000], Label2[i:i+1000], Features[i+1000:i+1100], Label2[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "        benchmark_stats(Label2[i+2000:i+2100])\n",
    "        print('#'*40)\n",
    "        print('-'*50)\n",
    "    else:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the above code didn't run because for some time period the classifier is predicting only one class. But whatever results we have in hand it can be seen after tuning the parameters for label2 (Open), we could achieve accuracy of 64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5600.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6842\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6207\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4500\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6928\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5401\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3700\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6755\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5100\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6301\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4600\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.5915\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6577\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4900\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.5300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6111\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4400\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6014\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4300\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.6300.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.4848\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.3200\n",
      "AUC score for predicting all +1 on the test dataset: 0.5000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Model Trained!!!!\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "F1 score for test set: 0.0000.\n",
      "Accuracy score for test set: 0.4900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.0000\n",
      "Accuracy score for predicting all +1 on the test dataset: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-5cf8dda525ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BENCHMARK STATS - NAIVE CLASSIFIER\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mbenchmark_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabel3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-169-3021ec86e8db>\u001b[0m in \u001b[0;36mbenchmark_stats\u001b[0;34m(Test)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#Calculating roc_auc score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC score for predicting all +1 on the test dataset: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#We will be using the above function to compare the accuracy,f1 score and AUC score of our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    269\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "#Tuning SVC with train size of 1000 and test size of 100. Label 3\n",
    "parameters = {'kernel':('linear', 'rbf','sigmoid'), 'C':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "              'gamma':[.000001,.000005,.00005,.0005,.001,.005,.01,.02,.04,.05,.1,.3,.5]}\n",
    "svc = SVC(random_state=3)\n",
    "gscv = GridSearchCV(svc, parameters,cv=10,n_jobs=-1)\n",
    "for i in range(0,3525,100):\n",
    "    if(len(Features[i+1000:i+1100]==100)):\n",
    "        train_predict(svc, Features[i:i+1000], Label3[i:i+1000], Features[i+1000:i+1100], Label3[i+1000:i+1100])\n",
    "        print('#'*40)\n",
    "        print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "        benchmark_stats(Label3[i+2000:i+2100])\n",
    "        print('#'*40)\n",
    "        print('-'*50)\n",
    "    else:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2135 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0129 seconds.\n",
      "F1 score for test set: 0.7500.\n",
      "Accuracy score for test set: 0.6000.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7500\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6000\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2289 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0103 seconds.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2297 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0093 seconds.\n",
      "F1 score for test set: 0.7879.\n",
      "Accuracy score for test set: 0.6500.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7879\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6500\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2213 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0106 seconds.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2211 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0096 seconds.\n",
      "F1 score for test set: 0.7342.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2337 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0115 seconds.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2091 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0111 seconds.\n",
      "F1 score for test set: 0.7654.\n",
      "Accuracy score for test set: 0.6200.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7654\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6200\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2237 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0120 seconds.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2212 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0119 seconds.\n",
      "F1 score for test set: 0.7421.\n",
      "Accuracy score for test set: 0.5900.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7421\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5900\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2223 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0126 seconds.\n",
      "F1 score for test set: 0.7578.\n",
      "Accuracy score for test set: 0.6100.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7578\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.6100\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2263 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0113 seconds.\n",
      "F1 score for test set: 0.6486.\n",
      "Accuracy score for test set: 0.4800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6486\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4800\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2248 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0148 seconds.\n",
      "F1 score for test set: 0.6395.\n",
      "Accuracy score for test set: 0.4700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6395\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4700\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.1996 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0116 seconds.\n",
      "F1 score for test set: 0.7261.\n",
      "Accuracy score for test set: 0.5700.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7261\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5700\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!!!!\n",
      "Made predictions in 0.1999 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0115 seconds.\n",
      "F1 score for test set: 0.7013.\n",
      "Accuracy score for test set: 0.5400.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7013\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5400\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2233 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0104 seconds.\n",
      "F1 score for test set: 0.7342.\n",
      "Accuracy score for test set: 0.5800.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.7342\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.5800\n",
      "########################################\n",
      "--------------------------------------------------\n",
      "Training a SVC using a training set size of 2000. . .\n",
      "Model Trained!!!!\n",
      "Made predictions in 0.2216 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Accuracy score for training set: 1.0000.\n",
      "AUC score for training set: 1.0000.\n",
      "Made predictions in 0.0029 seconds.\n",
      "F1 score for test set: 0.6286.\n",
      "Accuracy score for test set: 0.4583.\n",
      "AUC score for the test set: 0.5000.\n",
      "########################################\n",
      "BENCHMARK STATS - NAIVE CLASSIFIER\n",
      "F1 score for predicting all +1 on the test dataset: 0.6286\n",
      "Accuracy score for predicting all +1 on the test dataset: 0.4583\n",
      "########################################\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Tuning SVC with train size of 2000 and test size of 100\n",
    "parameters = {'kernel':('linear', 'rbf','sigmoid'), 'C':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "              'gamma':[.000001,.000005,.00005,.0005,.001,.005,.01,.02,.04,.05,.1,.3,.5]}\n",
    "svc = SVC(random_state=3)\n",
    "gscv = GridSearchCV(svc, parameters,cv=10,n_jobs=-1)\n",
    "for i in range(0,3525,100):\n",
    "    if(len(Features[i+2000:i+2100]==100)):\n",
    "        train_predict(svc, Features[i:i+2000], Label[i:i+2000], Features[i+2000:i+2100], Label[i+2000:i+2100])\n",
    "        print('#'*40)\n",
    "        print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "        benchmark_stats(Label[i+2000:i+2100])\n",
    "        print('#'*40)\n",
    "        print('-'*50)\n",
    "    else:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random forest tuning\n",
    "parameters = {\"criterion\":[\"entropy\",\"gini\"],\"max_features\":[\"sqrt\",\"log2\",10,20],\n",
    "              \"max_depth\":[10,15,20,None],\"min_samples_leaf\":[1,5,10,15,20]}\n",
    "RF = RandomForestClassifier(n_estimators = 1000,oob_score=True,n_jobs=-1,random_state=42)\n",
    "gscv = GridSearchCV(RF, parameters,cv=10,n_jobs=-1)\n",
    "for i in range(0,3525,100):\n",
    "    if(len(Features[i+2000:i+2100]==100)):\n",
    "        train_predict(gscv, Features[i:i+2000], Label1[i:i+2000], Features[i+2000:i+2100], Label1[i+2000:i+2100])\n",
    "        print('#'*40)\n",
    "        print(\"BENCHMARK STATS - NAIVE CLASSIFIER\")\n",
    "        benchmark_stats(Label1[i+2000:i+2100])\n",
    "        print('#'*40)\n",
    "        print('-'*50)\n",
    "    else:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I strongly believe and also research supports that tuning Random forest parameters will give significant results. But grisearch with RandomForest takes a lot of time. I tried to run it and it kept running for more than 2 hours. However, I have included the code for the same above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a pattern of decreasing accuracy indicating that more and more people are trying to use Machine Learning for trading and hence it is unable to find pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Features_label2 = [\"HSI_Returns\",\"AXJO_Returns\",\"SSE_Returns\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kalman filtering is a good technique to extract the true trend. We re-write the index as a local level model.\n",
    "\n",
    "                                                        yt=t+t\n",
    "                                                        t=t1+t1\n",
    " \n",
    "where   and   are white noise.\n",
    "\n",
    "Kalman filtering progresses through time and filters the state out of the index time series.\n",
    "\n",
    "\n",
    "The Kalman Filter is a unsupervised algorithm for tracking a single object in a continuous state space. Given a sequence of noisy measurements, the Kalman Filter is able to recover the true state of the underling object being tracked. Common uses for the Kalman Filter include radar and sonar tracking and state estimation in robotics.\n",
    "\n",
    "The advantages of Kalman Filter are:\n",
    "\n",
    "1. No need to provide labeled training data\n",
    "\n",
    "2. Ability to handle noisy observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqYj4f6hQDqWsPBHSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a12ea7da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sp = SPData[['SP_Close']]\n",
    "kf = KalmanFilter(transition_matrices = [1], observation_matrices = [1])\n",
    "measurements = sp.values.flatten()\n",
    "kf = kf.em(measurements, n_iter=3)\n",
    "(filtered_state_means, filtered_state_covariances) = kf.filter(measurements)\n",
    "(smoothed_state_means, smoothed_state_covariances) = kf.smooth(measurements)\n",
    "plt.plot((sp.values), 'ro', markersize=5, label='Observed')\n",
    "plt.plot((filtered_state_means), linewidth = 2, label = 'Filtered')\n",
    "plt.fill_between(range(len(filtered_state_means)), \n",
    "                 filtered_state_means.flatten()-filtered_state_covariances.flatten(), \n",
    "                 filtered_state_means.flatten()+filtered_state_covariances.flatten(), alpha=0.3, color='cyan')\n",
    "plt.title('Kalman filtered S&P 500 Series')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Index Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kalman filter performed really well because KF takes into consideration all the past information available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of Kalman filtered time series at the tail of the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a12f7f9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot((sp.values)[-100:-1], 'ro', alpha = 0.6, markersize=5, label='Observed')\n",
    "plt.plot((filtered_state_means)[-100:-1], linewidth = 2, label='Filtered')\n",
    "plt.fill_between(range(99), \n",
    "                 (filtered_state_means.flatten()-filtered_state_covariances.flatten())[-100:-1], \n",
    "                 (filtered_state_means.flatten()+filtered_state_covariances.flatten())[-100:-1], \n",
    "                 alpha=0.2, color=sns.color_palette()[3], label='Spread')\n",
    "plt.title('Kalman filtered S&P 500 Series (2017-07-27 - 2017-12-14)')\n",
    "plt.xlabel('Date (day)')\n",
    "plt.ylabel('Index')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88548693997578276"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_kf = sp.values.flatten()\n",
    "observed_kf= observed_kf[1:] > observed_kf[:-1]\n",
    "\n",
    "# daily trend of the filtered result\n",
    "fil_kf = filtered_state_means.flatten()[1:] > filtered_state_means.flatten()[:-1]\n",
    "\n",
    "# Get the accuracy\n",
    "kf_match = (observed_kf == fil_kf)\n",
    "np.mean(kf_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved predicting power of 88%. Thats pretty commendable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try Kalman filtering on the open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAobIRM5dqgCmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16a7add8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sp = SPData[['Open']]\n",
    "kf = KalmanFilter(transition_matrices = [1], observation_matrices = [1])\n",
    "measurements = sp.values.flatten()\n",
    "kf = kf.em(measurements, n_iter=3)\n",
    "(filtered_state_means, filtered_state_covariances) = kf.filter(measurements)\n",
    "(smoothed_state_means, smoothed_state_covariances) = kf.smooth(measurements)\n",
    "plt.plot((sp.values), 'ro', markersize=5, label='Observed')\n",
    "plt.plot((filtered_state_means), linewidth = 2, label = 'Filtered')\n",
    "plt.fill_between(range(len(filtered_state_means)), \n",
    "                 filtered_state_means.flatten()-filtered_state_covariances.flatten(), \n",
    "                 filtered_state_means.flatten()+filtered_state_covariances.flatten(), alpha=0.3, color='cyan')\n",
    "plt.title('Kalman filtered S&P 500 Series')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Index Open')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a171424e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot((sp.values)[-100:-1], 'ro', alpha = 0.6, markersize=5, label='Observed')\n",
    "plt.plot((filtered_state_means)[-100:-1], linewidth = 2, label='Filtered')\n",
    "plt.fill_between(range(99), \n",
    "                 (filtered_state_means.flatten()-filtered_state_covariances.flatten())[-100:-1], \n",
    "                 (filtered_state_means.flatten()+filtered_state_covariances.flatten())[-100:-1], \n",
    "                 alpha=0.2, color=sns.color_palette()[3], label='Spread')\n",
    "plt.title('Kalman filtered S&P 500 Series (2017-07-27 - 2017-12-14)')\n",
    "plt.xlabel('Date (day)')\n",
    "plt.ylabel('Index')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89396298218301329"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_kf = sp.values.flatten()\n",
    "observed_kf= observed_kf[1:] > observed_kf[:-1]\n",
    "\n",
    "# daily trend of the filtered result\n",
    "fil_kf = filtered_state_means.flatten()[1:] > filtered_state_means.flatten()[:-1]\n",
    "\n",
    "# Get the accuracy\n",
    "kf_match = (observed_kf == fil_kf)\n",
    "np.mean(kf_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It can be observed here also that Kalman filter gives better results for Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating helper functions to use them for classification\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "def LinearSVM(X_train, y_train, X_test, y_test, parameters):\n",
    "    clf=LinearSVC(loss=\"hinge\",C=parameters[0])\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return clf, accuracy\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RandomForest(X_train, y_train, X_test, y_test, parameters):\n",
    "    clf = RandomForestClassifier(n_estimators=parameters[0],n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return clf, accuracy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def LogRegress(X_train, y_train, X_test, y_test, parameters):\n",
    "    clf = LogisticRegression(C=parameters[0])\n",
    "    clf.fit(X_train,y_train)\n",
    "    accuracy = clf.score(X_test,y_test)\n",
    "    return clf, accuracy\n",
    "\n",
    "from sklearn import neighbors\n",
    "def KNN(X_train, y_train, X_test, y_test, parameters):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=parameters[0])\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return clf,accuracy\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def GNB(X_train, y_train, X_test, y_test):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return clf,accuracy\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "def AdaBoost(X_train, y_train, X_test, y_test, parameters):\n",
    "    n = parameters[0]\n",
    "    l =  parameters[1]\n",
    "    clf = AdaBoostClassifier(n_estimators = n, learning_rate = l)\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return clf, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask(df, features,y,start_test):\n",
    "    '''\n",
    "    To separate dataset and get X_train, X_test, y_train, y_test\n",
    "    '''\n",
    "    X=df[features]\n",
    "    y=df[y]\n",
    "    X_train = X[X.index < start_test]\n",
    "    y_train = y[y.index < start_test]    \n",
    "    X_test = X[X.index >= start_test]    \n",
    "    y_test = y[y.index >= start_test]\n",
    "    return X_train, y_train, X_test, y_test \n",
    "\n",
    "def classifier(X_train, y_train, X_test, y_test, method, parameters):\n",
    "    '''\n",
    "    To call different classifiers\n",
    "    '''\n",
    "    if method == 'RF':   \n",
    "        return RandomForest(X_train, y_train, X_test, y_test, parameters)\n",
    "    elif method == 'SVM':   \n",
    "        return LinearSVM(X_train, y_train, X_test, y_test, parameters)\n",
    "    elif method == 'LOG':\n",
    "        return LogRegress(X_train, y_train, X_test, y_test, parameters)\n",
    "    elif method == 'KNN':\n",
    "        return KNN(X_train, y_train, X_test, y_test, parameters)\n",
    "    elif method == 'GNB':\n",
    "        return GNB(X_train, y_train, X_test, y_test)\n",
    "    elif method == 'ADA':\n",
    "        return AdaBoost(X_train, y_train, X_test, y_test, parameters)\n",
    "\n",
    "\n",
    "#In time series, we cannot shuffle the dataset, we have to incrementally validate. \n",
    "#In the below function we split the data into k folds. As we move forward we train our data on all the previous data \n",
    "#available. So for example we will use the first fold on first iteration and test on fold 2. For second\n",
    "#iteration we will train our model on fold 1+ fold2 and test on fold 3 and so on. So as we move forward we make\n",
    "#sure that all past information is incorporated\n",
    "def CV(X_train, y_train, folds, method, parameter):\n",
    "    '''\n",
    "    To get the average score of cross validation\n",
    "    \n",
    "    '''\n",
    "    k = int(np.floor(float(X_train.shape[0])/folds))\n",
    "    acc = np.zeros(folds-1)\n",
    "    for i in range(2, folds+1):\n",
    "        split = float(i-1)/i\n",
    "        data = X_train[:(k*i)]\n",
    "        output = y_train[:(k*i)]\n",
    "        index = int(np.floor(data.shape[0]*split))\n",
    "        X_tr = data[:index]        \n",
    "        y_tr = output[:index]\n",
    "        X_te = data[(index+1):]\n",
    "        y_te = output[(index+1):]        \n",
    "        acc[i-2] = classifier(X_tr, y_tr, X_te, y_te, method, parameter)[1]\n",
    "    return acc.mean()  \n",
    "\n",
    "#the below function searches for the best parameter\n",
    "def SearchGrid(X_train, y_train, folds, method, grid):\n",
    "    '''\n",
    "    To get the best parameters for a given classifier\n",
    "    '''\n",
    "    param = list(grid.keys())\n",
    "    finalGrid = {}\n",
    "    if len(param) == 1:\n",
    "        for value_0 in grid[param[0]]:\n",
    "            parameters = [value_0]\n",
    "            accuracy = CV(X_train, y_train, folds, method, parameters)\n",
    "            finalGrid[accuracy] = parameters\n",
    "        final = sorted(finalGrid.items(), key=operator.itemgetter(0), reverse=True)          \n",
    "        return final[0]\n",
    "    elif len(param) == 2:\n",
    "        for value_0 in grid[param[0]]:\n",
    "            for value_1 in grid[param[1]]:\n",
    "                parameters = [value_0, value_1]\n",
    "                accuracy = CV(X_train, y_train, folds,method, parameters)\n",
    "                finalGrid[accuracy] = parameters\n",
    "        final = sorted(finalGrid.items(), key=operator.itemgetter(0), reverse=True)\n",
    "        return final[0]\n",
    " \n",
    "#this function below searches for the best classifier\n",
    "def cv_optimize(X_train, y_train, X_test, y_test, folds, method, grid):\n",
    "    '''\n",
    "    Return to a best classifier\n",
    "    '''\n",
    "    if grid==[]:\n",
    "        best=classifier(X_train, y_train, X_test, y_test, method, grid)\n",
    "    else:\n",
    "        param=SearchGrid(X_train, y_train, folds, method, grid)[1]\n",
    "        best=classifier(X_train, y_train, X_test, y_test, method, param)\n",
    "    return best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def make_roc(name, clf, ytest, xtest, ax=None, labe=5, proba=True, skip=0):\n",
    "    initial=False\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "        initial=True\n",
    "    if proba:\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n",
    "    else:\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if skip:\n",
    "        l=fpr.shape[0]\n",
    "        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    else:\n",
    "        ax.plot(fpr, tpr, '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    label_kwargs = {}\n",
    "    label_kwargs['bbox'] = dict(boxstyle='round,pad=0.3', alpha=0.2,)\n",
    "    if labe!=None:\n",
    "        for k in range(0, fpr.shape[0],labe):\n",
    "            threshold = str(np.round(thresholds[k], 2))\n",
    "            ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n",
    "    if initial:\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict=datetime.datetime(2015,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 1: Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataR = DataTemp.copy(deep=True)\n",
    "DataR[DataTemp.columns[:-3]] = scaler.fit_transform(DataTemp[DataTemp.columns[:-3]])\n",
    "DataR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGdoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a20748f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test=mask(DataR,DataR.columns[:-3],'Target1', predict)\n",
    "ada=cv_optimize(X_train, y_train, X_test, y_test,10, 'ADA',{'n_estimators':[10,20,50],'learning_rate':[0.8,1.0,1.2]})\n",
    "log=cv_optimize(X_train, y_train, X_test, y_test, 10, 'LOG', {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "svm=cv_optimize(X_train, y_train, X_test, y_test, 10, 'SVM', {\"C\": [0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "rm=cv_optimize(X_train, y_train, X_test, y_test, 10, 'RF', {\"n_estimators\": [10,20,50,100]})\n",
    "knn=cv_optimize(X_train, y_train, X_test, y_test, 10, 'KNN', {\"n_neighbors\": [3,5,7,9,11,13]})\n",
    "gnb=cv_optimize(X_train,y_train,X_test, y_test, 10,'GNB',[])\n",
    "with sns.hls_palette(8, l=.3, s=.8):\n",
    "    ax=make_roc(\"ADA\",ada, y_test, X_test, labe=100, skip=3,proba=True)\n",
    "    make_roc(\"SVM\",svm, y_test, X_test, ax,labe=100, skip=3,proba=False)\n",
    "    make_roc(\"LOG\",log, y_test, X_test, ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"RM\",rm,y_test, X_test,ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"KNN\",knn,y_test, X_test,ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"GNB\",gnb,y_test, X_test,ax,labe=100, skip=3,proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Close data we are getting slightly better results. Lets try the same thing for Open data and using features as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 2: Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16a50358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test=mask(DataTemp,Features_label2,'Target2', predict)\n",
    "ada=cv_optimize(X_train, y_train, X_test, y_test,10, 'ADA',{'n_estimators':[10,20,50],'learning_rate':[0.8,1.0,1.2]})\n",
    "log=cv_optimize(X_train, y_train, X_test, y_test, 10, 'LOG', {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "svm=cv_optimize(X_train, y_train, X_test, y_test, 10, 'SVM', {\"C\": [0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "rm=cv_optimize(X_train, y_train, X_test, y_test, 10, 'RF', {\"n_estimators\": [10,20,50,100]})\n",
    "knn=cv_optimize(X_train, y_train, X_test, y_test, 10, 'KNN', {\"n_neighbors\": [3,5,7,9,11,13]})\n",
    "gnb=cv_optimize(X_train,y_train,X_test, y_test, 10,'GNB',[])\n",
    "with sns.hls_palette(8, l=.3, s=.8):\n",
    "    ax=make_roc(\"ADA\",ada, y_test, X_test, labe=100, skip=3,proba=True)\n",
    "    make_roc(\"SVM\",svm, y_test, X_test, ax,labe=100, skip=3,proba=False)\n",
    "    make_roc(\"LOG\",log, y_test, X_test, ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"RM\",rm,y_test, X_test,ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"KNN\",knn,y_test, X_test,ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"GNB\",gnb,y_test, X_test,ax,labe=100, skip=3,proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 3: Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XeYnFXd//H3md779t7SE9IgCSX0\noohAEAR5sIGAggWVn2JBRBFFVIqI8DwiCihNilKlg4SE9J7sbnazvU7v9fz+2BATEtYQs9kknNd1\nebEzc88933vA/ey5TxNSShRFURTlg2jGuwBFURTl4KaCQlEURRmVCgpFURRlVCooFEVRlFGpoFAU\nRVFGpYJCURRFGZUKCkVRFGVUKigUZRRCiG1CiKQQIiaE6BdC3C+EsO30+tFCiFeFEFEhRFgI8Q8h\nxJT3ncMhhLhNCNG5/Tyt2x/7DvwVKcqHp4JCUf6zs6SUNmAmMAu4DkAIsQD4J/A0UA7UAWuAt4UQ\n9duPMQCvAFOBMwAHcDTgB446sJehKPtGqJnZivLBhBDbgMuklC9vf3wLMFVKeaYQ4i1gnZTyK+97\nz/PAkJTys0KIy4CbgAYpZewAl68o+4VqUSjKXhJCVAIfA1qFEBZGWgaP7eHQR4FTt/98CvCCCgnl\nUKaCQlH+s6eEEFGgCxgEfgR4GPn/T98eju8D3ut/8H7AMYpyyFBBoSj/2TlSSjtwAjCJkRAIAgWg\nbA/HlwHD23/2f8AxinLIUEGhKHtJSvkGcD9wq5QyDrwDnL+HQy9gpAMb4GXgdCGE9YAUqShjQAWF\nonw4twGnCiFmAt8FPieE+JoQwi6EcAshfgosAH68/fgHGLll9TchxCQhhEYI4RVCfE8I8fHxuQRF\n+XBUUCjKhyClHAL+DPxQSvkv4HRgESP9EB2MDJ89VkrZsv34NCMd2puBl4AI8C4jt6+WHvALUJR9\noIbHKoqiKKNSLQpFURRlVCooFEVRlFGpoFAURVFGpYJCURRFGZVuvAv4sHw+n6ytrR3vMhRFUQ4p\nK1asGJZSFu3Lew+5oKitrWX58uXjXYaiKMohRQjRsa/vVbeeFEVRlFGpoFAURVFGpYJCURRFGZUK\nCkVRFGVUKigURVGUUamgUBRFUUY1ZkEhhLhPCDEohFj/Aa8LIcQdQohWIcRaIcTssapFURRF2Xdj\n2aK4HzhjlNc/BjRt/9/lwN1jWIuiKMphzx9IsLllmFA4BUBsoJ9g21Y2tC1HY9LY9/W8YzbhTkr5\nphCidpRDzgb+LEfWOV8ihHAJIcqklGp/YUVRlA+ppz/CXfcvRysEXrek0ttLYMWbvJsY5i1LM1qr\ndp9mZcP4zsyuYGTnr/d0b39ut6AQQlzOSKuD6urqA1KcoijKoUBKSUt7gKdf2Iy/30+JL8Kz67ei\nc/ayYaiZsN+Pq16HyMncvn7GeAaF2MNze9xFSUp5L3AvwNy5c9VOS4qifGT1D8VobQ+i1Y78Cu3q\n9PPq6xsJRgIMRZMMiwJai4X1W4cI2epoamxEeDL06VuN+/qZ4xkU3UDVTo8rgd5xqkVRFOWglEqE\nSMb9mK1e4ikDt927lHQmD7k0M+sE3cNdBHMRiiZqkL0aps2cwDZDB7JmJtFsmrJCO2mNk81C7HOf\n9HgGxd+Bq4UQDwPzgLDqn1AURfm3VCLEplV/I5UIIpG0BJpo7+ihujhBIJakLZ7CUqklORhkyaoB\n/PEscdtKFsxtYlqllg1DOoIRG5X2cjT5XHZf6xizoBBC/BU4AfAJIbqBHwF6ACnl74HngI8DrUAC\n+MJY1aIoinIoCva1MdC2Gp3RTI+/l0c2t9AXs9KhTVPnLKZhUjlrN77BtuAmogU3DTOK+OKZp7Nw\nwtGYjXa2DXXyxDv/i0XXi5CysK91iJFBR4eOuXPnSrXMuKIoh4NoKkQk6cdh9mI3uXY8L6XE37OV\nNx76KdvCGwmjp0XU0BEtwVMTBX2OKcVWetYHePb1VdROq+Tck49nVmMFJ05etMu5hgMdDAbbmDHx\npHW5nJyxL3UecvtRKIqiHA6iqRDPrvkj8XSYeExSaZ+Dz23FbJUMDnTy1puP0eMfIqe1osmUMByY\njNRnCPZkqJ6qRW+rZOaC46kpW8hVF58LMr5b4AD4PDX4PDXk82T2tVYVFIqiKOMgEOtnKNKDNlvE\nv15LY9X2g9Tj9kQIhruIRp2Ysm58eivGfC1F5dMpGHp54u1NJOJaZnzKw1lHHM3Ej1cgxJ4Gke4/\nKigURVEOsFA4xcp1A7S36EiGdYQjGkzOHNFAhGKHjgVN5RjyBSq8FWjzeSzFC/jqTx5lXXsHnmI3\nFxx3PJcffTZeq/eA1KuCQlEUZYyFwin6h2JoNIJAKMlTL2ymbaCNZKGMpkZBkSWNU+SZMKGGRadX\nkolvwlsyH5ujhH8tW8s5l11GzuDg3HPP4YavfomJ1cUHtH4VFIqiKGMoFE7x+wdWMDgcJy/zeEq0\ndER60LmG8CUMzLJ5mXb2TExFdVjtWZqX34NGpyOby2MzVZAuqeXIhcfzw6u+wsKZR6AZ49tMe6KC\nQlEUZQytXN/L2uZeiit0ZMlgL9Kg29YNkSSNnhpOPvFEyusryKSibF77NJlMmn++1cLGobe59KsT\naapq4pm778Ks14/bNaigUBRF2U8KBUk0niESTdMXCLF0y0aefamF4cE8/WEN9SVZHCVhauu3YrHW\nUV+Xwl5uJZ2K0LPtXd5dsYEHnnkJf0HLzClTmFlewcTysvG+LBUUiqIo+yIUTrGtO4xOK5BAJJom\nEkvhT4QZTgQJJIdZuXUpybyWqsoIpkQ5s2tcVDfVYpAWGktn4I/2MRzqILStlZ/c8TueW9lNQ2MD\n1131Oc494VSsNs94XyaggkJRFOVDC4VTPPD4Wto6Q2g0gjlzitFaUyREFINPMMFiZGCgl0iojf7W\nInLxPF5jnDNO/DRF9eW8ueVJhiI9pBMh2ja/w2DWTnPMylVfupIfXHkFbqtlvC9xFyooFEVRPoRQ\nKsLbLZvZOtAJRh0aC6TsA5SW6KlIabFF06QGu1g2uJgcQ7gnBbAUXEwWcdrW/BGh/Ri12iLeWf0q\nry9+k8nzTsHnreLJe35LY2nVmM+J2BcqKBRFUfZSKBXhj6sfZ8mWpWxosWLDzOQaNwzqyAylGSJH\nwGAkZc7jKC1jsm0B65f9A08qgEtfQU6mGOxr5+6/vMjr69ZQXePlBFsFMzxGfLrsQRkSoIJCURRl\nr+QLed7tWcfa3vXEMl3YfD6KpJYFNZIaWzVOXwPu0kqsDg/ZXIYlzc/Q0/YOZqsGh8ZMcdMRrNzU\nwc2/+DXhnIYLzzmX/zmhFq9Fj0ajwXyAJs/tCxUUiqIoH2B4oIPB/jaE1cnWYA9butcx2LeRRDqI\nyFuZN30S5531Jby+3XfeDFpqKGjWUTFpPtqCloyzib88sJrS+kn8+bvf4dSjjiSTDO/Ya8Jkce2h\ngoODCgpFUZQ9GB7o4E8PX0drvJdQIUNj6RTK7S6O9BSTyc2kN2bnyCkL9xgSgcEWdPk8xbYann3x\nbcpnHU1NcQW33PgzjqyrwWoc2WzOZHEd1AHxHhUUiqIo71PI53nulSd4s3sQm9OMV6NldsmR1Ew4\nhjfXv8mylTlSKdiyUTBvUgqX0wSMbDTU372aRGyI9c1DXPebpwnlMnyu5GguOLOBEpttnK9s36ig\nUBTlsJbP50kkEmSze7fB2/BAD8+//TxPvtFOIFiOS2tHX1YgUFFLdlOK3GA9hnwfk+qLkNkcW9t7\nqat2kUqEWbfsIQZ6W3h15WYeeydESXkNd3zrW1x4+qloNfu8E+m4U0GhKMphK5PJsH7lCrKRCNr/\nMKIon8uyfssyNvatoSMUQjNcQqPNhENrYm5VLdWWFCbtAN7iPNmeNIWhLhJ+Qaw4RtuQgeBQK80b\nV/OvLf1s6vJz0Tmf5JbrbsRjPzRbETtTQaEoymGpUCiwftVKDMkE5SUlox470N/Jss2vsS64Gr0d\n3HkjwlyJx6VjYk0dp58wE7vNuOP46tISwtE0TrsRu83ImjWr6BjqIGn1MX9eLafMSdM07TgMB+do\n1w9NBYWiKIelVCpFOhweNSSG/SHefPdttoVaSIsENkMFTmp5d1sfBk0OrVbHvFk1u4QEgN02EhCx\nWIwbf3k7S9Yvpb6xnis+fzkVFiM2q5tgNEk4HMZ2iPZL7EwFhaIoh6VsNjvq7aYNmzbwh78tYzAa\nwKDXUt/gwmJ0kUpKfA4P05pq0BXsGLW7L6chpeS5F1/k9j/9GWnIs2DWdL5w/v9QV9G44xhtIks2\nnR6TazvQVFAoivKREouFeXvNSzz9+npee3kxkYifo+efwMRTFjBv+jTyGSMrVkfQCyMavYaNzev4\nwjW/JZvNMmPyZH71o+t59Pnn+fldd5OMR3DbbSxevJ4zj49SV7HrZ0kpx+ci9zMVFIqifCRIWaC1\nfQP/Wv8Oq9p70Oj0HHvs8QwMdKHVgcutw2evwGKw47OnCUfT2K16Tjr/azx67z1Ul5dx3c9v4VcP\n/YWjFhzJZRefxWmzG/B5KxiM6LniO9/lX089Od6XOSZUUCiKctgIhVP4g0m8bjM733QKhoZYvn4p\nHf0DrG3OkcuVU11WyuSFOV5/OYvP5eSYySdjMdgBMOoyOE0RYnGJwWBgaHCAb95wA/54AvvWFo6f\nZOToqiyx4RZq646kY7DroF2naX9QQaEoymEhFE7x+LMbCYTSFAoFjpjsZGDLAEuXbaRnoIeCzJPH\nhsPkxelJoxFpwECx243L7t4REplUlLZN/ySdjhKPxRj2D/LdW2+kvKIUo8FEd08/It6D3uLm3fXd\nfP1XnyUYjvLAnXeM7xcwhlRQKIpyWPAHkwwOJygUJP2BMKFMG7GtS/DYdHiL9HiLPNgtRfR3WEHk\nycoU8yc10rK6f5fzpJIhoqFeQsk8T725mLqGUoaHEmgKQY6fN5eh4Qh2VwUajZ4T5/v4/CXXsGJD\nM7f87nc8es8943T1Y0sFhaIohwWDJcNAYIislHRmNmHOt6E191NT5UOvl6T1UTrWDPHo08+TL0ju\n+/VvKHHvvmKrPzBIVzROwlCMt2ICn734XOZNnwPA64vfoWcgSNPUM0knwxjNTgwmOwvmzOHrXd34\ng0G8bveBvvQxp4JCUZRDXjQV4u/L/0JrpJ+Eph9TeZJSt5do0kQ0F6XaVIzZ4OTYc47jy5d8ASnz\n5PNZsukYuVyKTLrA8GA7f3r4QZp7NzJzzhxq7Bqu+Z8rycuR4bHpTIa77r+fr192KQaTnZ7BILWu\nkTkSazdtIpvN4nEd/Av87QsVFIqiHNSy2SypVOoDh5omsyleXvcmDz7aQjKsxeMzUDulGLfbh6Y3\ngwi20R/wIwBP1krA2EJB5gmEolz5w9tJJFMUZIHf/N8fmT27lukTSnjmqSV870tnowPuvP9PvPTW\nW8hCgc+efz7HHnUUAM++8gqP/eMZ9DodJpOR39/yi8O2Q1scauN8586dK5cvXz7eZSiKcgAMDg7S\nsno1OgHv/xWcyWXoiw3TN9zF1s2dLF8bwOcx4vN4WTBnChSGGFi/GlM+iDCaEfk8Rb4mzDYfWo0W\nodUipeAPj/6Ndb0DlFZWceVnLqDOEQYp0Wg01DSdiMFk36fahwMBrNU11DU0/PdfxH4ghFghpZy7\nL+9VLQpFUQ5Kfr+flpUrqPR6MRoMO57P5DN0RwYYSAyQDPVTmZWYnA2EytyUFRlwmq00OfJohB1n\nRT1mGUGj0SI0Gsqq5qA3WpBSkshk6Y5GKS6t5OPlNZx1zjnMmjGdTCq6S//DvioUCuj0+v3xVYw7\nFRSKohyUBnt78VqtO0Iik8/QExmkPz5MKhzCFIhTg45gQUdHZBivZzOVdhs+mxG3+0ScnnqScSsO\nTQEtWfRGG3qjhS0tLfzxscc5+cxPUFlWymXnLcJhMtI+HCCTzWIw2f+rgICRpc3j2SyVh8E6T6CC\nQlGUg1Q2ncKm15PNZ+mODtAfGyafTWMMJKjOCPQWB6vbVvDWei2BTBCHM0dFZQZnUQVmswejyUb9\n5Cm0bViPWWMgHIzw6DMPsXzjZqw2OzIeo9xsglyWSCxLMpFgyO/HYjb/V3Xn83miqTTlkyfj8Xj2\n07cxvsY0KIQQZwC3A1rg/6SUP3/f69XAnwDX9mO+K6V8bixrUhTl0JDN5+kI9RAuxCgUJJZkno1v\nrub2x56ggGDu9IlUllWQ1Vko9mYwFDwkEmmyMsfL76ziK987i+cfepCJM2bwm7t/z/8+/Ah5KbFa\nLHxt0Xkce/wJu3yetgC6omJ0lt0XAfwwzAYDpQ4HPp/vvzrPwWTMgkIIoQXuAk4FuoFlQoi/Syk3\n7nTYD4BHpZR3CyGmAM8BtWNVk6IoB79MPkt7qJsV/euxZXOUWZ1Yg3FSwSF++ddHuPwzlxCK9fKX\np1/k3NPTlHtmEs97sTo8lJZDRdWx/Ozum5g9fToFKRlIZYibzMydP59vXnYp9WVlnHzBp/nSJZeg\n0/37V2DBaqVx4kSsVus4Xv3BaSxbFEcBrVLKNgAhxMPA2cDOQSEBx/afnUDvGNajKMo4k1LS3dVF\nJBgkn9t1a9JsPk9vdID++DC5QoFoczcaf5itiQLxfJ5lW1aiKeh4c/kmdIYsExrcDPbEOeYMN3lN\nHQaLFq/FxS13/IHzzzyT2//vDzyzZCmnnObks5/6FLVuF0a9ns6ensN2GOtYGcugqAC6dnrcDcx7\n3zE3AP8UQnwVsAKn7OlEQojLgcsBqqur93uhiqKMPSklLZs3E+zYhttmw7z9r/lcIUd/bJi+2BD5\nQoFqsxOfzso7y54lFY3TmnCRtVgY7JNU2pw0FqeRWR1xYScTzzChuAadcaRfoa2zk+G2rfytpYVB\nv5/ujg6mlxRhN5pYuW4d1/zoBrr7+rjzpp/u0ppQRjeWu33vKbLfP2njIuB+KWUl8HHgASHEbjVJ\nKe+VUs6VUs4tKioag1IVRRlrfr+fwLZ2qktLcdjtGE16/NkQm8PtDGdClLp8zKudwYyKSRQ6OtFm\nMwhPNRmM2AwZXFYtRr0GpAGrw4vb7cLjLsfhdGMxmUglk9z069sIROOYLRYmFPm45MwzsRtNAMye\nPp03nvgbzz/0IHf+4T5Sh8mmQgfCWAZFN1C10+NKdr+1dCnwKICU8h3ABBw+PUCKouyQTCSwGAwU\nyNMd7WdF30a6wv04DDZmlE6kzlpEaqCTbYtfIRnykzdZ6Q/FSOdCaLVpirwudLoskyeXceyRE3Ca\nyigtKgMgns7wwtJlhKJR4tEIwf5+Qv5hvvK961i9YcMudUyor8diNrO5tXU8voZD0li2vZYBTUKI\nOqAHuBD4zPuO6QROBu4XQkxmJCiGxrAmRVHGSSaTZiAxTEeml2w+j9vsoNJRit1gJRn3s37Z4wxs\nWksulUBrqGFz2kMmmcRk11FR46DekOT15UOEk714s2beWrKMz563iOffXkxFQwOzZs9iwfRp1FWU\nA/C1H/6Iz3/5y8ycOpXOnh7KS0rQ6XR09faytWMbVeXl4/yNHDrGLCiklDkhxNXAi4wMfb1PSrlB\nCHEjsFxK+XfgW8D/CiGuYeS21OflobamiKIoo8oX8nSG+1jas5Z0eIDa0goqfaUYC5JEdIi/vvoE\nv7znj+QyKY6qK+G4mVMJR4qJp3WUldkYTrTQGWtha283G/0x/vLgu5h1y9FbbFxzx10UCgW8bjc3\nfPlyFkyfvscalq5axW/v+yN6nQ6h0XDzdd87LFd5HStqrSdFUcZEvpCnK9JPW7CLdD5LZihKSThP\nTWklsWg/Wze8wEBvP1//9XOcuWARGr2Bfy5+nIuOP4apVdNoS+jIZ/uJZwPUVgnuefRN8gXJqQsm\n0dU/QOe2ODMnTeGKC84nEIlyxU9/xqv33r3j84dDIWyV1VSUle1VvR1DQ0xbcPRhOzxWrfWkKMpB\noyALdIb7aA91k8plsGu01BpsRHQ5YrF2+jsHCPS1EuxqZWNrDrvVRW3TVExWJ+j9YDdw8gWnol3+\nBgm/Ea3RzdMvLeOTJx/Js6+u551lW6kqLuO7l17M7KmTAfA4naSz2ZElOPZxfaXC9oUAld2poFAU\nZb8oyMKOFkQql8FtclBrsNK95inakmH6+wM4CiVInRVt0oDVUkJOP4jN6sFgcVBa4sZkmsGG5g10\nJzuwugyUGeoYDkUYGHydS84/iRfeauH0BQu5+GNn7BIILy1ZyuS62n0OiUQyCVodRqNxP30bhxcV\nFIqi/FcKskB3ZIC2YBfJXBqnwUKtxYIuGcY/0EwqEcLhrKS/PUQhkcVaUYy9toI6l5Wl/U9QXBzn\ntOMn4vNYePKfKxiK9hBLhZg95RheefF1rrvlVsrdbiKBCAaNhukNDeSyOXLZHABbu3v41QMPcee1\n3yaRSO6oK5lMIeJxorHYB9YupSSTzRLJ5Zl61FGqRfEBVFAoirJPCrJAT3SQtmAn4ZgfTTpKpdGB\nPZMgLwvoTA6KSmcQ7ukivK0TkRN4qhopmzELodUx5I+Rl0VEEyGM9gA90a28te4VhFHS6+/m0UcW\n8/LiFUTTGXqjMW783d0EQmG+dfud/OI71zK5oYFBv5//99u7+MHXrqakrpad53rnMhkyVhsZ2+gr\nwVqsVmpKSrDb/7sVYw9nKigURflQpJT0RAfZGuwgkU0jUhEKzW9gKmQZ1ujxzjwHr28Cid4hwl2d\nFFunYai2U2lyUwhECUYzbNjSw7I1faSzZlo72njk1YeweSQrl7Xxta9dwh/+9k/8PVnOPOUkvvH5\nz+Pe/kt80aWXcf03r2Hm1KmEI1G+9P0fcP23vsknTtl9UQe734+rsYkqtZrDf00FhaIoe0VKSW9s\nkNZAJ4lsCk06hiM6jCEVJiIERVWzyaQT5IIp+ttXIfN57BUVuOsb0ZvNbGtro7NtkBdea2EoEGYw\nGKZhYo6jj1nA/b9/g7zMMefoaaTtdjIhwaITTuEbX/jSB9Zz3yMP097ZxW33/i+33fu/ADz8+7vx\nHSZLex9M1PBYRVFGJaWkLzZEa7CTeCaJUUocyTBDm15EbzCTyTtI5xxYRAptKkC5by6eikY8TU0Y\nrDaC8WE6hprp3tbPsuc30dKWxOQZZLBXi8enwWU3EslsZnVrG2ee8CmOnT2dRm8pdpPzv6p7cHgY\nd9ME1aLYbsyHxwohDEC1lFLNeVeUjwgpJf3xYVoDncQyCWwGC1Oc5fibX6evYxmxUA/VUy7ipRd6\nyCU1yLyVhUdNIu6bShwLrRuChOLtvLLuCdLZJKFAkmyLhkLeQnLAwoRaFwVDN4uXLiUYizBr4lQW\nzTuOiuKS/VJ/tpDHoEYx7Rf/MSiEEGcCvwYMQJ0QYibwIynluWNdnKIoB1YoFWE4ESQvCwwlgkTT\ncawGMzNLJ+ESOjZvWMz6dc3YHT6CsRhr/r6K9h4rVRVFZM0eQsYaXHkdhlyBgkjSEV6M0R5kZuUR\ndPdE6Y0lmVzqYUP7VrYOLad9sAWTdHL95V/n1GOO2X/XEYmQM5pxuVz77ZwfZXvToriRkeXBXwOQ\nUq4WQjSOaVWKohxwoVSEB9b+nb7YEOl8lpNq5zGrdDJltiLSyTCLX3uIp1/ppr8/ipQeJpSWU1Fa\nh9bjw+y147Q4OOeMiVisMBTp5eWNj5M0dKN3BrA4G2iyWLFmp9K2tZmkzorNXcEMo5NLz/s0FrOJ\njsHB/XIdeSnRW6zMmDtHzYvYT/YmKLJSytD7Nvo4tDo2FEUZVa6Q453uNbSFuim3F6NBMNFbS7m9\nGIBIeIh3V3XT22fAZnBgMLo46dQFzD1hMk8sfZD+4U1kLVnW9A1g0Jnwx/oIJ4ZoKJ5OrpCjvnga\nwV7Jjx/5FbOOPpkLLj2POTUluMym/X4tWq0Wo9GoNifaj/YmKDYJIS4ANNtXgv06sGRsy1IU5UAJ\nJsOsHWwmlklQbPHgNtrRarX4LG6CoSRr13WzbulbDHb3YdEVU1JaRN2UBcw+Zg4d/pX0xdZSXFxJ\nvgBGvYVa3ySqPRPJF3JohJZcTnLnb5/kL8+8jNPh4JhJZZw1e7L6RX4I2ZuguBq4HigATzCyGux1\nY1mUoihjryALtAY6aQt1YdYZObluHqfWL8CfDOE1u4j7s/zyN/9gsK+XdLaXY+amObbGSFnDCZSU\nFzOY3MTrm/+GP9ZHXuaZXHYkUyvmYTeN9As4LBfw6PNP8sNb/8SwP8a5p5/G7T/8AaU+teXMoWZv\nguJ0KeV3gO+894QQYhEjoaEoyiEomomzZmAL0XScSkcJk3316DQjvw7sWjP+rW08+ui/6GjfQllx\ngPZ0gA6DIJxeiSFfCol6/LE+tBodCyedSzgxzPSqBTtCIp3L0RZM4y+4cdo8/PHmWzl94XHjecnK\nf2FvguIH7B4K39/Dc4qiHOSklGwL9dAc2IZOo2V26WRKbCN/4RfyecJdnXSs28w76wcYjHXjKsoS\ntJiQBfBaNZgMNsq8TUyqmkc2n+Ptlr9TKBTw2Eooc9WRyWS44de/oTOe4JLPfpZzjj+Oa87+BHq1\nP/Uh7QP/7QkhTgfOACqEEL/e6SUHI7ehFEU5hCSyKdYNNhNIhimxeql2+EilQ/ijWSKd7XRuWUog\nnOa5FYK+QAijJYK7ZiUusw+XMUJlzQI8rmomVB6F1TgyGW7hxHOJJP04zF7eWbKaq264kW39/Zw4\nfz4LqipwmPZ/Z7Vy4I0W84PAeiAF7LzpbBT47lgWpSjK/tUdGWDT8FYAphdPwGkw8tyaP9Ld30xs\neABTeBi9Tk9voJy+aB1FRSm0ZjtOeyULZswka9AzofJIJpTO2nF7CcBucpGIZvniNd/jqVdfp8jr\n5f9+dhOfW6SmWR1OPjAopJSrgFVCiIeklKkDWJOiKPtJOpdhw1ArA3E/HrOT6cUTsOhNtLYtp3vr\nOvQ5LYZ8Bq+zBJ/nJPoHEtSWluO1BciTwVsURGN14DDZdgsJgP5ojJc2beGFxUv43KJzuPW67+Jy\nOMbpapWxsjc3DiuEEDcBU4Ad7Ugp5YQxq0pRlP/aQGyYDUOtZAs5JnnrqHVVkI6E6W1dR6R/K+ls\nEpPTh89ZiyNewtMvZ9AIPVPaxhSbAAAgAElEQVSnVXD03LmUenLYXItIixwOs3eXkFi1bj33PPEk\nZ190EXU1Nax9/lnqyvduy1Hl0LM3QXE/8FPgVuBjwBdQfRSKctDKFXJsGm6jOzKAUUqmWD048zCw\ndg2xgT60egPaSjfVtinIYBaXbjI9mWpsjj6Om19PNC4o8vmorXXvdu5YPM53bv45f3jiKcwmI5+7\n4HzmVzeoORGHub0JCouU8kUhxK1Syq3AD4QQb411YYqifHgjk+e2kMylKTdYSTS/yZaBHlLhEEW+\nqTjKKumRIf7x1jMkEgMMd9RiFXbMNiv11eVE4wKNVoPXbd7t3I898wzf/NnP6Q8E+PjxC7nrhh9R\nWaZaER8FexMUaTHy58JWIcSVQA9QPLZlKYqyJ6lEiGTcj9nqxWQZuRWUzSZJp6JsGmhma2AbJOJU\npCEY7GG4fxMGvR0MElOFm4TJyYNPrqJzsJhcpBqh02P35ikv0nDycfU47Ea8bjMu579HK6VzOVZ1\ndnHljT/FYTbz2B23c85pp47TN6CMh70JimsAG/A14CbACXxxLItSFGV3qUSIjSsfJRkPUMhnKK85\nCqHREEnH2RLpJ55LUyRMaJZuIBiMI2Ue++RK7OXVpKWduGEury7bSDTqxOcS+DN+NCKDx+mhuNhD\nXbVrl4DI5XL87oEHmXTMsUgh+OOvf80pc2ZhMe/e2lAOb/8xKKSUS7f/GAUuARBCVI5lUYqi7EoW\nCvR3r8Y/0IzJ4iKTjpPJJohbPHQSx1HUyJHmCpLL1rJlQI8omoHQaDEWH0FHPE00myYRXEdpmRGT\nmITRpCPVEOCY2R5c9krKy0p2CYk3lyzly9f/iObOTn76fT1Xffp8bE0N4/gNKONp1KAQQhwJVAD/\nklIOCyGmMrKUx0mACgtFGWOpRIjAUCuJ2CCZdByDyY7Z4sFgL2bIXkJcFqj2NlASyJLu6mA4Y+Tl\n4QoSAwKQnFQjCOhbSOk7sNngrHlXYaQYfzC52y0mAH8wyDU3/oSHX3gRl93OnT/4Pldc/BnVWf0R\nN9rM7JuB84A1jHRgP8nIyrG/AK48MOUpykdXMh5k2Rt3kkoE0enNHLHgi9RPOpXWgS10pMLoAV/E\nRGhTJ0OZHNJZTJ8owVCtp8Gjo6A3UT3BRDzUicfkxmKwkStkKXGbdgsIGJkTcdblV7Jm3XouOON0\nbrv+h/g8u498Uj56RmtRnA0cIaVMCiE8QO/2x1sOTGmK8tEWGGohlQhSVDYVKSFbyLEh3MNgPoNL\n78DcnuDR51oIpnVYPG5OP7mEo0rsSEAgSBeSDKc2kczG8dnLMRusOMze3T5nQ3MzfjTEgcu/+EUa\nnHZOOvroA369ysFrtKBISSmTAFLKgBBiswoJRTlwMukYWq0RKSGUTzMQ6kZoDZTGNdgHQ3QO54hr\nHTRM85ApJPEV5aiq0aC32mjr6WKL/zV643G81jJmVB9Huatul0lzqXSaH9z6K+7+6yN88pNncfO1\n3+aMJjUnQtndaEFRL4R4b4VYAdTu9Bgp5aIxrUxRPsIy6Rj5XJoJsz9FZzJMLJ/BltNS2p/EkClg\nL6+gtLoYsXk5m/qWkdOEMbS+QkTMw2ywIazDWJKSat9McvkcNqNjl5B45pVX+PpPbqKzv58TjzqK\nm664nFq32l9a2bPRguK89z3+7VgWoijKv4UDnYSzKUK5NCkEvjD4oglMVjtFM6Zh9nhoebeTsnIN\nZn2ACXVFmM15Ktz11BVNI51L8qbMkcvn0Gg0O245DURjXH/3Pdz34AOU2Gz8+Rc/56KzPznOV6sc\n7EZbFPCVA1mIoigjYpFB3t74ImGDhaKsHltXFn9QQm0NnpJqNvWk6V/VyqtvbyMtQwxkMtRXZXFa\niil3N2DQGTHojLssAW41OFjevo3HtrSSq6zihLPP5b6vX02Vb/c+C0V5P7WbiKIcJOLRIZpb3+SN\nDc8RS6cow4HNYuexpaC1utB2B1gwx0Kxz0o8FSMnhsiaN2LIm4jHBbNrTtptCXC7ycWqtWu57Lrv\noyuv4JTzL+ATM2cQmNBERmjG8WqVQ8mY/pcihDhDCLFFCNEqhNjjHhZCiAuEEBuFEBuEEH8Zy3oU\n5WAVGGzjkae+y9NLH2CofysTcy5qtDa6cg6k3U79RCPl5XrKq3O4KrpwVnSjtYTIJE1Uexsp97kp\nyNwu50wkEnz1e99jwQUX0j4wwJlzZ9PgcRNIJNEIDV6LmmGt7J29blEIIYxSyvSHOF4L3AWcCnQD\ny4QQf5dSbtzpmCbgOuAYKWVQCKHWkFIOG3tal2lnslAgl08zFOjk8ZdvpWewFQ9mavN6nBYDGXsj\nPb0GhhMbSG5LkC2kaEpNxUYlM+qmM+EzM3llzQtYrTnsDt0uQ1+XLl/Bp778FfqjUT524oncef0P\nqCkrI5RM4U8k8VrMuMxq9zll7/zHoBBCHAX8gZE1nqqFEEcAl0kpv/of3noU0CqlbNt+nocZmZux\ncadjvgTcJaUMAkgpBz/8JSjKwWdkXabHSScCSCmpajoOnc5EPp8hn0uTz2UoFHL0JUOs69lIwN9P\nUcKCPmfD3dRE0ZRP8PBzEWLpKNIQpK7OjMunZ1L1RCaUzhr5ECdc4P7Ujn4Iu8mFlJK+aIwerQ5f\nVTW3XvElLjjt1B1DXl1mkwoI5UPbmxbFHcAngKcApJRrhBAn7sX7KoCunR53A/Ped8wEACHE24AW\nuEFK+cJenFtRDmrB4TYGuldhsrjJZuIEh7bi8tai1RkxmZ3khGBLqI/ecAxX0oojX8fSoWLSBT3b\nChNoyOrJZDXMmFLEW5sK2Gw66spLKXPV7fI57/VD5HI5bv3Nb3js9Te5/he/oMzr5a2HH8JmMIzT\nN6AcTvYmKDRSyo73TcLJ78X79jRrR+7h85uAExhZO+otIcQ0KWVolxMJcTlwOUB1dfVefLSiHFg7\n32bKpKNsWfs0oeE2jBY3VfXHMGH6WTtuP23p7eHtDatIDXdTlLVgNcyl06mnYBmiusRNNq+jocaN\nXqchnghR4a7jhBmzaaio220rUoB3332Xy75xDZuGhplz5FFUmIwcUVWhJs4p+83eBEXX9ttPcnu/\nw1eB5r14XzdQtdPjSkaWAXn/MUuklFmgXQixhZHgWLbzQVLKe4F7AebOnfv+sFGUcZWI+Vn37oOk\nEyGy2SQOdyWZVISaiacgC1mqGo7GZHGRzed4a9Na7v/zUlKBNDaNnZOOb6S4toLZJh15YcFo1KLV\nalkwp5IFcyp5a/0b1GlNewyJWCzGt7/zHf7v6b/jra7hxh/+kKs/fT52o3GcvgnlcLU3QfFlRm4/\nVQMDwMvbn/tPlgFNQog6RjY7uhD4zPuOeQq4CLhfCOFj5FZU296VrijjRxYKxGNDxCN99HevJRzY\nhtVeAkg8RY1otXqERodGo8HlraO1t58Xlyxm3fJOUoM6pjbUonN4mDGrgRlTSgCYUOfdsaqr02Gk\nN9hOZ/JVzAYrb255koUTz90lLPypNC9tbubsCz/Dj752NdOrKlUrQhkTexMUOSnlhR/2xFLKnBDi\nauBFRvof7pNSbhBC3Agsl1L+fftrpwkhNjJyO+taKaX/w36Wooy1VCJEIjqEFJDLJIhHBykUcmi1\nejzFjaRTYXQ6M1qtloq6+Vi9s9jW0UNBY+Xhl9ewuWUT+myG4xtqGK7xYbHb0Gg1VFc4d3yG1phC\nY+1jMJmmPRShJ7iVAgVqi6YQT4WJJP0MdA/zo5/8hC//8HqiBckf7vk9c6urVF+EMqaElKPfyRFC\nbAW2AI8AT0gpoweisA8yd+5cuXz58vEsQTlMvdfPYDDa0eoN5DJJstkksUg/bRtfJJtJIGWB6sbj\ncPnqsTnKsFi9CI1mlz6KVNbE3X9eTvdAiIFgL3WVcWZXujl5wXEUNdQTjqR32w8ilPDz1Iq7iSQD\nCCGY3/gxiuwVrOt+B6Qkny+w8vlt3HL7vRjKK7jhxhs5Z+Fx1LldqhWh7BUhxAop5dx9ee/e7HDX\nIIQ4mpFbRz8WQqwGHpZSPrwvH6goB5t8PktgoJmNKx8jk44Bkoq6+RiMNgASsWHy+SwuXz25XIqi\n0ql4Spp2OYfJ4trRWb1k8Ta2bOtGqx3EYchz8pQpnHzaQvTbtxB1OXfdDyKZibNi28tEkn5qfJPJ\nF3KUu+qocDfgtZXxz9ee5fvX/YTWoTgLz1nEN77yZU6cOgW7UbUilANjrybcSSkXA4uFEDcAtwEP\nASoolENWIZ8jHh0gFuknERsmGuohl03hLWkilQjhcFdTVDYZvd5CJh1DFnIUCgX0ehMWe9EHnnfl\nhg4ee/4VAoEgDeU2GhsnMf+E+ej3MHchmgrR5W9hONaDXmukzFWPRmjR6fU7Js/ZjE5uv/MvxO0l\n/OS6q/n0qaeoVoRywO3NhDsbIxPlLgQmA08DalcTZcyFQiHCoRCZVGq/nC8VDxIKdpDPZcnn02h1\nGuxOD9U1E/GWTkIIQaFQwGovxlcyEaPJAYy0FiYece5us6wDwSTbukLo9CMr4SxduYanX1qPXgMz\nGqo59xNH01Dn2203uUwuTVegmVc3PkYyE8Wot3De3KuYVXMCkaQfm9HNww88xsmnnkrEaOLK62+g\nzOthbnWVakUo42JvWhTrgX8At0gp3xrjehQFgIGBAVpXr8Kh16PVav/r86VTYTaufIx8LoNWo6e6\n6VhsjkqSAQ1Rn5660uo9hsF7dr61BNDRHeL3f15BKp0nl8vgdQ8RiAYoclo4/YQjiSe1uFzWHSGR\nzWcIxPrxx/qJpAIMR3vJ5bM0FM8gV8iRziXx2ctpb+7k/CsvYcm69Xz2W9/moosvZl5TI/Ue1YpQ\nxs/eBEW9lLIw5pUoynaxWIzW1auo8nox6PX75Zw97ZuxGgVFtbPJZlKUFldhd1dSKBTobGnB5nBQ\nXFy8xzWZAELhFP5gEo/LRE9/lOdfbSWZzFJZkmFT+1ZqHFpOO34Bm7daiCclGq0GnSnB2q4NZHMZ\nsoUMUkrMBisV7gbqi6buaMHotDq0BSPXXnstv7n9DlyNTXzrlls5+2NncERZqWpFKOPuA4NCCPEr\nKeW3gL8JIXYbGqV2uFPGSjKZxKzV7LeQyGZiZDIxjGYnuWwKrVaD0TwyLFWj0WAzGYlFIhQX73lN\nylA4xePPbmTYn2TQHyeTzaMjR3PbNvyRNEVeNxeceSbVFaVMmTASKAVdgOc23kU2l0SvM3PCpEVU\neydgNTp2nHfn/SJ+/IOf8ut77uXMK67kc5//ArNqa6jzuNCoVoRyEBitRfHI9n+qne2UAyqfz++3\n9e+llASHtmI0OZk08zxy6ThGsxODyb7jGJ1ORy6b/cBz9A1G2botiNViIJ3Jkk8GsXiHKS6H4+bP\nZNGpx+B2/XtEU14bZOnWf5EvZJlSMZ9kJobD7N4lJABCQ1Hi8SxFTXY+celllB27kPmzZjGjtES1\nIpSDymg73L27/cfJUspdwmL7RDq1A55yQL369ttcf8svyRcKfObcc/jqF7+4y+t/euwx7n/kUbQa\nDRaLhZ9955t4bRmi4SHu+MtrbGhuQ6MR/OTa/8fRR+7dcPJUOkd7Z5hEJk1eBshlBkjJNCbp4aiZ\nkzjvtFk7+iGklHT6t9AbasdnLyObT5PMxHbZihQgl8txxx13cP311zNjwdH89Pf3kNXpOee441Qr\nQjko7U0fxRfZvVVx6R6eU5Qxk8/n+d7NP+eR399NWUkJH7v4Yk47/ngmNjTsOGbRxz7G584/H4Bn\n//k837vpBr7/xeN48Z02NMLGa48/xnAgwGeuupoXHnoQjWb0dksqneNfb21hoHMb2qJl9KTCGCcK\nLjryXOodkyn22naERCaXpmVgNZFkgFJnNTW+ycTTkV2WAAdYsmQJV155JWvWr+f4RZ/iC1/9Gkad\njrmlxTjUGk3KQWq0PopPMzIktk4I8cROL9mB0J7fpShjY9X69dRWVVFTWQnA2aefzouvv75LUNht\nIxPkMqko3d0byWWTmMwuev0Jjp1/JAA+jwen3c6aDRuZNX3aB35e/1CMf764ga63XyPpaKbb5mfy\njHl4Sippqqmhwe3bcWw0FaK5fxW5fIaG4ukUO0ZqfG8J8Pc8++yznHXWWZQ2NHLjfX/iyPnzaPR6\nqPe4VStCOaiN1qJ4F/AzsurrXTs9HwVWjWVRivJ+XT2dFLltZFJRDCY7ZcXFrFi7lmw6Ri6fpZDP\nUMjnuP/RR7nv0afIZrN85+IZaLQ6mmrKeW3JSi5cdBG9AwOs3biRnoH+PQZFJJZmW2eIBx5eTmdb\nC7nMAEc0eCkx6HGbXTjMNrzmkV/+0VSI9qH1BGIDOC0+plXOx2p07nI+KSW9vb1UVFSw8MQTuerH\nP+HET36SYpeLGaoVoRwiRuujaAfaGVktVlHGTSYVpb97NZFgF2uW/oni8mkEhlpJxAbp71mzy7Fn\nLGhkftN5LN0U4KVVrZxy+iS+fOmZ/PzuP3DGZy6msryMuUccgW773IxUOsfQcJxASEO3v51kMsOG\nNRtp6+6gtCZHatjNRLyc5NDimXgc5SVVOIw2Ov3NvLz+r8TSISxGB4vmXrVbSDQ3N/OVr3yF5uZm\nXl+2nG2xOGd++kIavW7VilAOKaPdenpDSnm8ECLIrhsOCUBKKT1jXp2iAKlkCJs+w3AogVajR6sz\nEklIqqvq8ZVMQqs1ILQ6dFo92UwSkJy8oIrbHngBb8lEDCY7N177baKxkcX4vnTt1eh0Tlau6yOV\nyhGLxxBeHR5bhIGhteg9w1Q2OKgsqcfZaGTebDfF1SWkDTmGw+00xwcZjHQRz8aoK56GLEiSmShY\nR4bXplIpfv7zn3PzzTdjtlq5+sc3sikYwmk2M7dStSKUQ89ot57e2+7UN8oxijLmctkUDZUueofC\nRDMmJvgm8sKbv+F3P7sZs/Xfo4naOjqor6mhpulEnn/lJeprajGY7CSSSfzBBM+9so0NW9YSCqfR\naj2YTXrKSmzkU1p6Y110BLaA08DxC07gYmcjvYPDpEU/EXOAoVAPuXwWnVaP11pCmbNu5K8nKdFq\ntTtGNfX397Nw4UJaWlpY9D+XcNHXv4HN4aTB46bBq1oRyqFptFtP783GrgJ6pZQZIcSxwAzgQSBy\nAOpTPuISsSH8A1uorDuKG7/VwHW3/YGCfJwLzz6biY0N3PK733HElCmcfsIJ3PfwI7y1dCl6nQ6n\nw8GdP70JgE1bOvnCt75BPi8p9hXxxQuvorHWTWWZg+HuDlZtWMKQWcMRRx/LUVOPxmNx0RtsZ3HP\nPeTyaTQaPQsnfJLG4hk4LT40YmS0lMvq2zGqyaS1AlBSUsKxCxfy7Vt+SdWUqdiNRtUXoRzy9mY/\nitXAkYzscPcS8CxQJ6X8xNiXtzu1H8XhKRkPEgl2odMbGRoK0rtuNQ5Tgd6Od5ESnJ5q6iedustE\nuT0JhVP0DcbQaUEiGPIneHd1DzIvicTTTG70YbEYWDDDQ3fneroifeTQ0njk8Zxy7GkIIegLbWNl\nx2t0Dm+hseQIEpk4c+tOpMLdsNvnFQoF7r33Xn72s5+xePFiDC43GwaHSOfyqhWhHFTGdD8KoCCl\nzAohFgG3SSnvEEKoUU/KfpNKhFj+xl0kE36E0GBxTSGVjmHRa9Ebbbg8tWTSMdLJ8KhBEQwleejJ\ndWQyBYQG5k4vQyJxO0w01Lrp7Y9SX+3Cphlm5cY1ZISkum4SPlspvqqJFGSBrQPr8Mf6KHfWUygU\nSGUT6Ha6tbSzNWvWcMUVV7B06VJOPPlk1g0MQiKF3WhkdnkZTpNqRSiHh73aClUIcT5wCXDO9uf2\nzyI8igL0diwn5G+nuGIaGo2Oirqj6NQMY5dpsqkomfTI7Ob31md6TzSWJhxN47QbsVkNLF/XSyCc\nYvrEYqQsUFfjxmk3Eo5mCASTiEKacHA1fYUIDm8Rc5rmYNVb6QkGyWmTvLbpcbQaLRNKZ1Phrqex\n9IjdJszByJDXa6+9lttuuw2Px8Nd99/PpGMXkskXVCtCOSzt7czsrzCyzHibEKIO+OvYlqUcjnbe\nLlQIQTw6SHBoK83rnyEeG2KwZz2lVXPwFFXh9NWzbtkyhGsaMhVFZ3IwGElCJAlAPJ7hX+92Eoln\nSKfzlJXY2NLqJxRJEU6EaKrxEE85QGugvkbPpk3rCab7SMX11NdMobqkhmQyTzgRoWRSNS82/4m8\nzFPqqGZu3ciAvvdPmHuPEIJgMMgXLr2Uz33r20QRGHQ65lQUq1aEcljam61Q1wshvgY0CiEmAa1S\nypvGvjTlcJJKhNiw4hESsSEy6Thl1bMxmuxkMgmc7iqq6o8lHNhGVcOCHUt9zznmGBKJBLlcbrfz\nrd7Qz9ZEDJfThMwXsFR5+f/snXd4VGX2xz93WmYmkzrphSQkkIRACk1QQEBAd1EUQQO6rG3XFcEC\nrq67NlTcVVfBgnUV8QdIEBTBLogsEKSXkISSHhLSk0mbPnN/fwwZM2RSUMCy83meeZ7ce9/73ndu\nknvuec95v6e/n5HwMB9Ky3VcflksKckhnC4r4FR1HmK0lCFR4xg6aDQ+SscKbqlUiklsZ3vhRxgs\n7QyLnUCroYkWQ0MXA1FWVsZ9993H448/ztChQ3lm6Uscq2+gzWojPtCfBG2gx4vw8JulLxXuxgIr\ngUocayjCBEGYI4pi9oUenIdfN3q9noL8fNpbmmmqK6P42FbkCjU2m5Xm5mC0IYlYrVBRXIso1iAI\nAkZzCQXHarv01d5uobnNhJ/GC5PVxuffnKSouBFfP29GjkrhmimpfPd9OXabnf5x3gyM03L06A5K\n6svQhAQwIf06YkLjXPpsMTTx+d53aGyvpd3cQl1LJWovjUs8wmKxsHTpUp588kkAZt54I7KISCpb\nWtEoFAzt54lFePjt05esp/3AH0VRzD+znQys/LHR85+KJ+vp14HBYCBn7158BfDVaGisPUbxsc1o\nfMNReKmJGTDBGZg2G1sxGZq7yH930Npm4tsdJTTo9BhNNiLCfeiXFIY2yBsQkckkKJQKpFIZNrsd\nu82KxWYGQC5ToJAr3FaHM1kMmKwG5FIFdtGOXKpAJlU4019NJhMNDQ1YLBZUKhX+AQHYBQFRFJFJ\nJMikUjw+hIdfGkqlkqioKORn1XO50FlPig4jASCK4jFBEDxi+R56pKKsDG+7jYDAQNpaqtHVFxMZ\nNwo//+guBkGh9Okxm+l0dStFZY2o1QqkUoG0kTGERoah8fZFIhHw8VZgtduQK70wGNuw2mzI5HI0\nal9kUvd/4marEaNFj8VmQiqRAQI+Sv8zP5+57unTSCQSoqOj8dJosNhsSAQBlVyOrBflWQ8efg5E\nUaShoYGKigri4uJ6P6GP9MVQHBQE4S0c008AN+MRBfTQC/q2VrwEK421BRQd+xrRbsVmtxMSPrjX\ntRCdaWk1smNvOWUVLXh7yxk6OAyNn4qIsCDsdpBKBSQCmAx69BY9UpkMb29flApltzWmLVYTZqsJ\nhUyJt5cvNrsVqUSGRJBSX1+PXC7Hz8+PsLAwtMHBmOx2LDYbXlIZXjKpp3a1h18sgiCg1Wqpq6s7\nr/32xVDcBdwLPIQjRrEdePW8jsLDr5aOTCaFlw8Ijm2jvonTJfvwtprB2gp2G0Fhyezcf5TbH30H\nEYnbwkMdfLZ5M39+8CFeXfwycnkIuw/s5OBRhzbljj1yBgx/jdiYfqiUSiwWE21GPRarFZWPD74a\nPyQSabfjtdosmKxGpBIZXjIVgiAglcgwGAyUlxfR2tpKQEAAPr6+GG02pxehVig8XoSHXwUX4kWm\nR0MhCMIQIB7YIIri8+f96h5+1Rj1OvIPfoiuvhSbzURk3Ci8lD4ovHxQa0IIlCtRq9SOILWxnZdX\nfsHaN96gX7/+bgsPAbS1t/PWqg+IDItj76EqwsMUjB01jmsmT0EilRAeYkEqlaJQyGnXt2CxWpFI\nJKhVGrzVvj0aCZvditGiRyqRopQ7xmW326mqqqK6uhqJREJMTAz+gYG0mc2IoujxIjx4gO5LEwuC\n8A/gExxTTZsFQXD/+ufhfxZDewP6tnoUSm/UmmACgvoTlzSZ6PjLCAiOQ60JRq0JImbABOrbfUmI\nSyAhPhGFXO4sPARgNptoamqivr6eJ198kcljJiOKEBQgEOQvkhirpn+0F0MGevPJl5/ipZDT3NKE\nyWxGJpWjUnoDAhaLBbPZ3OVjsVgwmgy0GR31tjqMBIBOp6OqqoqAgABSUlLw9vdHb7EgAN4KBUq5\nzK2RkEqlpKenM3jwYK655hp0uh9qeeXl5TFx4kQGDhzIgAEDePrpp+mcNPLll18yfPhwkpOTSUpK\n4q9//esF+x39WGbPnk1qaipLly79Sf1ce+21jB492mXfokWLiIyMJD09nQEDBnD99deTn5/v0qau\nrg65XM5bb73VY/8zZ86kuLj4J43xQlJSUsIll1zCgAEDyMzMxGw2d2lTWlqKSqUiPT2d9PR07rrr\nri5tpk2bxuDBP9RP+etf/8rWrVsv6Ng705MvfTOQKoriDTi0nuZenCF5+LWg8tZiNrVhMRvQ+IYS\nEBTv9o1eofShxSASFRHp3BceGkp1bR0Gg54TOTlUF5xg93ffUV5SQqJ/ABKbGXNDNdRXotTX4NVW\nQ33hUT758gukAkhsIkqpAhkCNpMJm8mE1WjEajQ4P2ZDO4a2ZlpbGjhdepyq43m0NdZhMptpbm4G\nICAggOTkZKJjYjCKojMWoellqkmlUnH48GFyc3Mdq7Nfc9T2MhgMTJs2jYcffpiTJ09y5MgRdu3a\nxeuvvw5Abm4u8+fPZ9WqVRw7dozc3Fz69+9/Pn8tbtednAvV1dXs2rWLnJwcFixY8KOvqdPpOHjw\nIDqdjpKSEpdjCxYs4PDhwxQUFJCZmcnEiRNd5tXXrVvHqFGjWLOm+7W9eXl52Gy2c7p/Nputz23P\nB3/7299YsGABBQUFBMrN814AACAASURBVAQE8O6777ptFx8fz+HDhzl8+DBvvvmmy7GPP/4YzZnq\njR3cc889PPvssxds3GfTk6EwiaLYDiCKYl0vbT38D2I2t+PjF0FU3GgS06Y7F8q5w10WtiiKFObl\n4y+XE+Tnx1sbNrDwpjmYzHJ8vFUMToxi/KVJhIUE0KCrYPvBnSgVMtRKFRpvHxRyBc3FxdTlHKE+\n9wh1OYepO+L41B4+SNm+nZQf2EnJ9s0cW7GC4g83sOflV9i56n0Off4pp/Z8T+W+PVTnHKZ49y5q\n9u+j+cgh2ooKzmmqafTo0VRWVgLwwQcfcNlllzFlyhQA1Go1y5Ytc/5TP//88zzyyCMkJSUBIJPJ\nuPvuu7v02dbWxm233caQIUNITU3lo48+AnB5YKxfv55bb70VgFtvvZWFCxcyYcIEHnzwQWJjY128\nnISEBGpqaqirq2PGjBmMGDGCESNGkJ3ddTnUlClTqK2tJT09nR07dnD48GFGjRpFamoq06dPp6mp\nCYDx48fzj3/8g8svv5yXX365Sz8fffQR11xzDbNmzSIrK6vb+5eZmcmUKVP44IMPnPvWrFnDiy++\nSEVFhfPens3q1au59tprndtz585l+PDhpKSk8MQTTzj3x8bG8tRTTzFmzBjWrVtHUVERV111FcOG\nDWPs2LEcP34cgE8//ZRLLrmEjIwMJk2aRE1NTbdj7guiKLJ161ZmzpwJwC233MInn3xyTn20tbWx\nZMkSHn30UZf9MTExNDQ0UF1d/ZPG2Fd6ilH071QrWwDiO9fOFkXx+gs6Mg+/WNpbaqks20vpia2A\niFTWe7Z0eGgIldU//ONV1dSgDfBHYrOi9vPhdE0Tx0vLuWXRUyBCu6mdx958lSfvuhW5RI/VYuZ4\naR3TJ05CKu0+DtGB1W7BZrcgFWTY2o2IVjt4e2NqbMTXbCEmKQa7CGarFTsiCokUuVRyzrEIm83G\nt99+yx133AE43nKHDRvm0iY+Pp62tjZaWlrIzc3lgQce6LXfp59+Gj8/P44ePQrgfDj3xMmTJ9my\nZQtSqRS73c6GDRu47bbb2LNnD7GxsYSGhnLTTTexYMECxowZQ3l5OVdeeSXHjh1z6WfTpk1cffXV\nHD58GIDU1FReffVVLr/8ch5//HGefPJJXnrpJcDhNfz3v/91O541a9bwxBNPEBoaysyZM/n73//e\n7diHDh3qfGCfOnWK6upqRo4cyY033sjatWtZuHBhl3Oys7OZPXu2c/uZZ54hMDAQm83GFVdcQU5O\nDqmpqYBjbcHOnTsBuOKKK3jzzTcZMGAAe/bs4e6772br1q2MGTOG3bt3IwgC77zzDs8//zwvvvii\nyzVPnDhBZmam2++wbds2/P1/eFlqaGjA398fmczxmI2KiurW6JWUlJCRkYGvry+LFy9m7NixADz2\n2GM88MADqNVqt/csOzubGTNmuL+p55GeDMXZV192IQfi4deBvrWePVtfor21Gn17AwOHTAMc8Yru\nPIrWNhNB2miKSssor6xEG6Dl4y++4qG77+f06RaqT5vIK6jjjinzaWk1kZ4Syivr32LGxFEIVh1e\nXt4MSkjlyXc3cffsm1361g4YCDge+FIvGXZsiKIdg7kdpd2MRJDh29qfurLTCIJI6MBkRsy6GUGj\nwfwT1kUYDAbS09MpLS1l2LBhTJ48GXC8RXZnbM7FCG3ZssXlLTwgIKDXc2644QanEc3MzOSpp57i\ntttuIysry/lw27Jli0s8oKWlhdbWVnx83KcsNzc3o9PpuPzyywHHW/ENN9zgPN7dQ7OmpobCwkLG\njBmDIAjIZDJyc3Nd5tk70zmGk5WVxY033gjArFmzuOOOO9waiqqqKoKDg53bH374IW+//TZWq5Wq\nqiry8/OdhqJjnG1tbezatcvlO5hMJgAqKirIzMykqqoKs9nsdh1CYmKi04D2hrvFzO7+BsLDwykv\nL0er1XLgwAGuu+468vLyKC4uprCwkKVLl1JaWtrlvJCQEE6fPt2nsfxUeipc9O1FGYGHXxVVFQex\nWg1EJ4zhVNEu9G11aHxDXSrN6ZqNVJxuIVItxWwW+Pq/hRgMVi6/dCbX3XYndtHOxMsmIZcGsHbz\negZGxxPqF0N0uB8niurYd2QPp2tOsX5THVPHjeHOP97Kvvx8QrWBRIeGYhVFrHYLer2R6ro6IsJC\nEAURq91Kc5Mes9kKgkCgvwaFWoEqJJD0mZkIRiMKbRA2tRq7zYZCKkUpcx+s7o2OGEVzczNXX301\nr732Gvfeey8pKSls377dpW1xcTEajQYfHx9SUlI4cOAAaWlpPfbfncHpvM9oNLoc8/b2dv48evRo\nCgsLqaur45NPPnFOXdjtdr7//ntUKtU5f2d3dL5mZ9auXUtTU5PzYdvS0kJWVhaLFy922/7QoUMM\nH+5YNLxmzRpqampYvXo14Fj4WFBQwIABA1zOUalUzntQUlLCCy+8wL59+wgICODWW291uT8d47Tb\n7fj7+7t92N9zzz0sXLiQadOmsW3bNhYtWtSlzbl4FEFBQeh0OqxWKzKZjIqKCiIiIrqc5+XlhdeZ\nwlbDhg0jPj6ekydPsm/fPg4cOEBsbCxWq5Xa2lrGjx/PtjNJIEaj8bz9HnvDE3fw0GeMBh1mYwsq\nby2iXSQ8OoP4QVe6xCd0zUbWf5bP5u0lZH2ax+btRVRWtWGzi8REpvDy02/wxcq1PPHAPIalhvPA\nLZnM/v14fH2UtBlaQdrIgZzveOYvt/DB0hc5fOwEBWVFDIgNZvmT/6Dd2IzZakRvaqWxuQmFQo79\nTDFGQ7sFqURGeHggarWUunoddpuITConODoaTWws9jMPDG+FApVc/pPTXv38/HjllVd44YUXsFgs\n3HzzzezcuZMtWxzrPgwGA/feey8PPfQQAA8++CD//Oc/OXnyJOB4cC1ZsqRLv1OmTGHZsh+c+I6p\np9DQUI4dO+acWuoOQRCYPn06CxcuJDk5Ga1W67bf3t6O/fz8CAgIYMeOHQCsXLnS6V30xJo1a/jq\nq68oLS2ltLSUAwcOdBun+Oijj/jmm2+YPXs2J06coL29ncrKSue5f//7392em5ycTGFhIeAwRN7e\n3vj5+VFTU8OXX37p9lq+vr7ExcWxbt06wGGQjxw5Aji8p8hIR8LF+++/7/b8Do/C3aezkQDH72DC\nhAmsX7/e2WfnmEoHdXV1ziB7cXExBQUF9O/fn7lz53L69GlKS0vZuXMnAwcOdBoJcEw1duehnW8u\nqKEQBOEqQRBOCIJQKAjCwz20mykIgigIws+iH+Whd0S7nbrTuajUWoaO+QuxA8czeMTNhEVnuEw5\nNTQZqKhuxS6C3WonSOtNZLiGQH8VsdH+pKeEEhHmi5+PEpnM8ecnVYho/BsR7afwltcTGxHO5PGT\n0fj6c9nI4Xz63accPbWLXQWfk3d6L3bRTmurEY1GhUSQoJB6oZB5YbXaQbDTUN+Aqd2CXCZHJlEh\nigJ6ixWLzY5CKu01o+lcycjIIC0tjaysLFQqFRs3bmTx4sUkJiYyZMgQRowYwfz58wHHfP9LL73E\n7NmzSU5OZvDgwVRVVXXp89FHH6WpqYnBgweTlpbGd999B8Czzz7L1VdfzcSJEwkPD+9xXJmZmaxa\ntcrlDfiVV15h//79pKamMmjQoC4ZNu54//33efDBB0lNTeXw4cM8/vjjPbYvLS2lvLycUaNGOffF\nxcXh6+vLnj17AFi6dKkzPXbVqlVs3bqV4OBg1qxZw/Tp0136mzFjhtvsp6lTpzofnGlpaWRkZJCS\nksLtt9/OZZdd1u34Vq9ezbvvvktaWhopKSls3LgRcKTt3nDDDYwdO5agoKBe70tfeO6551iyZAkJ\nCQk0NDQ4Y1mbNm1y3sft27eTmppKWloaM2fO5M033yQwMLDHfi0WC4WFhU4v7ELTqyigs6EgeImi\naOpzx4IgBU4Ck4EKYB8wu7Nu1Jl2PjjKqyqA+aIo9qj45xEFvPgY9TqqKw6jb6ujX8JYNL5h3bZt\nbDLw7GvZWPXVRCoMTJvsmCPuKDDko/lBaVXXrOPQru9oa63GZrESGRDOqZoWDubns+DOP2O06Fn7\n5XpyT+Yz7ZpLsdotRAb0Jzzj9wT6B6DV+tLQ0EpwoBZBKqWiqgqz1YK/jwZtYBDF5eWEhYWhVKuR\nCAJyiQASKepupks8/LowGAxMmDCB7OzsPiU4/JbYsGEDBw8e5Omnn3Z7/NixYyQnJ7vs+ymigL2+\nVgmCMFIQhKNAwZntNEEQ+iLhMRJH7YpiURTNQBbQ1e+Cp4HnAaObYx5+Zox6HUf3rqLg6GfUVeUj\nkyl7bN/QpKdfpB+TJmaQNqIfVpsRb7WcqHBfFyPRpNfx/dHtlJQdx1tQkD5wGP0HDMGKDZPFQH3r\nafYVb6G+pRKL1YRcKifAO5iogAEYjRaCtVqUcm8QwXJGBDBYq8VH44PBbKW6vh4vpRKbKCKXSlHJ\nZU5VWA+/DVQqFU8++WS3mUS/ZaxWa5+y584XfdF6egW4GscqbURRPCIIwoQ+nBcJnOq0XQFc0rmB\nIAgZQLQoip8JgtDt8lRBEO4E7gTo169fHy7t4adi1OtobiilpiqPpvoihzy4yrfb7CZds5H8glo2\nfnUSm11ErZRz1fgR1FYUUtzQgGhzxBHMNguFp09SWVGMtd2InyIQ7/CB1FihvKqC/KYC9peexO/A\nx0glUqqbQaYJwmALwEceRWGNDm2QlVPVtYh2Oza7nfbaWvrHxBAYGEhAYABmqw2L3U5lRQU+KiVe\nzrfNvnnPHn49XHnllT/3EH4WOmdtXQz6YigkoiiWnRX068vyRndRQud/qiAIEmApcGtvHYmi+Dbw\nNjimnvpwbQ8/AUN7E/u3v4ahvQG7XUStCUSpDkAqlblkN3XQ2GTg1eV7Katsobq2jalXJCCKIgaT\nQPqIkYAjaFhcW8L+nJ14+UuZFDuRuLhUaoqLiQoJQW9u5VjlPuIkgXz0pZnQ6H4EB/mzceNH3Hf/\nTH4/5nrUCkcKZ7XVhspLgV6vRyKREBkRjlqlwmKzYbI6Mp7MRiNSiQS18uJkhXjw8FumL4bilCAI\nIwHxTNzhHhyxh96oAKI7bUcBnZN+fYDBwLYzRigM2CQIwrTe4hQeLiw1FYcxtDcQFJaMiEhkzEi8\nlL6ovLVuvYmCkgZ0LY71D4fsdlrbzKjVCrQBjoe0ztDC3rxsKssKUAJD+icTmzCE1lY9Te01mGpr\nyDmVTZtRR7Ohjjl/vII3Xv4aqSDnuqmTuXZMJsveWUnaoEHUlJeRMeVKZKGhRIRHUK/ToZArMFmt\n6E0mqk6fdsQj5HL6RUZ2GasHDx7Onb4Yirk4pp/6ATXAFvqm+7QPGCAIQhyOMqqzgJs6Doqi2Aw4\nUwsEQdgG/NVjJH5eDO2NGPQNqNQBCIIUqUSCvzauR3kOi9WOQi5BrZIxPD2SS4dFEdfPH2+NjMNl\nR8jN2wsGE4lB/SiVnGBX42Z27fmaaO/BtLZUobbasdmtxGgTCfOLJWpwAvMzFzg9CIAH585FEAQ+\n//wzVEoV8fHxyKQyfHx9MdkcU01qpZLkAQkInrpzHjycV3o1FKIo1uJ4yJ8ToihaBUGYD3wNSIHl\noijmCYLwFLBfFMVN5zxaDxcUq9VEdcVhvH1CiEkYj8nY3K0X0UFjk4GSch0TLotlQJzW4UV4mcmr\nzaf08DHMdfVEq4MZdsmVnOY0ZYe+IDwgBplERkRgHJbgIMKD/BGxI9rtqLzUxGgTnUairq6OF154\ngYyMDGbNmsXUqVdTj4BUKsVkc6S8OlZXy5D2FqwWRQRPTQkPHs6ZvmQ9/UcQhLfP/vSlc1EUvxBF\ncaAoivGiKD5zZt/j7oyEKIrjPd7Ez4ehvYmCo59jMugIi8pA7RNEQHC8WyPR0Khn3+FKvt1Zwotv\n7ebg0WpOFDWgDVDRQhPPffcGK75bwffF+xgSlcLQyyZQyWk2562loa2SUw0FqOQ+JESmIFVqsFsk\nDI2ZQFLEcIbGTECt8MFut7F2bRYzZsxgx44d2O0/hMXsoojhzLqIjoym3oyEKIpY7Xaksr440b3j\nkRnvmZqaGq6++mrS0tIYNGgQv//97wHHeooTJ064tL3//vt5/vnn2bZtG4IguCisHjp0CEEQeOGF\nF9xe56WXXuL//u//ftQYLwYmk4nMzEwSEhK45JJL3EpxgEO4cMiQIaSnp7usjcjMzHTKj8fGxpKe\nng7A0aNHnYKQF4O+/Nds6fSzEpiOazaTh18pbS01NNUVYDK2UnpyG3abGd+Afi4P5bPRNRt56d29\ntLWZaW834+erJD0lFIPZxM7jORTV76a6qogwpQap1odT6nosdYdpaq9B4+XLhOSZNLbXMCR6NIE+\nwaQMH07u/n146a1I8aLVaORIcR5Lly6loKCAocOGc8/8+YSHh1NVW0NFSyth/WKwWq14yaRIRBGr\ntbfcChGDvhmrtQ2ZPAIUP73ke4eEBzj0j1577TUeeeQRp8z4G2+8wZQpU9Dr9cyYMYPXX3+defPm\nOWXGP//8c5KSkrBarbz9dp/eu/pMh2TEj6VDZrysrOxHX/Pxxx9n8uTJ3HfffQDk5OQAOJVkO9Rd\n7XY769evJzs7m5KSEoYMGcLatWudC9OysrK6lTuxWq0sX76cgwcP/uhxXmjeffddAgICKCwsJCsr\ni7/97W+sXbvWbdvvvvuuy0K/zm0feOAB/Pz8ABgyZAgVFRWUl5dflEzQvkw9uXwrQRBWApsv2Ig8\nXBQMbY3s/nYJdpsZs9mASh1ARMwILGZDjwJ/dQ169HozifFaTGYrBpOFqpZ6qhsrMYo1SKU69EIN\np2hG2irnd+rLSAxLQyKRkV2wCbvdTqAmlHB/hwaQj48P6aNG09ra6qxpUNjcwolGHU8ue51rrrkG\nQRBoMhg4XteAQakhSqFwitg11BzHZGzp8btazG2cKsxGEEQEQUJMwrge63Z7qXwJCkvu9vjZjB49\n2vkg7E5mfPz48cybN++cZMbvuece9u/fjyAIPPHEE8yYMQONRkNbWxvgkBn/7LPPWLFiBbfeeiuB\ngYEcOnSI9PR0NmzY4CIrkZCQQHZ2NhKJhLvuuovy8nLA8UZ+9irmzjLjr776Kj4+Ptx1113o9Xri\n4+NZvnw5AQEBjB8/nksvvZTs7GymTZvmktdfVVXlvAeAU5xv9uzZZGZmOg3F9u3biY2NJSYmhpKS\nEvr160dLSws1NTWEhITw1VdfOb2Rs9m6dStDhw51Pvj/85//8Pbbb2M2m0lISGDlypWo1WqXezN0\n6FCeeuop7rnnHo4ePYrVamXRokVce+21lJaWMmfOHNrb2wFYtmwZl156aZ//DtyxceNGp2bUzJkz\nmT9/fo/Ckd0hiiIffvihS7Gia665hqysLKc8zIXkx5jWOCDmfA/Ew8VF11SK3WYmLHooRr0Oq8WA\nxWxAIpG4TYHtwEspBQTa9WYkKitRAw3UlZWRFmFAL6+kWdFMsGghNXYsGpmKWG08gZpQAMYlTqfF\n0ICvSouP8gdDpFQq+fTTTykoKOCRRx5hxowZTJ06FaVSic1u50R9A+U2PUGhoQwJDaGmrBTFGa9A\nLpdjt8p7/K6GNj2CIKLWBKNvq8NobOnRUJwLHplx9zLj8+bNIzMzk2XLljFp0iRuu+02IiIiSE1N\nRSKRcOTIEafsSWepcHA8UNetW0dGRgZDhw51CuadTXZ2tsu9vv766/nzn/8MOCRQ3n33Xe65554u\n9+Yf//gHEydOZPny5eh0OkaOHMmkSZMICQlh8+bNKJVKCgoKmD17Nu5UIMaOHUtra2uX/S+88AKT\nJk1y2VdZWUl0tCP5UyaT4efnR0NDQxfPQRAEpkyZgiAI/OUvf+HOO+90Ob5jxw5CQ0NdhBGHDx/O\ns88++8swFIIgNPHD+gcJ0Ah0q9vk4deDIEiwWPR4KTUMTJ2GaLf2GryWSiQMGRKIJKAVu7UGr0Yd\n44JDaQswcKS5hAhVPPZGERVW/JRqfFU/GB0fpb+LgQAoKipi/vz5fPXVV4wYMYKHHnoIuVyOUqmk\nyWAgp7oWvcVCjL8fiUFapBIJncvJ9OXNX6vXYTY2Y7fbUap8iUuc2ON37AsemXGc13HHlVdeSXFx\nMV999RVffvklGRkZ5ObmEhwczOzZs8nKynLqLD311FMu5954441kZmZy/PhxZs+eza5du9xeo6qq\nykWmIjc3l0cffRSdTkdbW5vLYrzO9+abb75h06ZNzriH0WikvLyciIgI5s+fz+HDh5FKpU7hxrPp\nEEjsC32VGs/OziYiIoLa2lomT55MUlIS48aNcx5fs2ZNF4P6i5AZBxAc3ygNR3orgF3sqziUh180\nxvYmQiJSCI3K6DX9tQODxci+0mOUt5Qy0KsFrVXAPzAYW5gKm9WCxhxAgHcoPqoABkddSoR/XBfD\n0IHJZOKFF15g8eLFyOVyXn75Ze6++25kMhk2u52T9Y2U6nSo5XIuiYokUP3jF84p1f4kpk3H0N7Q\nqyHsKx6Z8a7XPJvAwEBuuukmbrrpJq6++mq2b9/OjBkzmD17NlOmTOHyyy8nNTWVkJAQl/PCwsKQ\ny+Vs3ryZl19+uVtD0VlmHBxV/j755BPS0tJYsWKFi9Jq53GKoshHH31EYmKiS3+LFi0iNDSUI0eO\nOF4qlO7las7Fo4iKiuLUqVNERUVhtVppbm52K/jXIT8eEhLC9OnT2bt3r9NQWK1WPv74Yw4cOOBy\nzi9GZvyMUdggiqLtzMdjJH4DNDeWU5T/FS2609RU9F6ExWq3crKhlP+W7OHwoTxspTqirAHUaKrZ\nZ9nLnvLN9NMmcsOIexkeN5Epg28mMSyjWyMBjipmTz/9NFdffTXHjh3j3nvvRSaT0WQwsLPsFKU6\nHf38/LgsJvonGYkOlGr/brO4fgoemXH3bN26Fb1eD0BraytFRUXOoGt8fDxarZaHH364y1tyB089\n9RTPPfdcj2J/nWXGO64THh6OxWJx1rJwx5VXXsmrr77qfNs/dOgQ4PCewsPDkUgkrFy5stv62h3l\nYc/+nG0kAKZNm+aULF+/fj0TJ07s8gLQ3t7uNDzt7e188803LvLhW7ZsISkpiaioKJfzfmky43sF\nQRh6wUfi4YJiNrXTWFdIeeF2So5vwW63ExSWRHOrlfzjZeiaf3gzs9nsGIwWdC1GjpSVsuFANtv2\nHSB3Sz7H9zZR3SrySWEdla0N+KoCCfONQaXwxkfpT2RAfLcGoq6uzvmQSkhIID8/n3Xr1hEZGYnN\nbudYbT27Tzmc15FREaSEBp9XOfALhUdmvCsHDhxg+PDhpKamMnr0aP70pz8xYsQI5/HZs2dz/Pjx\nLpLiHVx66aVcd911PV7jd7/7nYv39vTTT3PJJZc4p26647HHHsNisZCamsrgwYN57LHHALj77rt5\n//33GTVqFCdPnuzRW+ord9xxBw0NDSQkJLBkyRJn7fTTp087g/Q1NTWMGTOGtLQ0Ro4cydSpU7nq\nqqucfbiL44AjS2rq1Kk/eYx9oVuZcUEQZGcWzR0FkoEioB2HhpMoiuLPYjw8MuN9x2ox0tZSTVvz\naYyGZgBU6kDkCm8qSnbTphf59L9m5Op4JDIvRg2NRKGQYbPZaTW1U9hUSlNbPdJWI2qjmeMNFdTq\nVPTrLxKmGUhYXCMx0T7IpFLGJU7v1kDY7Xbee+89HnroIVpbWzl69KiL2985FtHPz4/EYG2PBsKd\nhLKH/02mT5/O888/36X63W8dk8nE5Zdfzs6dO92m+55vmfGeYhR7gaFAz2bdwy8Go15HW0s1ot2K\n2azH0N4AgJfSF21oEj5+4cjkjnlX34AojuSWYJFUEhLoR2ubCUEQCApWUNFeRa1YTIX+O5RmHSpv\n6JeYjNomo+JkOFablWC/SKaPvgqJvK1LFlNncnNzmTt3Ljt37mTs2LG8+eabTiNxdixiZFQEWjdF\n5D146I5nn32Wqqqq/zlDUV5ezrPPPnvR1oT0dBUBQBTFoosyEg8/CaNex/4db6BvrUcQIDZxItqQ\ngWj8wlF4abq0V6r98VKHI5XVo1bJUXnbsGqLyDHWYzA1Y64vIlSoJzoiHpnWl4z+EyhvPEFUoJX2\ndi+mDB1CdEgoENrtmMxmM1OmTMFsNrN8+XJuvfVW5/zsuXoRHjy4IzExsUtQ+n+BAQMGXFTj2JOh\nCBYEYWF3B0VR7BqB8/CzUX3qEPrWWgJDBiLarQSFJhEQHN+lXatRR7O+HoVUyanaekaO8MbgVcaB\n2q3kF7bjbbYyQpFImPcgqoPDUQUEIpFIiA0eRGzwILfrIM5m69atXH755SgUCj788EOSkpKceeOd\nvQiVTObxIjx4+BXQk6GQAhrc15Xw8AuioeYEdVV5yOQqpFIFErnS7aK5VqOOr3JWUt1cRmuLgLEp\nAU2kBYvYiLfCQqw1EFE0kRiVQcrQyRhEQxfD0JOBqKio4L777uPjjz9m+fLl3HbbbYwZM8Z5XGcw\ncqS6Br3FQrSfL0nBQR4vwoOHXwE9GYoqURSf6uG4h58Ro15HU30R7a21lJ7YikSmwMcvgvB+Q7td\nF1HRWEhxbS4+3mEUn7IjtdnJGJpClMVEbl0zglSGb2wc/TPGIPPywgevHg1DB1arlWXLlvHYY49h\ns9n417/+xc033+w8brPbKWhopLSpGaVM6vEiPHj4ldFrjMLDLw+jXsf+7a+hb6vHbDKg9tESFTuK\n9tZavJS+Lkaiuq6NslM6Wk11bD62jvyqRox6K6bqWNIi/Sj4rJrYVF8mDM5EGu6PvyakT8ahM3Pm\nzCErK4vf/e53vPbaa8TFxTmP6QxGcmpqaTebPV6EBw+/Unr6j73ioo3CQ58x6nUU5n1Ji+40QWHJ\nBIcno1T60d5a20Wn6WRZBYte+oLXPviWJf+3heMVBiKCBhHtH8bgAC3pvlIkUjnKhCHEDhlJdNDA\nPhuJDpkEcOj61Wq/4wAAIABJREFUrFu3js8//9xpJOyiyPE6x7oIu93OiMgIBoeG/GaMhEdmvGdW\nrFjhXDvSmebmZv74xz8SHx9PfHw8f/zjH2lubnYeLygo4OqrryY+Pp5hw4YxYcKELivdOzh06BB/\n+tOfftT4Lhb/+te/SEhIIDExka+//tptm1tvvZW4uDinnPjZiyD37duHVCpl/fr1gGM9Uud1FheD\nbv9rRVFsvJgD8dA7Rr2OnD3/R3nRTtqaq7FaTChVvgwalknswPEkpk13ehOtRh3vfLqG49W56NSH\n8A2CgeFqLgkTGa61EKFSoVcGERifQHh0SC9X/gFRFMnKyiI5Odm5UGnMmDHMnDnTmdGkMxjZWXaK\nkiYdkb4+jIntR5D3zzvV1GrUUdlURKtR13vjPtAh4ZGbm0tgYCCvvfYagFNm/OGHH+bkyZMcOXKE\nXbt28frrrwM4ZcZXrVrFsWPHyM3NpX///udlTB10qPD+WDpkxnNycliwYMF5veYdd9xB//79KSoq\noqioiLi4OOfD3mg0MnXqVO68806Kioo4cOAAr776KsXFxW77+uc//+kU/TufYzxf5Ofnk5WVRV5e\nHl999RV33313t6u9//3vfztXeHfUnACH6OTf/vY3F92q4OBgwsPDyc7OvuDfoYOLJ8zu4Sdhs5qp\nKNmFrqGEwOB4tCEDCYkYTFh0htt4xIGiQ5ysq0Tu7YfM4ou2qZ0RVguU1DPyimsJ/f1ltBgFtAEq\n/P3ca9qcTWFhIXfffTebN29m+PDh/OEPf3A5bhdFCuobKWnSoZRJGREZccENRGn9MdpNPcuM682t\nHC7bjl20IxEkpMeMcymzejbeXr7EBnlkxn+KzLg7CgsLOXDggEuNhccff5yEhASKiorYtm0bo0eP\nZtq0ac7jgwcPditT0draSk5OjlMza+/evdx///0YDAZUKhXvvfceiYmJrFixgs8//xyj0Uh7eztb\nt27l3//+Nx9++CEmk4np06fz5JNPAnDddddx6tQpjEYj9913XxcF13Nl48aNzJo1Cy8vL+Li4khI\nSGDv3r2MHj26z328+uqrzJgxg3379rnsv+6661i9enWX392FwmMofsEY9Tr0bfVYzHr0bbVYzHrU\nPiEovDRIpXK3RsJoNVHQWMZXh44hU9n53QhvLMV19DMZiAyKRiqLJDJuEAFhgQSfw1g++OADbr/9\ndry8vFi2bBl33XWXiw6Pzmgkp9oRi4jy9SUpWIu8B52ei0m7sQW7aMdfHYxOX0e7saVHQ3EueGTG\n3cuMuyM/P5/09HSXv5uOKby8vDzy8vIYOrRvgg/79+93MSBJSUls374dmUzGli1b+Mc//sFHH30E\nwPfff09OTg6BgYF88803FBQUsHfvXkRRZNq0aWzfvp1x48axfPlyAgMDMRgMjBgxghkzZjg1sjpY\nsGCBU06lM7NmzeLhh11FtSsrKxk1apRzOyoqisrKyrNPBeCRRx7hqaee4oorruDZZ5/Fy8uLyspK\nNmzYwNatW7sYiuHDhzuFHi8GHkPxC8XQ1kjO3pW0t9Rgs5lISPk98clXEpc4ya0Kqs1uo7S5kqKm\nU1TVNGFsNnLNgEEMFNQoIsMwmCpR+vsjkytQBXZfb+JsLBYLcrmc4cOHM3PmTJ5//nmn0iW4ehFe\nF8mL6Exf3vxbtTrazQ6ZcY3Sl2FxE885YH82HplxnNfpK93dm+72T58+nYKCAgYOHMjHH3/scqyq\nqorg4B9edZqbm7nlllsoKChAEAQsFovz2OTJk52Krd988w3ffPMNGRkZgMNzKygoYNy4cbzyyitO\nocVTp05RUFDQxVCcS8ymrxLj//rXvwgLC8NsNnPnnXfy3HPP8fjjj3P//fd3K4x4MSXGwWMofjEY\n9ToM7Q1I5UospnYqy/bS3FiKxjcciVSGvzbWWWznbC/idGsth6tyadTXIzMryN5yCLOhilYfCcHR\ns+mXMhy7xYKhsQFVoBalf+8PydraWh544AHa29v5+OOPGThwIKtWrXJpozMaOVpdS9sv0IvojI/S\nv9uiST8Wj8x412v2RkpKCocOHcJutyM5k9Rgt9s5cuQIycnJ1NbWuty7DRs2sH//frfB/rMlxh97\n7DEmTJjAhg0bKC0tZfz48W7HKIoif//73/nLX/7i0t+2bdvYsmUL33//PWq1mvHjx3e5v3BuHkWH\nxHgHFRUVLi9ZHXSIO3p5eXHbbbc562Ts37+fWbNmAVBfX88XX3yBTCbjuuuuu6gS49A39VgPFxij\nXkfegSyO7H6fPd8uofZ0Dr7+UfgFxqJUB6JSB7hdQFdWW8f63dlszt/D9rwvOLg3m3fe2Er+0RaM\nLUFoggeiGhCFwtsbpb8/Af3jezUSdrudt99+m8TERNauXUtKSkqXAJxdFDlR18Du8kqsdjvDI8MZ\nEhbyizQSHfSmbPtj8ciM952EhAQyMjJYvHixc9/ixYsZOnQoCQkJ3HTTTWRnZ7Np0ybn8Q6p8rM5\nW2K8ubmZyMhIwJFx1R1XXnkly5cvd8Z5Kisrqa2tpbm5mYCAANRqNcePH2f37t1uz1+6dKlbifGz\njQQ4JMazsrIwmUyUlJRQUFDAyJEju7TrUA8WRZFPPvnEOaVWUlJCaWkppaWlzJw5k9dff92pqHsx\nJcbB41H8IqivOU5jbSFqTRByhZqgsEEEhw8iLCrd7TSTwWJkb8kJ1qzPp73Vjr5dh0pjRGbwRjRJ\niI1VoNWGYBO8XCrM9UZxcTF/+MMf+P777xk/fjxvvPFGF7nmX4sXcTHpLDM+Z84cNm7cyD333MO8\nefOw2WzMmTPHrcy4Xq9HEAS3UtGPPvoo8+bNY/DgwUilUp544gmuv/56p8x4dHQ0gwcPdj7w3JGZ\nmcmIESNcHpyvvPIK8+bNIzU1FavVyrhx43qVGn///fedwez+/fvz3nvv9em+rFixgk8++cS5vXv3\nbmd50oSEBERRZPTo0bz77ruAw0v47LPPWLhwIffffz+hoaH4+Pi4nYtPSkqiubnZOW320EMPccst\nt7BkyRImTpzY7ZimTJnCsWPHnAFljUbDqlWruOqqq3jzzTdJTU0lMTHRJbbwY0lJSeHGG29k0KBB\nyGQyXnvtNec00u9//3veeecdIiIiuPnmm6mrq0MURdLT0/sk/X4xJcahB5nxXyq/JZlxURRprD1J\nTWUOtRU5aAIikcu8XNJcO2O1WzlZV86eE0WcyG+lotCIv1cLtbXVhMfUMbB/BAUV/vTTJiFIRGZO\n7RDu6xsNDQ2MHTuWhx9+mDlz5rhMc9hFkcKGRoobHbGIwaHBBJ8Hvf4fg0dm3AM43u59fHx+8Wsp\nLgTjxo1j48aN3cauLqbMuIcLSHtLLadKsrHbrASFJRM38AqMhia3pTpFUeTIqWNsPnSQxkYbfgof\nIlQGCgwHMJiMqP29+dMNfyYwxAe7RYNZr+hz2uumTZtYsWIF69atQ6vVkpub65w/7qDZaCKnuoY2\ns5lIXx+Sg4P+570IDz8/c+fOZd26dT/3MC46dXV1LFy4sE8JDucLj6H4GWhuLGf/9jewWc34BkTS\nP2kySrU/Ks0PtXRFUeR0fT27846zvySPY5X5yCUQFSCQognFJmkiPb2ZgMAUAoLVBIb4EBnQVS22\nO8rLy7n33nvZuHEjKSkpVFVVERUV5WIkzvYihkeG/2xehAcPZ6NUKpkzZ87PPYyLTnBwcK/V/843\nHkNxETHqddRV5VFdcQREO9HxozHqm6murqK2rYE2cx0ymUBru5mC8tNs/b6adpMFiWBlSLoPGeEq\n2lpPE6eJJC7pWg4270EURSQSSZ9jEVarlZdeeoknnngCURR57rnnWLBgAXK53KWdx4vw4MFDBx5D\ncZEwtDVyYOcb6NvqkUgU+PpHUq+roLypnu83ixRUVGEXrfSLNxMeHkNLuwRvb28uTYuGJj1S6x4s\n7U0EhvRj8KVT8dME4WOMPOeUT5vNxjvvvMPEiRN59dVXiY2NdTl+thcxLCKcEI3Hi/Dg4X8Zj6G4\nCFgtRnIObqaotIm4/slo1BL8wgfy2bF1FJbLOXC8jIhIKRqNH96RTcQPVBJuCeOYxYq5Ugc2C5NH\nXon/gBC0AZEutSH6YiCampp49tlnefTRR/Hx8SE7O5vAwMAuefrNRhNHa2ppNZk8XoQHDx6ceAzF\nBaSjZkRFRTmbd+uprwvnULGJIQMVaJot5Ob6Ul2sxay3UlZpICKujXgfCWGHTqOoPklsm5mAEZeT\ndNlIwvr1PXupA1EU+eCDD1i4cCENDQ1cdtllTJs2rctqU7soUtTQRFFjk8eL8ODBQxc8C+4uEEa9\njoPZ73B072qO5R2g2aAlICQViyQche9QQoLCkHpZEX1biB9hZNDAaG6ePIYZ/iOQltWj9PcnLCaC\n1JHJP8pInDx5ksmTJ/OHP/yB2NhY9u/f7yK21kGz0cSu8goKGxsJ99EwJibaYyT6gEdmvGdWrFhB\ncHAw6enpJCUlufSzaNEiBEFwWTC3dOlSBEGgu9T3mTNndqsi+0ugpKSESy65hAEDBpCZmYnZbO7S\nprS0FJVK5ZQTv+uuu5zHOuQ7Bg4cSFJSklOnatmyZX1et3Ih8RiKC0Rr82namiuRKmM53RSGrsWI\nj6+GYWkJXDkpCU2kmfABAYQFhzI4ZDiXJ6WRrtAgNBtQ+vmj9PdHHRCAWhv0o65///33s3//fl5/\n/XV27drlIl0MP2g0fV9egdlqZVhEOGnhob/ZqSadsYWipnJ0xp6VZvuKR2a892tmZmZy+PBhsrOz\neeaZZ1zkLIYMGeKiZbV+/XoGDRrktu+8vDxsNts53afu5LwvFH/7299YsGABBQUFBAQEOBcRnk18\nfLxzNXfnhXXPPPMMISEhnDx5kvz8fOfq99tvv51XXnnlonyHnvBMPZ1HdM1GGpoMaANUWG0Sqhpk\n7Dluoc0oJyxaTfxgL4JCpeQ059LQXsOA8FBuHf47DE1WrOUnkenNhA4dQf8Jk89Jl6mDzZs3k5SU\nRHR0NG+88QZeXl6EhYV1addiMpFT7YhFRPj4MCjk1xuLOFZfRIupvcc2reZ2tpftd8qMj4sZjo+i\ne6/J18ub5KC+pxp7ZMZ7lhnXarUkJCRQVVVFdHQ04JDJ3rhxI48++ijFxcX4+fl1ybzrYPXq1Vx7\n7bXO7blz57Jv3z4MBgMzZ850yoTHxsZy++2388033zB//nxGjBjBvHnzqKurQ61W85///IekpCQ+\n/fRTFi9ejNlsRqvVsnr1akJDz91r70AURbZu3coHH3wAOIQTFy1axNy5c/vcx/Llyzl+/DgAEomE\noCDHC6JarSY2Npa9e/e6lf+4WFxQQyEIwlXAy4AUeEcUxWfPOr4Q+BNgBeqA20VRLLuQY7pQ6JqN\nfLDhKDX17ZjNNgbGwOmWZAS5hiFJWo42FfFl+XG89XamJowjNSiO5nYlAYKI7fQxvBQSwtJGojqj\ncnkuBqK6upqFCxeyZs0a5s2bx7Jly4iJienSzi6KFDc2UdjQhEIqYWhEGKEazXm7B79UWoxt2EU7\nweoA6vRNtBjbejQU54JHZrx3mfHy8nKMRiOpqanOfb6+vkRHR5Obm8vGjRvJzMzsdoolOzub2bNn\nO7efeeYZAgMDsdlsXHHFFeTk5Dj7ViqV7Ny5E4ArrriCN998kwEDBrBnzx7uvvtutm7dypgxY9i9\nezeCIPDOO+/w/PPP8+KLL7pc88SJE90q427bts1pgMGhaODv749M5nic9iQnXlJSQkZGBr6+vixe\nvJixY8c6py0fe+wxtm3bRnx8PMuWLXMar+HDh7Njx47fpqEQBEEKvAZMBiqAfYIgbBJFMb9Ts0PA\ncFEU9YIgzAWeB/quW/wLoqHJQHVdOyqlDEGQ4KM2MP6SfhyrCORUczUNxiYSggPx0SiI8Y/AZmrE\nVF1PbfthlL5+hKUPRabsWwGhDjoE/B5++GEMBgNPPPGEW3EycPUiwn18SPkVexGd6cubv07bQrO5\nFbvdjq9Sw8S4S/BX+v6k63pkxnFepzvWrl3Ld999x4kTJ/jPf/6D8qy/71mzZpGVlcXXX3/Nt99+\n262hOFtS/MMPP+Ttt9/GarVSVVVFfn6+01B0jKetrY1du3a5jNVkMgEOFdfMzEyqqqowm80uNd47\nSExM7FUwsYO+yomHh4dTXl6OVqvlwIEDXHfddeTl5WG1WqmoqOCyyy5jyZIlLFmyhL/+9a+sXLkS\ncEiKd3gbPxcXMkYxEigURbFYFEUzkAVc27mBKIrfiaLYIQ+5G4i6gOO5oAT4KTGarNhsdvpF+tIv\nuJWwICujR2sIS7STOFxBqL8v/iof/KVqCo/spKaiAGmoH5EjR52zkQCHjv3cuXMZNmwYOTk5LFq0\nqMs/Y8e6iF1ljljE0Igw0n/DsQh3+Ct9mZ44ifGxI5meOOknGwn4IUZRVlaG2Wx2xihSUlK6BGTd\nyYz3xvmWGb/++uuBH2TGO+bJKysruzUSfaEnmfHMzEzy8vLYsWMHDzzwANXV1S7Hr7nmGlauXEm/\nfv3w9e3+d9JZUrykpIQXXniBb7/9lpycHKZOnepyHzrGY7fb8ff3d1F47fCc7rnnHubPn8/Ro0d5\n66233MqJnzhxwhl0PvvTOXEBICgoCJ1O54zTdCcn7uXl5cw4HDZsGPHx8Zw8eRKtVotarWb69OmA\nw+AfPHjQed7FlhR3x4U0FJHAqU7bFWf2dccdwJfuDgiCcKcgCPsFQdhfV1d3Hod47hj1OprqijC0\nNWIx6zHom2hrqaZVd4rkOAkZSXaGJdTQXPM9J0v3syP/A/qFSvhj+ljSQ2IZ6duPgzs+5FDldho1\nevI5QZu57wHW1tZWSkpKALjrrrtYvXo1W7ZsITExsUvbFpOJ78srKGhoJMxHw5jYfv8TU03u8Ff6\nEh/Q77wYic54ZMZ7Z/To0cyZM4eXX37ZZb9KpeK5557jkUce6fH8zpLiLS0teHt74+fnR01NDV9+\n6faRga+vL3FxcU4tKFEUOXLkCOAqSf7++++7Pb/Do3D38T9rWlgQBCZMmMD69eudfXaOqXRQV1fn\nDLIXFxdTUFBA//79EQSBa665hm3btgHw7bffugT2L7akuDsupKFw52e7laoVBOEPwHDg3+6Oi6L4\ntiiKw0VRHN7ZBb3YdKS8HtjxJju/foaC3M+pLNlN9alDHMk5Sl1tFWH+JhSSFtqlck4rlBjMLZws\n/Yrt+WvYeeA9ju7dRLWhgoCIGAb2vwS73U6LoaHXa4uiyIYNGxg0aBCZmZmIoohWq+Wmm27q8ubZ\n4UV8X16BqZMXofgf8iIuJp1lxlUqFRs3bmTx4sUkJiYyZMgQRowY4VZmPDk5mcGDBzvrEXTm0Ucf\npampicGDB5OWluYsltMhMz5x4kRnwZvuyMzMZNWqVS7TQ6+88gr79+8nNTWVQYMG9UnS+v333+fB\nBx8kNTWVw4cP8/jjj5/L7QEcWUHvvfcera2tLvtnzZrVa/nTqVOnOh+iaWlpZGRkkJKSwu23395j\nzejVq1fz7rvvkpaWRkpKChs3bgQc6bk33HADY8eOdQaNfyrPPfccS5YsISEhgYaGBmfMatOmTc77\ntX37dlJTU0lLS2PmzJm8+eabzsp7zz33HIsWLSI1NZWVK1e6xEyys7OZNGnSeRnnj+WCyYwLgjAa\nWCSK4pVntv8OIIriv85qNwl4FbhcFMXa3vr9OWXGm+qKOLjzP6h9grHbLPRLGENgSCJlpw28v/4E\nEkFCv34qYpIa2VfyORLRSqDUjs1bg9YeSFPDaYZFjycpYyK7Sr9wVvoalzi9xxXWZWVlzJ8/n88+\n+4zU1FTeeuutbvXyW0wmjlbX0nImFjEoJOg3ZyA8MuP/WxgMBiZMmEB2drbbsqC/ZQ4dOsSSJUuc\n8Yq+8muSGd8HDBAEIQ6oBGYBN3VuIAhCBvAWcFVfjMTPjVzhjd1uQbRbaRc17C/WYzpxkupqI836\nRmLi4LtjR/6/vTMPj7I6+//nzEwm+x4CgSQkIaxhiWFHECioVGkUca0FsS4XiKIi2P5URCxu1b5W\nBYq+vgpabRUtiBZFsSKaskPYQYJhSUhIMkkmyySznt8fMxmyZ4JkP5/rysXMec42NzPP/Zzte+Nd\nlk+3CCupidcQFRLPrvRNVFYU0y0ynqTR0wjyDfU4NOf27dvdTxOvvPIKDz/8sHt3RXUcUpJZWExG\nYSFeGg1XRPWgR2DXnGZSdC58fX1ZtmwZ2dnZxMbGtnV3WpWCggL+9Kc/tXU3Ws5RSCltQogHgc04\nt8e+I6U8IoR4FtgjpdyIc6opAFjnmj45K6Wse3y4nSClnV7xY7Bou/F/n+zizPk0dDrB9VMTiIzy\nIstQRLnDzhWxfegXEUxMSH80Z4wk+16Bd1IUUbEDPdZpKikpISgoiJSUFH7/+9+zePHiBn8kpWYL\nB3MvuEYRAQyK7NbpRhGKrs21117b1l1oE6p207U1LXqOQkq5CdhUK+3paq/bduKtmZjKDfj6hVJk\nDqG4zEpEuC+hwXqG9BlIxNhIfjixn2izkUE9wrEUGykvyCQ4qBv9x1+NPsCznSUGg4E//vGPfP31\n1xw5coSAgADeeOONevNKKfnZNYrQqVGEQqFoIdTJ7GZQWV6Ej18YWquWC3kVBAV50bN7ED7B3pyr\nPMvIgYkkBI7j3OFdiMoQukUlEDl4CNoGTpxWR0rJ+++/z2OPPUZRURELFy5sdN99qdnCoQt5GCsr\n1ShCoVC0KMpReIjVYsJoyqOwxMiaz46h0YCXTsvE8UkUSSOR/mEkBcaSf/AA/mVawgekEBKf4NEh\nK6PRyI033sjWrVsZO3asO8h7fahRhEKhaG2Uo/CQ/MJMthz/nsM/e3Esw0HvXpH4Bek5VZjF5N5X\nkKgJJ2fXTgB6pozEz4Ntd1WHqoKCgoiIiOCtt97innvuqROzugo1ilAoFG2BUo/1AGNFIV/s/Aeb\nt1o4+1MY5cZAzA4rZY5K+oV1I+jYec6lbUPn40P0mHEeOYnNmzeTkpJCVlYWQgjWrVvHfffdV6+T\nkK54Ef89e44Kq5XkqB4kR/VQTqINUTLjjbNmzRr32RGHw8Fdd93F73//e6SUxMXFMXPmTHfeTz75\nhDlz5rjLaTQat8giwODBgzl9+nS97XR2+fG9e/cyZMgQEhMTWbBggft7tGjRIv7zn/+02udQjqIB\nqk5g5+Sd4L3vlrL98HYMBjshgYUMGOJNv8FRzJk2ioAt/+XUV//GcPw44f0H4uXn12i9OTk53H77\n7UybNg2TyUReXuO7gkvNFrafy+Yng4FIf3/G944hSk01NZviikpOGYoorqgr13ApKJlxz9qUUjJ3\n7lysVitvv/22eyp2z549HDlypN4y0dHRPPfcc0222RXkx+fNm8dbb73FyZMnOXnyJF999RXglCF5\n8cUX662rJVCOoh4qTcUc2LGW/f99h/VfPcmFvOMEWKPwE1HYHT5EhEZw4/gxJOSUYikpocfQZAKi\nemI2Fjda78qVKxkwYAAbNmxg2bJlHDx4sMFTqdKl9Fp9FHFFzx5413OGoitzLK+AneeyG/3bkpHJ\n/6Tt4N296fxP2g62ZGQ2mv9YXkGz+jB27Fi3WmhDMuNVP+rmyIzffffdDBkyhKFDh7oD2QRUk2Cp\n/iQ+Z84cFi5cyOTJk1m8eDFxcXE1RjmJiYlcuHCB/Px8Zs6cyciRIxk5ciRpaWl12q4uM/7DDz+Q\nnp7OmDFjGDp0KDNmzHDLiUyaNIknnniCiRMn1pHnqOLhhx/GYDDw3nvv1RgtL1q0iOeff77eMtOn\nT+fIkSOcOHGi3utV1Cc/PmLECJKSkli6dKk7PS4ujmeffZbx48ezbt06Tp06xbRp0xg+fDgTJkxw\nC+59/vnnjB49miuuuIKpU6dy4cKFRttviir58ZtvvhlwCipu2LDB4/I5OTmUlJQwduxYhBDMnj3b\nXb53794YDIY6+lkthbrr1KKivIifDm3kzJkMSgml2ByAQ/bi1Blf0JuRWn+umzCI2MJyyoDgmFjs\nVhsajQbfsPBG6967dy+jR49m5cqV9O3bt8F8ZRYLB3OdaxE9AgIYFBmhHMQvoMRcicMh6RbgR36Z\niRJzJYHe+stSt5IZb1hm/MMPP2TgwIFs3bq1ziHRW2+9lVWrVtWIcleFRqPh8ccf5/nnn29Qiwk6\nv/x4dnY20dEXdVJrl09JSSEtLa3GNF5Loe4+1TCVFrBr6xvkFRj4/EdJsd2BXtuXkckjCA47R98Y\nGyHaHoTn27D4VxJz5QR0eu8GgwyVlJTw9NNPM2vWLIYPH86qVavw9vZucCeUlJLMomJOGpw7mob1\n6E7PoEtX9uwKDIxsej2ouCIcY6UFh3QQFO7DrxLiCfFtvlpvdZTMOO52GiIlJYXjx4+za9euOppM\nWq2WxYsX88ILL/DrX/+6Ttnf/va3PPfcc24BzPro7PLjTZWPjIzk/PnzHvXll6IchQu73cqZk99h\nMZdSKvqTZzlPTHQA8T1GEDPQj3xCCNUF4FdUhp+opEfySPy7RQJ1gwxJKfn00095+OGHycnJITY2\nluHDh9eRAK9OmcXCodw8iisr6R7gT1JkNzWKuEyE+PowY1B/DKYKwv18f7GTgItrFEajkenTp7Ny\n5UoWLFhAUlIS27Ztq5G3PpnxYcOGNVr/5ZYZf+qpp4CLMuOXS7a6MZnxAQMG8Oyzz3LrrbeyefNm\nkpKSalyfNWsWL7zwQp10cE7JPfbYY7z00ksN1l+f/Pju3bsJDQ1lzpw5TcqP1+ahhx5i4cKFpKam\nsnXrVp555pk6eZozoqguP67T6RqVH/f29gZqyo9HR0eTlZXlzle7fGvKj6s1CsBmM5OduQOEhlxz\nIF/sO0KFvRytr5ZKfTn6CDO3XjuAST20TE7ypd+4UW4nUZvMzEymT5/OLbfcQmRkJNu3b2fhwoUN\nti2lJLPwaVfjAAAbWElEQVSwiLQz5yi3WBnWozspPaOUk7jMhPj60Cc89LI4ieoomfHGGTduHKtX\nr+b66693h1+twsvLi0cffdQ9jVWbOXPmsGXLFhoKLdDZ5cejoqIIDAxkx44dSCl57733apRvTfnx\nLu8orNYKfjqxhVP5h9mXa+XzncGUlYcxqF9fQnvbiRliYkj3aKLyCukZKOk/fgz+jUidf/DBB2zb\nto1XX32V3bt3M3r06Abzllks7DiXzfECA938/ZgQF6OmmjogSma8caZPn87SpUuZNm0aBkNNSf17\n7rmnwR1Ter2eBQsWNLgzsCvIj//tb3/j3nvvJTExkT59+rin6axWKxkZGYwYcUlisM2mxWTGW4rL\nKTNeUHyO/x78J3vPpGMs6U5RfiDelr5ERJdwtqCEyD6V/G58KuHnSrFXmolKGeGOaV2dH374AbPZ\nzNSpUzGbzeTn59dYhKqNlJLTRcX8ZChEKzQMioxQDqIZKJlxBXRt+fH169ezb9++BpVlO5LMeLsm\nO/cw/7vpRU5kSipsXqQkxpF4hRfmgm4UVPgR4OfNjGFDnE7CbCFq+Eh8ay0oFhQU8Pjjj/Puu+8y\nYcIEpk6dire3d6NOQq1FKBSXh64sP26z2TzaPXe56JJ3qMK8U2zc8Gf+870vWk0gPiGCiCgTMT0j\n0Sb4kVsoSO45kPDcPBxWKz2Hj6yxYC2lZM2aNSxevBij0cgf/vAHlixZ0mibtUcRakeTQvHL6ary\n49V3bbUGXc5RVJqK2bp5Nbv2aKms1NGnrxEfn1j8fAag8QtEaGBi/z5oT5zFYbfTc8RIvIOCa9Sx\nadMm9zzo6tWrm1xQKrc4NZqKKpyjiEGR3fBRowiFQtFB6HJ3q7OnT/LFjzryS3qA2YIw+2MLDuOI\n6TSOMxZm95uG9sRZpMNBz5Gj8A4MAsBkMrF//36uvPJKrrvuOj777DOmT5/eoIAfOEcRZ4qNnCgw\noBUahvboTi81ilAoFB2MLucoDh/LoqzCl4H99ISWGEgZNZyckAsEB/ugs/tQdOw4QT4R9Bo5yh1s\n6Msvv2T+/PkUFBRw9uxZQkJCSE1tPBBf9VFEpL8/Sd3VKEKhUHRMutT22Au5WeQWVBITN5Cw7v2I\niR9IfFIkdr0Zrc2B9kIhYV7+bieRnZ3NLbfcwnXXXYe3tzeff/55nb3Stalai0g7k0WZ2crQHt0Z\n3itKOQmFQtFh6TKOwma18cN/9xMa4s+iB6cxcWIf+gwXePlruCV+EmNMYVwTPowBYyah9w8gLy+P\nQYMG8cUXX7B8+XIOHDjQ5EGjcouFnVnZHMsvINzPl/FxMWqqqZOiZMab5quvvmLUqFEMGDCA5ORk\nbrvtNvehuzlz5tCrVy+3fEZBQQFxcXFATdntYcOGMW7cuAYFAnNycpg+ffol97E1WLt2LX379qVv\n374NHuR75pln6NWrl1tqfNMmZwTpxiTIp06d6pEG2GVBStmh/oYPHy6bS1Fxhfznv36Ub/ztQ3nm\nzFkppZSbjmyQz215Vv54/Hv587ffyMzvv5OW8nKZlZXlLvfaa6/JjIyMJusvLDfJrT+flp8ePia/\nOfmzPFdsbHYfFZ5z9OjRZpcpKq6QGZmFsqi44rL0wd/f3/169uzZcvny5VJKKU0mk0xISJCbN2+W\nUkpZXl4up02bJlesWCGllPLQoUMyISFBHjt2TEoppdVqlStXrrwsfarCarX+ovI5OTkyNjb2F7V5\n6NAhmZiYWOP/6rPPPpPff/+9lFLKu+66S8bExMhVq1ZJKaXMz8+XvXv3llJKmZmZKZOSktzlVq9e\nLWfPnl1vu4sWLZIbNmzwuJ82m83jvJcDg8Eg4+PjpcFgkIWFhTI+Pl4WFhbWybd06VL58ssv10mv\nbYvqrFmzxv29q019vxFgj7zE+26nnw8pNlbyzj/3cfToT/SI9CcwKIJdZ7fz5bHPCRA6fsr7nNAe\nk4jsN5iFf/gDb775Jjt27CAlJYUFCxY0Wrfd4eCngkI+PHCYMouFYB9v5o4arkKTtiLHThZQUmpu\nNE9pmYVtO8/gcEg0GsFVo3sTGNCwemxQoDcD+3p+Mnfs2LHuQDsNyYxPmjSJ+fPnN0tm/KGHHmLP\nnj0IIVi6dCkzZ84kICCAsrIywCkz/sUXX7BmzRrmzJlDWFgY+/fvJzk5mfXr19eQlUhMTCQtLQ2N\nRsPcuXPdT/Z//etf65xiri4z/sYbbxAYGMjcuXMxmUz06dOHd955h9DQUCZNmsS4ceNIS0sjNTW1\nxr7+l156iSeeeKLGoa/a63qPPPIIr776Kvfdd1+j9i0pKWlQFPHTTz9l+fLlgPPpe9asWZSXlwOw\nYsUKxo0bx9atW1m2bBlRUVGkp6dz9OhR/v73v/P6669jsVgYPXo0q1atQqvVMm/ePHbv3k1FRQU3\n33wzy5Yta7RvTbF582auvvpq90nrq6++mq+++qqG6u2lkpqayoQJE3jyySd/cV1N0ekdhaGogrNZ\np9H7l+AV6McX+zZx2n4Qvd3OQBmJXWdn25kTPHvnfeTm5vLggw/Sp0+fRussMZvJMpZwvqSMs0Yj\nVrud4T17YLbbKbdYW+mTKTylpNQlMx7mR36hiZLSykYdRXNQMuP1y4wfOXKkySm12NhYxo8fz/vv\nv89vfvObGtdOnTpFcnIypaWlmEwmdu7cWad8ZmYmoaGhbkG9yMhIvvnmG3x8fDh58iR33HEHVSoO\nu3bt4vDhw8THx3Ps2DE++ugj0tLS8PLy4oEHHuCDDz5g9uzZjUqVV/Hyyy/zwQcf1OnPVVddxeuv\nv14jLTs7m5iYGPf7xqTGV6xYwXvvvceIESP4y1/+4naO9UmQg1NR2Gw2YzAY3FpeLUWndxQVlkwO\nndmLzldSqM0lwB5D38B+lOWX4vBysO6bb/n673sZOjCFjRs3NqidYnM4yCktI8tYQnFlJRoh6B4Q\nQEKY84yF2W5HIzSE+7WOmqPCiSdP/sXGcIxlFhx2B0FBPvxqfDwhwUpmHFpWZrwKg8HAlClTMJlM\n3H///TUcyBNPPEFqairXX399jTJVEd8APvroI+6//353dLcqasuMW61WHnzwQdLT09FqtW7hRYBR\no0a5ZcO//fZb9u7dy8iRIwHn/2VkpFPkszGp8ioWL17M4sWLm/zc4LnU+Lx581iyZAlCCJYsWcJj\njz3GO++806AEeVCQc9t+ldS4chQuhBAx3hCVkJjIt7W+MA1RWJLFl2n/h8WoIdQrGK30o/iInZBS\nX3S+YXhHRxIjk3hgzihSZ9yI3Wrl5PHjNf4jSy0WCqx2zHo9Wr0ef72egd2c2kxVMavDfP0uq4S1\n4vISEuzDjGn9MRRVEB7q+4udBCiZ8frarE5SUhL79u1j2LBhhIeHk56eziuvvOKeNqsiMTGR5ORk\nPv744wbbSE1N5e67766TXl1mHODVV1+le/fuHDhwAIfDUUPWv3o/pZTcddddvPDCCzXqa0qqvIrm\njCiio6PdwoXglAqfNGlSnbLdu3d3v77vvvvcC/QNSZBXPdC2ltR4h3AUeiH6xerE4hCh6akpuMA/\nX/lzk2Vs0kZ2YQblpWYsVj25fg703l4UV+5jQ/YFhg0ZTM+oKJx+2cjXb72Fzt+P4eMnkJgQj6HC\nTH55OSarFYfNhndAABMnTiS6HlXJEF8f5SDaOSHBPpfFQdSmSmb8hhtuYN68edx55508//zzbNmy\nhalTp9YrM37TTTcxfvx4+vXrh8Ph4K9//WsdKfoqOfCqKZ6ioiJCQ0PdMuP9+/dn/fr1DY4EmpIZ\nr3oiTk9PJzk5udHPVyUzPmHCBI9lxh9//HFmzJjBmDFj3OsUJpOp3rxPPvlknRFFdX788cd6p4P7\n9evH6dOn3e+NRiPR0dFoNBrWrl3bYHzsKVOmcMMNN/Doo48SGRlJYWEhpaWl9UqV13dTb86I4tpr\nr+WJJ55wTx1+/fXXdRwUOEdHVWrA69evd6s95OfnExYWhlarrSFBDk6Hl5ub694t1pK0e0chhAjv\npRVL+nh5De+r11ZU6nX0tze9DlBUWoS+TGCzBiA1oLVIKKukqCiPPnpvoh0O4qTDnd9mreTCuXw+\n+/g8o2++lR5RUQQHBdE3IIBu/r6Yyk1kHz1KrwkTmjWFoOj8VJcZnzVrFp999hkPPfQQ8+fPx263\nM2vWrHplxk0mE0KIem+STz31FPPnz2fw4MFotVqWLl3KTTfd5JYZj4mJYfDgwXWe0Ktz2223MXLk\nSNasWeNOe/3115k/fz5Dhw7FZrNx1VVXNSk1vnbtWvdidkJCAu+++26TNhkyZAivvfYas2fPprS0\nlPDwcGJjY+tdHE5KSiIlJYV9+/a506rWKKSU6PV63n777Trl/P396dOnDxkZGSQmJvLAAw8wc+ZM\n1q1bx+TJkxsc7QwaNIjly5dzzTXX4HA48PLyYuXKlYwZM8YtVZ6QkNCoVLmnhIWFsWTJEvc019NP\nP+1e2L733nuZO3cuI0aM4PHHHyc9PR0hBHFxcbz55puAU4L86aefRqfTodVqa0iQ7927lzFjxtQJ\nM9sStHuZcSHENaO8tSuuDfA5H6jTWXP0PlNHjXIaXdps2B1WtBovhMtYUkpKjOVknMvFbpc4EGi9\nrVQUVWKrLCM2NorY2DjyrRZ6duuGt1ZHhdVGhc2GTTo4npWN7D+Ih+bNI0Bfc8Hz5wsXSLlqYqOR\n6hQtj5IZV1Sxfv169u7d69751JV4+OGHSU1NZcqUKXWudUWZ8dhuWo0M1OlqDCOkzUZZSQ4WmwO7\n3YGfXxBarQazxcaZHBNWC2i9tQgbaC06dBodw1KSCQ4JREqJxiIpKDfh5XIweqEh2NubAd27c6zE\nWMdJAGiEwOFw1ElXKBRtw4wZM+oEQ+oqDB48uF4n0RJ0BEfhpROixrBn1+GjZObmUm6zodfqiAwM\nJiIAcotzsVntCKEhOCiUstJKCsqK0Ou8iAgOxi/Aj3+nbSe/rJwKh8Sk0TBxyGBG9+/Hhfx8vk4/\nQIXVwjkffxa74twqFIr2zb333tvWXWgTmjp/cjnpkHfCf58+xxmLFbuEEG9Bd2sRSRUVDI7vg41y\nTp7L5busTLJtDiokeAnBg/0SOVtk5LuCIrw1GiwOB/k2B+YDhxgaG8PXO3YyY/IkHFKw5sgRPv78\nc347Y0Zbf1RFAzS2DVWh6Mq0xHJCx9N6kpJ+oQEM9fOml07D3fEDOWe1k1NZTrEpl/ziHHIslZQ4\nJIE+ehaNHUKol5aPj50kKjgQvVbHPUOS+HWvKLrpBP46DWaLFZ1OS6hLlykqIpJ/b/m2jT+ooiF8\nfHwwGAwt8oNQKDoyUkoMBsNlX0ftcCMKiWRIt0CEzUae2YreS0Oo3gsLNopLiomJ6Mn+vGxMUjIs\nMJAjp7LxRWC0WDDb7YBk78mTZFusCAmThwwhIiQIh12SV1iEVuvF2fPnMWq6VgzejkR0dDRZWVnk\n5+e3dVcUinaHj49Po+GYL4WO5yikpMRqxmJzPk3mVxZTYDYzslsQVruDjPP5BOm0WCQcMxSiF4Ix\nvaLYmp3LhbJyrHY7Z7V+GLCi1WjYl5HBoN4xXDtuDD/sT8dktqALCkYnlKNor3h5eblP2SoUipan\nRaeehBDThBAnhBAZQog/1nPdWwjxkev6TiFEXFN12h02HOiwOmw4pGT9mSyGBwcSqPcisUcow2N7\nIL30CGBaYgKzhiaxKzsHoRHk5OUzM6E3j0wcTyCCCzYHVglnL+QTFRHOzCmTue7KK4kMCye+iwVr\nVygUioZoMUchhNACK4FfA4OAO4QQg2pluwcoklImAq8CLzVVr9kqQeowW+3kOyRXdAslWFro5qfB\n31uLj5c32aWlBOv1ZBuNDI3vjbdGUGq1o7VZKSoo5F/fb8MHCBRwrthIRHAgFZVOBVK7tHMs4xSz\nb7n5cppDoVAoOiwtOfU0CsiQUv4MIIT4J3ADcLRanhuAZ1yvPwFWCCGEbGyV0iEoKijhlMWOFyCL\ni+gWEQEOLd8fO4+XEIR4e2M1WzlZamLNlu8w2h0E+XjTNyaa7cVGcsrN2KWk2CGZMTiJyJAQfkw/\nQOb585itdnpF9WT8qFEtYROFQqHocLSko+gFnKv2PgsY3VAeKaVNCGEEwoGC6pmskpBMs7VH1fu0\nskpy7Q50wNZyC16m88TqtHazlKKXl9YSr3NQYLP4FNkcfCtBL2CaVpbt2LOHg2abb6VDaoXAMUCv\ndVhO/VSy8ZRTZTIYqLDbNUePHZNjR47Irf2BSuwOXaFDlgHt5dRdBLVs1YVRtriIssVFlC0u0v9S\nC7ako6hvk3vtkYIneSwagTHe2+sQQKbZOvKh8MDdTTU+zM+73vQRfs5/8212vVaI4jCtpkbUmwsW\nW0CgxV75u9CA52qX/YfRFFFYaf1OSmlpqv3WQAix51KP5Hc2lC0uomxxEWWLiwgh9lxq2ZZczM4C\nYqq9jwbON5RHCKHD+VBfWCvPWaNDOsrs9vrv/JeITYK2llOyOqQocjh8NFBHE2BPhSX8gs1uaC9O\nQqFQKFqLlhxR7Ab6CiHigWzgduC3tfJsBO4CtgM3A/+pZ31izxmr/eiRCmtib29ZUeGQ2nyrvX5t\nZQ8pdzi0BruDCK3GWmZ3SAAJssxu1xyz2LUVkuPbys0R4JxjKnM4RIbFVnDe5kj/Je0qFApFR6TF\nHIVrzeFBYDOgBd6RUh4RQjyLM8j3RuD/gPeFEBk4RxK311NPkRDiEYn15WybvYdE5Jyy2BoPktwI\nDqDCIe1egqIsIdyC9XYpKXFI+ymrfYMZtpyw1tCytwAmKWX9Avdtx1tt3YF2hLLFRZQtLqJscZFL\ntkW7lxmvQgjhC/QGV6yhS8cBVFJ3QdoB5Ekpa099KRQKRZemwzgKhUKhULQNHU8UUKFQKBStSrt1\nFC0h/9FR8cAWC4UQR4UQB4UQ3woherdFP1uDpmxRLd/NQggphOi0WyM9sYUQ4lbXd+OIEOLD1u5j\na+HBbyRWCPGdEGK/63dyXVv0s6URQrwjhMgTQhxu4LoQQrzustNBIUSKRxVLKdvdH87F71NAAqAH\nDgCDauV5AFjten078FFb97sNbTEZ8HO9nteVbeHKFwhsA3YAI9q63234vegL7AdCXe8j27rfbWiL\nt4B5rteDgNNt3e8WssVVQApwuIHr1wFf4jzDNgbY6Um97XVE4Zb/kM5zC1XyH9W5AVjrev0JMEV0\nzkg2TdpCSvmdlNLkersD55mVzogn3wuAPwF/xrlpobPiiS3uA1ZKKYsApJR5rdzH1sITW0guboQJ\npu6Zrk6BlHIbdc+iVecG4D3pZAcQIoSIaqre9uoo6pP/6NVQHimlDaiS/+hseGKL6tyD84mhM9Kk\nLYQQVwAxUsovWrNjbYAn34t+QD8hRJoQYocQYlqr9a518cQWzwC/E0JkAZuAh1qna+2O5t5PgPYb\nj+JyyX90Bjz+nEKI3wEjgIkt2qO2o1FbCCE0OFWI57RWh9oQT74XOpzTT5NwjjJ/EEIMllIWt3Df\nWhtPbHEHsEZK+RchxFic57cGSynbi25ba3FJ9832OqK4XPIfnQFPbIEQYirwJJAqpbzkA4ntnKZs\nEQgMBrYKIU7jnIPd2EkXtD39jXwmpbRKKTOBEzgdR2fDE1vcA3wMIKXcDvjgFAzsanh0P6lNe3UU\nbvkPIYQe52L1xlp5quQ/oGH5j85Ak7ZwTbe8idNJdNZ5aGjCFlJKo5QyQkoZJ6WMw7lekyqlvGQx\ntHaMJ7+RDTg3OiCEiMA5FfVzq/aydfDEFmeBKQBCiIE4HUVXjKW7EZjt2v00BjBKKXOaKtQup57k\nZZL/6Ax4aIuXgQBgnWs9/6yUMrXNOt1CeGiLLoGHttgMXCOEOArYgcVSyjqClx0dD23xGPC/QohH\ncU61zOmMD5ZCiH/gnGqMcK3HLAW8AKSUq3Guz1wHZAAm4G6P6u2EtlIoFArFZaS9Tj0pFAqFop2g\nHIVCoVAoGkU5CoVCoVA0inIUCoVCoWgU5SgUCoVC0SjKUSjaHUIIuxAivdpfXCN54xpSymxmm1td\n6qMHXJIX/S+hjrlCiNmu13OEED2rXXtbCDHoMvdztxAi2YMyjwgh/H5p24qui3IUivZIhZQyudrf\n6VZq904p5TCcYpMvN7ewlHK1lPI919s5QM9q1+6VUh69LL282M9VeNbPRwDlKBSXjHIUig6Ba+Tw\ngxBin+tvXD15koQQu1yjkINCiL6u9N9VS39TCKFtorltQKKr7BRXDINDLq1/b1f6i+JiDJBXXGnP\nCCEWCSFuxqm59YGrTV/XSGCEEGKeEOLP1fo8RwjxxiX2czvVBN2EEH8TQuwRztgTy1xpC3A6rO+E\nEN+50q4RQmx32XGdECKgiXYUXRzlKBTtEd9q007rXWl5wNVSyhTgNuD1esrNBV6TUibjvFFnueQa\nbgOudKXbgTubaP83wCEhhA+wBrhNSjkEp5LBPCFEGDADSJJSDgWWVy8spfwE2IPzyT9ZSllR7fIn\nwE3V3t8GfHSJ/ZyGU6ajiiellCOAocBEIcRQKeXrOLV8JkspJ7ukPJ4CprpsuQdY2EQ7ii5Ou5Tw\nUHR5Klw3y+p4AStcc/J2nLpFtdkOPCmEiAb+JaU8KYSYAgwHdrvkTXxxOp36+EAIUQGcxilD3R/I\nlFL+5Lq+FpgPrMAZ6+JtIcS/AY8lzaWU+UKIn106OyddbaS56m1OP/1xylVUj1B2qxDifpy/6yic\nAXoO1io7xpWe5mpHj9NuCkWDKEeh6Cg8ClwAhuEcCdcJSiSl/FAIsRO4HtgshLgXp6zyWinl//Og\njTurCwgKIeqNb+LSFhqFU2TuduBB4FfN+CwfAbcCx4H1UkopnHdtj/uJM4rbi8BK4CYhRDywCBgp\npSwSQqzBKXxXGwF8I6W8oxn9VXRx1NSToqMQDOS44gfMwvk0XQMhRALws2u6ZSPOKZhvgZuFEJGu\nPGHC85jix4E4IUSi6/0s4HvXnH6wlHITzoXi+nYeleKUPa+PfwE34oyR8JErrVn9lFJacU4hjXFN\nWwUB5YBRCNEd+HUDfdkBXFn1mYQQfkKI+kZnCoUb5SgUHYVVwF1CiB04p53K68lzG3BYCJEODMAZ\n8vEozhvq10KIg8A3OKdlmkRKWYlTXXOdEOIQ4ABW47zpfuGq73uco53arAFWVy1m16q3CDgK9JZS\n7nKlNbufrrWPvwCLpJQHcMbHPgK8g3M6q4q3gC+FEN9JKfNx7sj6h6udHThtpVA0iFKPVSgUCkWj\nqBGFQqFQKBpFOQqFQqFQNIpyFAqFQqFoFOUoFAqFQtEoylEoFAqFolGUo1AoFApFoyhHoVAoFIpG\n+f+Z7gtT7OsjsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1719ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test=mask(DataTemp,DataTemp.columns[:-3],'Target3', predict)\n",
    "ada=cv_optimize(X_train, y_train, X_test, y_test,10, 'ADA',{'n_estimators':[10,20,50],'learning_rate':[0.8,1.0,1.2]})\n",
    "log=cv_optimize(X_train, y_train, X_test, y_test, 10, 'LOG', {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "svm=cv_optimize(X_train, y_train, X_test, y_test, 10, 'SVM', {\"C\": [0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "rm=cv_optimize(X_train, y_train, X_test, y_test, 10, 'RF', {\"n_estimators\": [10,20,50,100]})\n",
    "knn=cv_optimize(X_train, y_train, X_test, y_test, 10, 'KNN', {\"n_neighbors\": [3,5,7,9,11,13]})\n",
    "gnb=cv_optimize(X_train,y_train,X_test, y_test, 10,'GNB',[])\n",
    "with sns.hls_palette(8, l=.3, s=.8):\n",
    "    ax=make_roc(\"ADA\",ada, y_test, X_test, labe=100, skip=3,proba=True)\n",
    "    make_roc(\"SVM\",svm, y_test, X_test, ax,labe=100, skip=3,proba=False)\n",
    "    make_roc(\"LOG\",log, y_test, X_test, ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"RM\",rm,y_test, X_test,ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"KNN\",knn,y_test, X_test,ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"GNB\",gnb,y_test, X_test,ax,labe=100, skip=3,proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HSI_MA10 = MA(HSI[\"HSI_Close\"],10)\n",
    "AXJO_MA10 = MA(AXJO[\"AXJO_Close\"],10)\n",
    "SSE_MA10 = MA(SSE[\"SSE_Close\"],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "NewData = pd.merge(DataTemp[Features_label2],pd.DataFrame(HSI_MA10),left_index=True,right_index=True)\n",
    "NewData = pd.merge(NewData,pd.DataFrame(AXJO_MA10),left_index=True,right_index=True)\n",
    "NewData = pd.merge(NewData,pd.DataFrame(SSE_MA10),left_index=True,right_index=True)\n",
    "NewData = pd.merge(NewData,pd.DataFrame(Label2),left_index=True,right_index=True)\n",
    "NewData[\"MA_10_x\"] = scaler.fit_transform(NewData[\"MA_10_x\"].reshape(-1,1))\n",
    "NewData[\"MA_10_y\"] = scaler.fit_transform(NewData[\"MA_10_y\"].reshape(-1,1))\n",
    "NewData[\"MA_10\"] = scaler.fit_transform(NewData[\"MA_10\"].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16a5f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test=mask(NewData,NewData.columns[:-1],'Target2', predict)\n",
    "ada=cv_optimize(X_train, y_train, X_test, y_test,10, 'ADA',{'n_estimators':[10,20,50],'learning_rate':[0.8,1.0,1.2]})\n",
    "log=cv_optimize(X_train, y_train, X_test, y_test, 10, 'LOG', {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "svm=cv_optimize(X_train, y_train, X_test, y_test, 10, 'SVM', {\"C\": [0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "rm=cv_optimize(X_train, y_train, X_test, y_test, 10, 'RF', {\"n_estimators\": [10,20,50,100]})\n",
    "knn=cv_optimize(X_train, y_train, X_test, y_test, 10, 'KNN', {\"n_neighbors\": [3,5,7,9,11,13]})\n",
    "gnb=cv_optimize(X_train,y_train,X_test, y_test, 10,'GNB',[])\n",
    "with sns.hls_palette(8, l=.3, s=.8):\n",
    "    ax=make_roc(\"ADA\",ada, y_test, X_test, labe=100, skip=3,proba=True)\n",
    "    make_roc(\"SVM\",svm, y_test, X_test, ax,labe=100, skip=3,proba=False)\n",
    "    make_roc(\"LOG\",log, y_test, X_test, ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"RM\",rm,y_test, X_test,ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"KNN\",knn,y_test, X_test,ax,labe=100, skip=3,proba=True)\n",
    "    make_roc(\"GNB\",gnb,y_test, X_test,ax,labe=100, skip=3,proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding more features such as moving average of the other indices, the accuracy improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock prediction is an active area of research and many hedge funds are already exploiting the ML algorithms. So to find any pattern is very difficult. Also, S&P500 index is the most common dataset for Machine Learning reseacrh. If there exists any profit making algo - people and institutions tend to use it until equilibrium is achieved and it can be no longer used. Even after that, I was able to achieve a **maximum accuracy** of **61%** for prediction of next day Open using **Support Vector Classifier**. Also the efficient market hypothesis states that it is impossible to beat the market because the current price reflects and incorporates all the relevant information and thus prediction is impossible.\n",
    "According to the EMH, stock prices will only respond to new information and so will follow a\n",
    "random walk. If they only respond to new information, they cannot be predicted. That the stocks\n",
    "follow a random walk is actually a sign of market efficiency, since predictable movement would\n",
    "mean that information was not being reflected by the market prices. There are three variants of this theory  weak, semi-strong, and strong. Most research has\n",
    "concluded that the semi-strong version holds true. This version claims that stock prices reflect all\n",
    "publicly available information, but private information can be used to unfairly predict profits. This\n",
    "is the basis behind strong insider trading laws. Kalman filtering constantly adjust the prediction time series by including the new information. The fitted data has a trend fitting power of close to 90%.\n",
    "High frequency trades can make use of this 61% accuracy for significant profits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibiliography\n",
    "1. Predicting Stock Price Direction using Support Vector Machines By Saahil Madge\n",
    "2. Predicting Market Fluctuations via Machine Learning by Michael Lim,Yong Su\n",
    "3. Forecasting S&P 500 Stock Index Using Statistical Learning Models by Chongda Liu, Jihua Wang, Di Xiao, Qi Liang\n",
    "4. Predicting stock and stock price index movement using Trend Deterministic Data Preparation and machine learning techniques by Jigar Patel, Sahil Shah, Priyank Thakkar, K Kotecha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
